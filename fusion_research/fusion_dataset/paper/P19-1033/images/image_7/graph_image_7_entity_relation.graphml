<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_7&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image consists of two bar charts labeled (a) AUC and (b) nDCG@10. Each chart compares the performance of different methods in learning news title representations. The x-axis of both charts is labeled with two categories: LSTUR-ini and LSTUR-con. The y-axis of chart (a) ranges from 0.615 to 0.640, while the y-axis of chart (b) ranges from 0.395 to 0.420. Both charts contain four bars for each category, representing four different methods: LSTM (yellow), LSTM+Att (light green), CNN (green), and CNN+Att (dark green). In chart (a), the highest value is achieved by CNN+Att for LSTUR-con at approximately 0.635. In chart (b), the highest value is also achieved by CNN+Att for LSTUR-con at approximately 0.415. The trends show that incorporating attention mechanisms generally improves performance, with CNN+Att outperforming other methods in both metrics."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;LSTM&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A model used in the experiments, represented by yellow bars in the graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;LSTM+ATT&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"An enhanced version of LSTM with attention mechanism, represented by light green bars in the graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;CNN&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A model used in the experiments, represented by dark green bars in the graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;CNN+ATT&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"An enhanced version of CNN with attention mechanism, represented by teal bars in the graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;LSTUR-INI&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Initial condition for LSTUR model, shown on the left side of both graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;LSTUR-CON&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Condition after convergence for LSTUR model, shown on the right side of both graphs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;AUC&quot;">
  <data key="d0">"GEO"</data>
  <data key="d1">"Area Under the Curve metric, depicted in graph (a)."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<node id="&quot;NDCG@10&quot;">
  <data key="d0">"GEO"</data>
  <data key="d1">"Normalized Discounted Cumulative Gain at 10 metric, depicted in graph (b)."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
</node>
<edge source="&quot;IMAGE_7&quot;" target="&quot;LSTM&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTM是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;LSTM+ATT&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTM+Att是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;CNN&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CNN是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;CNN+ATT&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CNN+Att是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;LSTUR-INI&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTUR-ini是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;LSTUR-CON&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTUR-con是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;AUC&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"AUC是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_7&quot;" target="&quot;NDCG@10&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"nDCG@10是从image_7中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_7.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
