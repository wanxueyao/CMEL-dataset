{
    "image_1": [
        {
            "merged_entity_name": "BIDIRECTIONAL LSTM",
            "entity_type": "ORGANIZATION",
            "description": "A neural network layer that processes sequences in both forward and backward directions, utilized in the credibility assessment model to capture long and short range dependencies in text.",
            "source_image_entities": [
                "BIDIRECTIONAL LSTM"
            ],
            "source_text_entities": [
                "BIDIRECTIONAL LONG SHORT-TERM MEMORY (LSTM) NETWORK"
            ]
        },
        {
            "merged_entity_name": "CLAIM SOURCE EMBEDDING",
            "entity_type": "OBJECT",
            "description": "A vector representation of the source of the claim, used in the credibility assessment model to capture the trustworthiness of the claim's origin.",
            "source_image_entities": [
                "CLAIM SOURCE EMBEDDING"
            ],
            "source_text_entities": [
                "C S_{N}"
            ]
        },
        {
            "merged_entity_name": "ARTICLE SOURCE EMBEDDING",
            "entity_type": "OBJECT",
            "description": "A vector representation of the source of the article, used in the credibility assessment model to influence the credibility score based on the article's origin.",
            "source_image_entities": [
                "ARTICLE SOURCE EMBEDDING"
            ],
            "source_text_entities": [
                "A S_{M,N}"
            ]
        },
        {
            "merged_entity_name": "CREDIBILITY SCORE",
            "entity_type": "OBJECT",
            "description": "The output score indicating the credibility of the claim, generated by the end-to-end neural network model after processing claim and article embeddings, attention weights, and source information.",
            "source_image_entities": [
                "CREDIBILITY SCORE"
            ],
            "source_text_entities": [
                "CREDIBILITY SCORE"
            ]
        }
    ],
    "image_2": [
        {
            "merged_entity_name": "SN",
            "entity_type": "EVENT",
            "description": "Snopes category in the dataset with 4341 total claims, 1164 true claims, 3177 false claims, and 29242 articles from 336 sources, known for investigating rumors and providing credibility labels.",
            "source_image_entities": [
                "SN"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "merged_entity_name": "PF",
            "entity_type": "EVENT",
            "description": "PolitiFact category in the dataset with 3568 total claims, 1867 true claims, 1701 false claims, and 29556 articles from 336 sources, which rates the credibility of claims made by political figures.",
            "source_image_entities": [
                "PF"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        },
        {
            "merged_entity_name": "NT",
            "entity_type": "EVENT",
            "description": "NewsTrust category in the dataset with 5344 total claims and 25128 articles from 251 sources, which is a news review community that assigns credibility scores to news articles based on community reviews.",
            "source_image_entities": [
                "NT"
            ],
            "source_text_entities": [
                "NEWSTRUST"
            ]
        },
        {
            "merged_entity_name": "SE",
            "entity_type": "EVENT",
            "description": "SemEval category in the dataset with 272 total claims, 127 true claims, 50 false claims, and 95 unverified claims, and 3717 articles from 89 sources, which is used for determining credibility and stance of social media content, particularly Twitter.",
            "source_image_entities": [
                "SE"
            ],
            "source_text_entities": [
                "SEMEVAL-2017 TASK 8",
                "SEMEVAL"
            ]
        }
    ],
    "image_3": [
        {
            "merged_entity_name": "TABLE 2",
            "entity_type": "EVENT",
            "description": "Table 2 is an event in the text where model parameters used for each dataset, including SN (Snopes), PF (PolitiFact), NT (NewsTrust), and SE (SemEval), are presented.",
            "source_image_entities": [
                "TABLE"
            ],
            "source_text_entities": [
                "TABLE 2"
            ]
        },
        {
            "merged_entity_name": "SEMEVAL",
            "entity_type": "ORGANIZATION",
            "description": "SemEval is the organization that provides datasets and data splits for the task of determining credibility and stance of social media content, particularly Twitter, and is also involved in the benchmark dataset released for SemEval-2017 Task 8.",
            "source_image_entities": [
                "SE"
            ],
            "source_text_entities": [
                "SEMEVAL",
                "SEMEVAL-2017 TASK 8"
            ]
        },
        {
            "merged_entity_name": "SNOPES",
            "entity_type": "ORGANIZATION",
            "description": "Snopes is a general fact-checking website that investigates rumors and provides credibility labels, and is also involved in the extraction of relevant snippets from reporting articles and is used as a dataset for credibility classification.",
            "source_image_entities": [
                "SN"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "merged_entity_name": "POLITIFACT",
            "entity_type": "ORGANIZATION",
            "description": "PolitiFact is a political fact-checking website that rates the credibility of claims made by political figures, assigns credibility ratings to claims, and is used as a dataset for credibility classification.",
            "source_image_entities": [
                "PF"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        },
        {
            "merged_entity_name": "NEWSTRUST",
            "entity_type": "ORGANIZATION",
            "description": "NewsTrust is a news review community that assigns credibility scores to news articles based on community reviews and is used as a dataset for credibility regression.",
            "source_image_entities": [
                "NT"
            ],
            "source_text_entities": [
                "NEWSTRUST"
            ]
        }
    ],
    "image_4": [    
        {        
            "entity_name": "LSTM-TEXT",        
            "entity_type": "CONCEPT",        
            "description": "LSTM-text is a recent approach for credibility assessment proposed by Rashkin et al. in 2017, achieving 64.65% accuracy on true claims and 64.21% on false claims in the Snopes dataset, with a Macro F1-Score of 0.66 and AUC of 0.70.",        
            "source_image_entities": [            
                "LSTM-TEXT"        
            ],        
            "source_text_entities": [            
                "LSTM-TEXT"        
            ]    
        },    
        {        
            "entity_name": "CNN-TEXT",        
            "entity_type": "CONCEPT",        
            "description": "CNN-text is a CNN-based approach for credibility assessment proposed by Wang in 2017, achieving 67.15% accuracy on true claims and 63.14% on false claims in the Snopes dataset, with a Macro F1-Score of 0.66 and AUC of 0.72.",        
            "source_image_entities": [            
                "CNN-TEXT"        
            ],        
            "source_text_entities": [            
                "CNN-TEXT"        
            ]    
        },    
        {        
            "entity_name": "DISTANT SUPERVISION",        
            "entity_type": "CONCEPT",        
            "description": "Distant Supervision is a state-of-the-art distant supervision based approach proposed by Popat et al. in 2017, achieving the highest accuracy among the listed configurations for the Snopes dataset, with 83.21% on true claims and 80.78% on false claims, a Macro F1-Score of 0.82, and an AUC of 0.88.",        
            "source_image_entities": [            
                "DISTANT SUPERVISION"        
            ],        
            "source_text_entities": [            
                "DISTANT SUPERVISION"        
            ]    
        },    
        {        
            "entity_name": "SNOPES",       
            "entity_type": "ORGANIZATION",        
            "description": "Snopes is an organization involved in the extraction of relevant snippets from reporting articles and is also a dataset used for credibility classification, comparing the performance of various models, including DeClarE, which shows clear separability between credible and non-credible articles.",        
            "source_image_entities": [            
                "SNOPES"        
            ],        
            "source_text_entities": [            
                "SNOPES"        
            ]    
        },    
        {        
            "entity_name": "POLITIFACT",        
            "entity_type": "ORGANIZATION",        
            "description": "PolitiFact is an organization that assigns credibility ratings to claims made by political figures and is also a dataset used for credibility classification, comparing the performance of various models, with claim sources analyzed by DeClarE.",        
            "source_image_entities": [            
                "POLITIFACT"        
            ],        
            "source_text_entities": [            
                "POLITIFACT"        
            ]    
        }
    ],
    "image_5": [
        {
            "entity_name": "MSE",
            "entity_type": "CONCEPT",
            "description": "Mean Squared Error (MSE) is a metric used to evaluate the performance of the different configurations in credibility regression tasks, with a lower value indicating better performance.",
            "source_image_entities": [
                "MSE"
            ],
            "source_text_entities": [
                "MEAN SQUARE ERROR (MSE)"
            ]
        }
    ],
    "image_6": [
        {
            "entity_name": "IITP",
            "entity_type": "ORGANIZATION",
            "description": "IITP, proposed by Singh et al. in 2017, is the best performing approach for the open variant of the SemEval task, with a macro accuracy of 0.39 and an RMSE of 0.746.",
            "source_image_entities": [
                "IITP (OPEN)"
            ],
            "source_text_entities": [
                "IITP"
            ]
        },
        {
            "entity_name": "NILETMRG",
            "entity_type": "ORGANIZATION",
            "description": "NILETMRG, proposed by Enayet and El-Beltagy in 2017, is the best performing approach for the close variant of the SemEval task, with a macro accuracy of 0.54 and an RMSE of 0.673.",
            "source_image_entities": [
                "NILETMRG (CLOSE)"
            ],
            "source_text_entities": [
                "NILETMRG"
            ]
        },
        {
            "entity_name": "DECLARE (PLAIN)",
            "entity_type": "ORGANIZATION",
            "description": "DeClare (Plain) is an approach that uses only biLSTM, without attention and source embeddings, and has a macro accuracy of 0.46 and an RMSE of 0.687.",
            "source_image_entities": [
                "DECLARE (PLAIN)"
            ],
            "source_text_entities": [
                "DECLARE (PLAIN)"
            ]
        },
        {
            "entity_name": "DECLARE (FULL)",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE (Full) is an end-to-end system that uses biLSTM, attention, and source embeddings, outperforming other approaches in credibility classification, with a macro accuracy of 0.57 and an RMSE of 0.604.",
            "source_image_entities": [
                "DECLARE (FULL)"
            ],
            "source_text_entities": [
                "DECLARE (FULL)"
            ]
        }
    ],
    "image_7": [
        {
            "entity_name": "DeClarE",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE is an automated end-to-end neural network model for evidence-aware credibility assessment of natural language claims, using PCA to project article representations and distinguish between credible and non-credible sources. It is developed by an organization that has also created a system for credibility classification and regression tasks.",
            "source_image_entities": [
                "DECLARE"
            ],
            "source_text_entities": [
                "DECLARE"
            ]
        },
        {
            "entity_name": "PCA",
            "entity_type": "EVENT",
            "description": "Principal Component Analysis, a statistical procedure used by DeClarE to reduce the dimensionality of data while retaining trends and patterns, projecting article representations from a high-dimensional space to a 2D plane for analysis.",
            "source_image_entities": [
                "PCA"
            ],
            "source_text_entities": [
                "PCA"
            ]
        },
        {
            "entity_name": "POLITICIANS",
            "entity_type": "PERSON",
            "description": "Individuals holding political offices, such as Bernie Sanders, Barack Obama, Hillary Clinton, etc., clustered based on their ideological similarities in the projections, and located close to each other in the embedding space by DeClarE.",
            "source_image_entities": [
                "POLITICIANS"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        }
    ],
    "image_8": [
    ]
}