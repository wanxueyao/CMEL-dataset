{
    "image_1": [
        {
            "entity_name": "IMAGE_1",
            "entity_type": "ORI_IMG",
            "description": "The image is a table comparing different summarization approaches applied to a news article. The table is divided into four main sections: Original Article, Extractive Approach, Abstractive Approach, and Unified Approach. Each section contains text describing the summary generated by each approach. The Original Article section details McDonald's announcement about the new 'Artisan Grilled Chicken' product, its availability in stores, and changes in ingredients. The Extractive Approach section highlights key sentences from the original article, marked in blue bold font, focusing on the product's availability and ingredient changes. The Abstractive Approach section provides a more coherent summary, marked in red italics font, but with some factual inaccuracies. The Unified Approach section combines the advantages of both extractive and abstractive approaches, marked in green bold font, providing a concise and coherent summary. The table is structured with rows and columns, where each row represents a different summarization approach and each column represents a specific aspect of the summary."
        },
        {
            "entity_name": "MCDONALD'S",
            "entity_type": "ORGANIZATION",
            "description": "A fast-food restaurant chain that is introducing a new product called 'Artisan Grilled Chicken' and making changes to its ingredients to use simpler, cleaner ingredients."
        },
        {
            "entity_name": "ARTISAN GRILLED CHICKEN",
            "entity_type": "PRODUCT",
            "description": "A new food product being introduced by McDonald's which will be available in various forms such as sandwiches, wraps, and salads."
        },
        {
            "entity_name": "SODIUM PHOSPHATES",
            "entity_type": "INGREDIENT",
            "description": "An ingredient previously used by McDonald's to keep chicken moist but has been removed from the new recipe."
        },
        {
            "entity_name": "VEGETABLE STARCH",
            "entity_type": "INGREDIENT",
            "description": "An ingredient that has replaced sodium phosphates in the new recipe for 'Artisan Grilled Chicken' to keep the chicken moist."
        },
        {
            "entity_name": "MALTODEXTRIN",
            "entity_type": "INGREDIENT",
            "description": "An ingredient that was previously used by McDonald's as a sugar to increase browning or as a carrier for seasoning but has been removed from the new recipe."
        },
        {
            "entity_name": "JESSICA FOUST",
            "entity_type": "PERSON",
            "description": "The director of culinary innovation at McDonald's who explained the changes made to the ingredients."
        },
        {
            "entity_name": "PANERA BREAD",
            "entity_type": "ORGANIZATION",
            "description": "Another fast-food restaurant chain that plans to remove artificial colors, flavors, and preservatives from its food by 2016."
        }
    ],
    "image_2": [
        {
            "entity_name": "IMAGE_2",
            "entity_type": "ORI_IMG",
            "description": "The image is a comparative bar chart illustrating the attention distribution across sentences and words in a model that combines word-level and sentence-level attentions. The chart is divided into two main sections. On the left, there are three groups of bars representing Sentence 1, Sentence 2, and Sentence 3. Each group contains multiple bars of different colors: orange, blue, and green. The orange bars represent the word-level attention, the blue bars represent the sentence-level attention, and the green bars represent the combined attention. A red arrow labeled 'Inconsistent' points to a high word-level attention (orange bar) in Sentence 2 where the sentence-level attention (blue bar) is low. This indicates an inconsistency in the attention distribution. The right section of the chart shows the same three sentences after multiplying and renormalizing the attentions. Here, the inconsistencies are attenuated, as indicated by the red arrow labeled 'Attenuated'. The y-axis ranges from 0 to 1, representing the attention values. The x-axis labels the sentences. The chart highlights the process of combining and normalizing attentions to address inconsistencies."
        },
        {
            "entity_name": "SENTENCE 1",
            "entity_type": "EVENT",
            "description": "The first sentence in a document, represented by orange bars in the attention distribution graph."
        },
        {
            "entity_name": "SENTENCE 2",
            "entity_type": "EVENT",
            "description": "The second sentence in a document, represented by blue bars in the attention distribution graph."
        },
        {
            "entity_name": "SENTENCE 3",
            "entity_type": "EVENT",
            "description": "The third sentence in a document, represented by green bars in the attention distribution graph."
        }
    ],
    "image_3": [
        {
            "entity_name": "IMAGE_3",
            "entity_type": "ORI_IMG",
            "description": "The image is a diagram illustrating the architecture of an extractor used in a neural network model for text summarization. The diagram is divided into three main layers: Word-level RNN, Sentence-level RNN, and Sentence-Level Attention. The Word-level RNN layer consists of nine GRU (Gated Recurrent Unit) blocks, each representing a word in a sentence. These blocks are connected sequentially from left to right, indicating the flow of information through the network. Each GRU block is labeled with a 'w' followed by a subscript number (e.g., w1, w2, ..., w9), representing individual words in the input sequence. The Sentence-level RNN layer contains three GRU blocks, which are connected to specific word-level GRU blocks. These connections are depicted by arrows pointing upwards from the word-level GRU blocks to the sentence-level GRU blocks. The Sentence-Level Attention layer is represented by three circles at the top of the diagram, each containing a value (0.9, 0.2, and 0.5). These values represent the attention weights assigned to each sentence by the model. The attention weights are used to determine the importance of each sentence in the overall summary. The diagram also includes dashed lines connecting the word-level GRU blocks to the corresponding sentence-level GRU blocks, indicating the flow of information between these layers. The overall architecture suggests a hierarchical approach to text summarization, where word-level information is first processed, then aggregated at the sentence level, and finally weighted using attention mechanisms to generate a summary."
        },
        {
            "entity_name": "WORD-LEVEL RNN",
            "entity_type": "ORGANIZATION",
            "description": "A recurrent neural network that processes individual words in a sentence, capturing sequential information."
        },
        {
            "entity_name": "SENTENCE-LEVEL RNN",
            "entity_type": "ORGANIZATION",
            "description": "A recurrent neural network that processes entire sentences, building on the output of the word-level RNN to understand context and meaning at a higher level."
        },
        {
            "entity_name": "GRU",
            "entity_type": "ORGANIZATION",
            "description": "Gated Recurrent Unit, a type of recurrent neural network that helps in mitigating the vanishing gradient problem and is used in both the word-level and sentence-level RNNs."
        },
        {
            "entity_name": "ATTENTION MECHANISM",
            "entity_type": "ORGANIZATION",
            "description": "A mechanism that allows the model to focus on specific parts of the input sequence, enhancing its ability to make accurate predictions by giving more weight to relevant information."
        }
    ],
    "image_4": [
        {
            "entity_name": "IMAGE_4",
            "entity_type": "ORI_IMG",
            "description": "The image is a detailed diagram illustrating the decoding mechanism in a pointer-generator network, a type of sequence-to-sequence attentional model used for text summarization. The diagram is divided into several key components: \\n\\n1. **Encoder Hidden States**: Represented by a series of vertical bars at the bottom left, these states are denoted as {h_e^1, ..., h_e^N}, indicating the hidden states generated by a bidirectional LSTM encoder from the input words. \\n2. **Decoder Hidden State**: Shown as a single vertical bar on the right side, labeled as h_d^t, representing the hidden state of the unidirectional LSTM decoder at step t. \\n3. **Context Vector**: Depicted as a single vertical bar in the center, labeled as h*(α̂^t), this vector is generated using the updated word attention α̂^t. \\n4. **Word Distribution p_vocab**: Illustrated by a series of vertical bars on the far right, this distribution represents the probability of generating words from a fixed vocabulary. \\n5. **Final Word Distribution p_final**: Shown by a series of vertical bars at the top, this distribution combines the word distribution from the vocabulary and the context vector to generate the final output. \\n6. **Updated Word Attention α̂^t**: Represented by a series of vertical bars on the left, this attention mechanism updates the context vector based on the current decoder state. \\n7. **p_gen**: A scalar value that determines the probability of generating a word from the vocabulary or copying a word from the input. \\n8. **1 - p_gen**: Another scalar value that complements p_gen, determining the probability of copying a word from the input. \\nThe arrows and connections between these components illustrate the flow of information during the decoding process. The diagram highlights how the model dynamically switches between generating words from a vocabulary and copying words from the input text, depending on the values of p_gen and 1 - p_gen."
        },
        {
            "entity_name": "CONTEXT VECTOR",
            "entity_type": "PERSON",
            "description": "A vector summarizing the context information for the current time step in the decoder, denoted as h*(α^t"
        },
        {
            "entity_name": "ENCODER HIDDEN STATES",
            "entity_type": "UNKNOWN",
            "description": "Encoder Hidden States是从image_4中提取的实体。"
        },
        {
            "entity_name": "DECODER HIDDEN STATE",
            "entity_type": "UNKNOWN",
            "description": "Decoder Hidden State是从image_4中提取的实体。"
        },
        {
            "entity_name": "UPDATED WORD ATTENTION",
            "entity_type": "UNKNOWN",
            "description": "Updated Word Attention是从image_4中提取的实体。"
        },
        {
            "entity_name": "WORD DISTRIBUTION P_VOCAB",
            "entity_type": "UNKNOWN",
            "description": "Word Distribution p_vocab是从image_4中提取的实体。"
        },
        {
            "entity_name": "FINAL WORD DISTRIBUTION P_FINAL",
            "entity_type": "UNKNOWN",
            "description": "Final Word Distribution p_final是从image_4中提取的实体。"
        }
    ],
    "image_5": [
        {
            "entity_name": "IMAGE_5",
            "entity_type": "ORI_IMG",
            "description": "The image is a table that presents ROUGE F-1 scores of the generated abstractive summaries on the CNN/Daily Mail test set. The table has four columns: Method, ROUGE-1, ROUGE-2, and ROUGE-L. The rows represent different methods used for generating summaries. The first row shows the pre-trained method with ROUGE-1 score of 73.50, ROUGE-2 score of 35.55, and ROUGE-L score of 68.57. The second row shows the end-to-end method without inconsistency loss with ROUGE-1 score of 72.97, ROUGE-2 score of 35.11, and ROUGE-L score of 67.99. The third row shows the end-to-end method with inconsistency loss with ROUGE-1 score of 78.40, ROUGE-2 score of 39.45, and ROUGE-L score of 73.83. The last row shows the ground-truth labels with ROUGE-1 score of 89.23, ROUGE-2 score of 49.36, and ROUGE-L score of 85.46. The table highlights the performance of different methods in generating abstractive summaries."
        },
        {
            "entity_name": "METHOD",
            "entity_type": "EVENT",
            "description": "The different methods used for evaluating the ROUGE scores, including pre-trained, end2end without inconsistency loss, end2end with inconsistency loss, and ground-truth labels."
        },
        {
            "entity_name": "ROUGE-1",
            "entity_type": "ORGANIZATION",
            "description": "A metric used to evaluate the quality of text summaries by comparing a generated summary against reference summaries. It measures the overlap of unigrams between the candidate and reference texts."
        },
        {
            "entity_name": "ROUGE-2",
            "entity_type": "ORGANIZATION",
            "description": "Similar to ROUGE-1 but measures the overlap of bigrams instead of unigrams."
        },
        {
            "entity_name": "ROUGE-L",
            "entity_type": "ORGANIZATION",
            "description": "An evaluation metric that uses the longest common subsequence (LCS) between the candidate and reference texts to measure the quality of a summary."
        }
    ],
    "image_6": [
        {
            "entity_name": "IMAGE_6",
            "entity_type": "ORI_IMG",
            "description": "The image is a table that presents ROUGE F-1 scores of various abstractive summarization methods on the CNN/Daily Mail test set. The table has four columns: Method, ROUGE-1, ROUGE-2, and ROUGE-L. Each row represents a different method and its corresponding ROUGE scores. The methods listed are HierAttn (Nallapati et al., 2016b), DeepRL (Paulus et al., 2017), pointer-generator (See et al., 2017), GAN (Liu et al., 2017), two-stage (ours), end2end w/o inconsistency loss (ours), end2end w/ inconsistency loss (ours), and lead-3 (See et al., 2017). The ROUGE-1 scores range from 32.75 to 40.68, with the highest score achieved by the end2end w/ inconsistency loss model. The ROUGE-2 scores range from 12.21 to 17.97, with the highest score also achieved by the end2end w/ inconsistency loss model. The ROUGE-L scores range from 29.01 to 37.13, with the highest score again achieved by the end2end w/ inconsistency loss model. The table highlights the performance of the two-stage and end2end models developed by the authors, which outperform other baseline models."
        },
        {
            "entity_name": "HIERATTN (NALLAPATI ET AL., 2016B)*",
            "entity_type": "ORGANIZATION",
            "description": "A method for text summarization that uses hierarchical attention mechanisms. It achieved ROUGE-1 of 32.75, ROUGE-2 of 12.21, and ROUGE-L of 29.01."
        },
        {
            "entity_name": "DEEPRL (PAULUS ET AL., 2017)*",
            "entity_type": "ORGANIZATION",
            "description": "A reinforcement learning-based method for text summarization. It achieved ROUGE-1 of 39.87, ROUGE-2 of 15.82, and ROUGE-L of 36.90."
        },
        {
            "entity_name": "POINTER-GENERATOR (SEE ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A neural network model for text summarization that combines a pointer mechanism with a generator. It achieved ROUGE-1 of 39.53, ROUGE-2 of 17.28, and ROUGE-L of 36.38."
        },
        {
            "entity_name": "GAN (LIU ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A generative adversarial network-based method for text summarization. It achieved ROUGE-1 of 39.92, ROUGE-2 of 17.65, and ROUGE-L of 36.71."
        },
        {
            "entity_name": "TWO-STAGE (OURS)",
            "entity_type": "ORGANIZATION",
            "description": "Our two-stage method for text summarization. It achieved ROUGE-1 of 39.97, ROUGE-2 of 17.43, and ROUGE-L of 36.34."
        },
        {
            "entity_name": "END2END W/O INCONSISTENCY LOSS (OURS)",
            "entity_type": "ORGANIZATION",
            "description": "Our end-to-end method for text summarization without inconsistency loss. It achieved ROUGE-1 of 40.19, ROUGE-2 of 17.67, and ROUGE-L of 36.68."
        },
        {
            "entity_name": "END2END W/ INCONSISTENCY LOSS (OURS)",
            "entity_type": "ORGANIZATION",
            "description": "Our end-to-end method for text summarization with inconsistency loss. It achieved ROUGE-1 of 40.68, ROUGE-2 of 17.97, and ROUGE-L of 37.13."
        },
        {
            "entity_name": "LEAD-3 (SEE ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A baseline method for text summarization that selects the first three sentences of a document as the summary. It achieved ROUGE-1 of 40.34, ROUGE-2 of 17.70, and ROUGE-L of 36.57."
        }
    ],
    "image_7": [
        {
            "entity_name": "IMAGE_7",
            "entity_type": "ORI_IMG",
            "description": "The image is a table comparing different methods for summarization based on three criteria: informativity, conciseness, and readability. The rows represent different methods: DeepRL (Paulus et al., 2017), pointer-generator (See et al., 2017), GAN (Liu et al., 2017), Ours, and reference. The columns represent the evaluation criteria with their respective scores. For informativity, the scores are as follows: DeepRL has 3.23, pointer-generator has 3.18, GAN has 3.22, Ours has 3.58, and reference has 3.43. For conciseness, the scores are: DeepRL has 2.97, pointer-generator has 3.36, GAN has 3.52, Ours has 3.40, and reference has 3.61. For readability, the scores are: DeepRL has 2.85, pointer-generator has 3.47, GAN has 3.51, Ours has 3.70, and reference has 3.62. The 'Ours' method outperforms the others in informativity and readability, while the reference has the highest score in conciseness."
        },
        {
            "entity_name": "DEEPRL (PAULUS ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A method developed by Paulus et al. in 2017, with scores of 3.23 for informativity, 2.97 for conciseness, and 2.85 for readability."
        },
        {
            "entity_name": "POINTER-GENERATOR (SEE ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A method developed by See et al. in 2017, with scores of 3.18 for informativity, 3.36 for conciseness, and 3.47 for readability."
        },
        {
            "entity_name": "GAN (LIU ET AL., 2017)",
            "entity_type": "ORGANIZATION",
            "description": "A method developed by Liu et al. in 2017, with scores of 3.22 for informativity, 3.52 for conciseness, and 3.51 for readability."
        },
        {
            "entity_name": "OURS",
            "entity_type": "ORGANIZATION",
            "description": "Our method, with scores of 3.58 for informativity, 3.40 for conciseness, and 3.70 for readability."
        },
        {
            "entity_name": "REFERENCE",
            "entity_type": "ORGANIZATION",
            "description": "The reference method, with scores of 3.43 for informativity, 3.61 for conciseness, and 3.62 for readability."
        }
    ],
    "image_8": [
        {
            "entity_name": "IMAGE_8",
            "entity_type": "ORI_IMG",
            "description": "The image is a table labeled 'Table 4: Inconsistency rate of our end-to-end trained model with and without inconsistency loss.' The table has two rows and two columns. The first column is labeled 'Method' and the second column is labeled 'avg. $R_{inc}$'. The first row under 'Method' is 'w/o incon. loss' with a corresponding value of 0.198 in the 'avg. $R_{inc}$' column. The second row under 'Method' is 'w/ incon. loss' with a corresponding value of 0.042 in the 'avg. $R_{inc}$' column. The table highlights the significant reduction in the average inconsistency rate ($R_{inc}$) when the model is trained with inconsistency loss compared to when it is trained without."
        },
        {
            "entity_name": "TABLE",
            "entity_type": "OBJECT",
            "description": "A table displaying the average \\( R_{inc} \\) values for two methods: one without incon. loss and one with incon. loss."
        },
        {
            "entity_name": "METHOD W/O INCON. LOSS",
            "entity_type": "ORGANIZATION",
            "description": "A method that does not include incon. loss, resulting in an average \\( R_{inc} \\) of 0.198."
        },
        {
            "entity_name": "METHOD W/ INCON. LOSS",
            "entity_type": "ORGANIZATION",
            "description": "A method that includes incon. loss, resulting in an average \\( R_{inc} \\) of 0.042."
        }
    ],
    "image_9": [
        {
            "entity_name": "IMAGE_9",
            "entity_type": "ORI_IMG",
            "description": "The image is a text excerpt comparing two versions of a news article summary, one with inconsistency loss and one without. The text discusses a tornado event near Dallas, Texas, where a photo was taken by Ryan Shepard showing a large black cloud formation reaching the ground. Jamie Moore, head of emergency management in Johnson County, Texas, provides an estimate of the tornado's width. The National Weather Service warned about severe thunderstorms in the area, causing street flooding. The text highlights the differences in detail and accuracy between the summaries with and without inconsistency loss. The version with inconsistency loss contains highlighted words (in red bold font) indicating inconsistent fragments."
        },
        {
            "entity_name": "RYAN SHEPARD",
            "entity_type": "PERSON",
            "description": "Snapped a photo of a black cloud formation reaching down to the ground and said it was a tornado."
        },
        {
            "entity_name": "JAMIE MOORE",
            "entity_type": "PERSON",
            "description": "Head of emergency management in Johnson County, Texas who estimated the tornado to be more like a mile wide."
        },
        {
            "entity_name": "NATIONAL WEATHER SERVICE",
            "entity_type": "ORGANIZATION",
            "description": "Warned about severe thunderstorms causing street flooding in the area."
        },
        {
            "entity_name": "JOHNSON COUNTY, TEXAS",
            "entity_type": "GEO",
            "description": "Location where Jamie Moore is the head of emergency management."
        },
        {
            "entity_name": "DALLAS",
            "entity_type": "GEO",
            "description": "City near which tornadoes touched down on Sunday."
        },
        {
            "entity_name": "TORNADO",
            "entity_type": "UNKNOWN",
            "description": "Ryan Shepard snapped a photo of a black cloud formation reaching down to the ground and said it was a tornado."
        },
        {
            "entity_name": "SEVERE THUNDERSTORMS",
            "entity_type": "UNKNOWN",
            "description": "The National Weather Service warned about severe thunderstorms drenching the area, causing street flooding."
        }
    ]
}