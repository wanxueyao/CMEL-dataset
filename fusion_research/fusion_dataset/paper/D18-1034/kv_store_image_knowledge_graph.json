{
    "image_1": [
        {
            "entity_name": "IMAGE_1",
            "entity_type": "ORI_IMG",
            "description": "The image consists of two scatter plots side by side, illustrating the projection of word embeddings from Spanish to English. The left plot shows the initial distribution of word embeddings in a 2-dimensional space, with words labeled in both Spanish (red dots) and English (blue dots). Words such as 'mezclas', 'habilidades', 'trastorno', 'angry', 'encounter', and 'disorder' are scattered across the plot. The right plot depicts the result after projecting these embeddings into a shared space. Here, the words are more closely aligned, indicating improved alignment for translation purposes. A red box highlights the nearest neighbor relationship between 'trastorno' (Spanish) and 'disorder' (English), demonstrating the effectiveness of the projection method. To the right of the plots, a table lists the translations of selected words, including 'disorder' and 'recognize' in English and their Spanish counterparts 'trastorno' and 'reconocer'. The overall layout and content suggest a focus on cross-lingual word embedding alignment for translation tasks."
        },
        {
            "entity_name": "PROJECTION DIAGRAM",
            "entity_type": "EVENT",
            "description": "A diagram showing the projection of words from one language to another, with a focus on finding the nearest neighbor for translation."
        },
        {
            "entity_name": "TRANSLATION TABLE",
            "entity_type": "OBJECT",
            "description": "A table listing English and Spanish translations of specific words, such as 'disorder' and 'trastorno'."
        }
    ],
    "image_2": [
        {
            "entity_name": "IMAGE_2",
            "entity_type": "ORI_IMG",
            "description": "The image is a detailed diagram of a Self-attentive Bi-LSTM-CRF Model used for Named Entity Recognition (NER). The diagram is structured in a hierarchical manner, starting from the bottom with character-level inputs and progressing to the CRF layer at the top. At the bottom, there are characters 'S', 'a', 'n' representing parts of the word 'San'. These characters are fed into a Char Bi-LSTM layer, which processes them sequentially. Above this, there is a Word Embedding layer that takes the word 'flights' as input. This word embedding is then passed through a Word Bi-LSTM layer, which captures the sequential information of the words. The output of the Word Bi-LSTM layer is then fed into a Masked Self-attention mechanism, which allows the model to focus on relevant parts of the input sequence. The output of the self-attention mechanism is combined with global context information and fed into an LSTM Output layer. Finally, the output of this layer is passed to the CRF Layer, which assigns labels to each word. In this case, the labels are 'O', 'O', 'B-LOC', and 'I-LOC', indicating the start and continuation of a location entity. The diagram uses circles and rectangles to represent different layers and arrows to indicate the flow of information. The colors used are primarily orange for the embeddings and outputs, and gray for the layers and labels."
        },
        {
            "entity_name": "CRF LAYER",
            "entity_type": "ORGANIZATION",
            "description": "A Conditional Random Field (CRF) layer used for sequence labeling tasks, specifically for identifying the beginning and inside of location entities in a sequence."
        },
        {
            "entity_name": "GLOBAL CONTEXT",
            "entity_type": "EVENT",
            "description": "The global context is a feature that captures information from the entire input sequence, which is then fed into the CRF layer to improve the model's performance."
        },
        {
            "entity_name": "LSTM OUTPUT",
            "entity_type": "ORGANIZATION",
            "description": "The output of the Long Short-Term Memory (LSTM) network, which processes the input sequence and generates a sequence of hidden states."
        },
        {
            "entity_name": "MASKED SELF-ATTENTION",
            "entity_type": "ORGANIZATION",
            "description": "A mechanism used to focus on specific parts of the input sequence, allowing the model to selectively attend to relevant information."
        },
        {
            "entity_name": "WORD BI-LSTM",
            "entity_type": "ORGANIZATION",
            "description": "A bidirectional LSTM network that processes word-level embeddings, capturing both past and future context for each word in the sequence."
        },
        {
            "entity_name": "WORD EMBEDDING",
            "entity_type": "ORGANIZATION",
            "description": "A representation of words as dense vectors, where similar words are mapped to nearby points in space."
        },
        {
            "entity_name": "CHAR EMBEDDING",
            "entity_type": "ORGANIZATION",
            "description": "A representation of characters as dense vectors, used to capture subword information and handle out-of-vocabulary words."
        },
        {
            "entity_name": "CHAR BI-LSTM",
            "entity_type": "ORGANIZATION",
            "description": "A bidirectional LSTM network that processes character-level embeddings, capturing both past and future context for each character in the sequence."
        }
    ],
    "image_3": [
        {
            "entity_name": "IMAGE_3",
            "entity_type": "ORI_IMG",
            "description": "The image is a table labeled 'Table 1: NER $F_{1}$ scores' that provides comparative results for Named Entity Recognition (NER) across different models and languages. The table is structured with the following columns: Model, Spanish, Dutch, German, and Extra Resources. Each row represents a different model or method used for NER. The rows include various models such as Täckström et al. (2012), Nothman et al. (2013), Tsai et al. (2016), Ni et al. (2017), Mayhew et al. (2017), and our methods. The values in the Spanish, Dutch, and German columns represent the $F_{1}$ scores for each model in these respective languages. For example, Täckström et al. (2012) has an $F_{1}$ score of 59.30 for Spanish, 58.40 for Dutch, and 40.40 for German. Our methods are listed at the bottom with their respective $F_{1}$ scores and standard deviations. The footnote indicates that approaches marked with an asterisk (*) use more resources than ours, and those marked with a dagger (†) use multiple languages for transfer. The context discusses the challenges in cross-lingual settings and the comparison with dictionary-based translation."
        },
        {
            "entity_name": "TÄCKSTRÖM ET AL. (2012)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a paper in 2012, using a parallel corpus for their work."
        },
        {
            "entity_name": "NOTHMAN ET AL. (2013)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a paper in 2013, utilizing Wikipedia as an extra resource."
        },
        {
            "entity_name": "TSAI ET AL. (2016)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a paper in 2016, also using Wikipedia as an extra resource."
        },
        {
            "entity_name": "NI ET AL. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a paper in 2017, leveraging Wikipedia, a parallel corpus, and a 5K dictionary."
        },
        {
            "entity_name": "MAYHEW ET AL. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a paper in 2017, using Wikipedia and a 1M dictionary."
        },
        {
            "entity_name": "MAYHEW ET AL. (2017) (ONLY ENG. DATA)",
            "entity_type": "ORGANIZATION",
            "description": "A subset of the Mayhew et al. (2017) research group's work, focusing only on English data with a 1M dictionary."
        },
        {
            "entity_name": "BWET (ID.C.)",
            "entity_type": "ORGANIZATION",
            "description": "A method developed by our team, achieving scores of 71.14 ± 0.60 for Spanish, 70.24 ± 1.18 for Dutch, and 57.03 ± 0.25 for German."
        },
        {
            "entity_name": "BWET (ID.C.) + SELF-ATT.",
            "entity_type": "ORGANIZATION",
            "description": "An enhanced version of BWET (id.c.), incorporating self-attention, achieving higher scores across all languages."
        },
        {
            "entity_name": "BWET (ADV.)",
            "entity_type": "ORGANIZATION",
            "description": "Another method developed by our team, achieving scores of 70.54 ± 0.85 for Spanish, 70.13 ± 1.04 for Dutch, and 55.71 ± 0.47 for German."
        },
        {
            "entity_name": "BWET (ADV.) + SELF-ATT.",
            "entity_type": "ORGANIZATION",
            "description": "An enhanced version of BWET (adv.), incorporating self-attention, achieving higher scores across all languages."
        },
        {
            "entity_name": "BWET",
            "entity_type": "ORGANIZATION",
            "description": "A baseline method developed by our team, achieving scores of 71.33 ± 1.26 for Spanish, 69.39 ± 0.53 for Dutch, and 56.95 ± 1.20 for German."
        },
        {
            "entity_name": "BWET + SELF-ATT.",
            "entity_type": "ORGANIZATION",
            "description": "An enhanced version of BWET, incorporating self-attention, achieving higher scores across all languages."
        },
        {
            "entity_name": "BWET ON DATA FROM MAYHEW ET AL. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "Our method applied to the dataset used by Mayhew et al. (2017), achieving scores of 66.53 ± 1.12 for Spanish, 69.24 ± 0.66 for Dutch, and 55.39 ± 0.98 for German."
        },
        {
            "entity_name": "BWET + SELF-ATT. ON DATA FROM MAYHEW ET AL. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "An enhanced version of BWET on the dataset used by Mayhew et al. (2017), incorporating self-attention, achieving higher scores across all languages."
        },
        {
            "entity_name": "OUR SUPERVISED RESULTS",
            "entity_type": "ORGANIZATION",
            "description": "The best performance achieved by our team using a supervised approach, achieving scores of 86.26 ± 0.40 for Spanish, 86.40 ± 0.17 for Dutch, and 78.16 ± 0.45 for German."
        }
    ],
    "image_4": [
        {
            "entity_name": "IMAGE_4",
            "entity_type": "ORI_IMG",
            "description": "The image is a table that presents NER (Named Entity Recognition) F1 scores for different models applied to Spanish, Dutch, and German languages. The table has four rows and four columns. The first row serves as the header, listing the languages: 'Spanish', 'Dutch', and 'German'. The subsequent rows are labeled 'Common space', 'Replace', and 'Translation'. Each cell contains a numerical value representing the F1 score along with its standard deviation. Specifically, for Spanish, the scores are 65.40 ± 1.22 for 'Common space', 68.21 ± 1.22 for 'Replace', and 69.21 ± 0.95 for 'Translation'. For Dutch, the scores are 66.15 ± 1.62 for 'Common space', 69.37 ± 1.33 for 'Replace', and 69.39 ± 1.21 for 'Translation'. For German, the scores are 43.73 ± 0.94 for 'Common space', 48.59 ± 1.21 for 'Replace', and 53.94 ± 0.66 for 'Translation'. The highest scores for each language are highlighted in bold."
        },
        {
            "entity_name": "MODEL",
            "entity_type": "ORGANIZATION",
            "description": "A table comparing different models for language processing across Spanish, Dutch, and German."
        },
        {
            "entity_name": "SPANISH",
            "entity_type": "GEO",
            "description": "The first column of data representing performance metrics for the Spanish language."
        },
        {
            "entity_name": "DUTCH",
            "entity_type": "GEO",
            "description": "The second column of data representing performance metrics for the Dutch language."
        },
        {
            "entity_name": "GERMAN",
            "entity_type": "GEO",
            "description": "The third column of data representing performance metrics for the German language."
        },
        {
            "entity_name": "COMMON SPACE",
            "entity_type": "EVENT",
            "description": "The first row of data representing a model where all languages are processed in a common space."
        },
        {
            "entity_name": "REPLACE",
            "entity_type": "EVENT",
            "description": "The second row of data representing a model where one language is replaced by another."
        },
        {
            "entity_name": "TRANSLATION",
            "entity_type": "EVENT",
            "description": "The third row of data representing a model where translation is used between languages."
        }
    ],
    "image_5": [
        {
            "entity_name": "IMAGE_5",
            "entity_type": "ORI_IMG",
            "description": "The image is a table labeled 'Table 2: Comparison of different ways of using bilingual word embeddings, within our method (NER $F_{1}$ )'. The table compares various models and their performance on the Uyghur Unsequestered Set. The columns are as follows: Model, Uyghur Unsequestered Set, and Extra Resources. The rows list different models and their corresponding scores. The first row shows Mayhew et al. (2017) with a score of 51.32 and extra resources listed as Wikipedia, 100K dict. The second row shows Mayhew et al. (2017) (only Eng. data) with a score of 27.20 and the same extra resources. The third row lists BWET with a score of 25.73 ± 0.89 and extra resources listed as 5K dict. The fourth row lists BWET + self-att. with a score of 26.38 ± 0.34 and the same extra resources. The fifth row lists BWET on data from Mayhew et al. (2017) with a score of 30.20 ± 0.98 and extra resources listed as Wikipedia, 100K dict. The sixth row lists BWET + self-att. on data from Mayhew et al. (2017) with a score of 30.68 ± 0.45 and the same extra resources. The seventh row lists Combined (see text) with a score of 31.61 ± 0.46 and extra resources listed as Wikipedia, 100K dict., 5K dict. The eighth row lists Combined + self-att. with a score of 32.09 ± 0.61 and the same extra resources."
        },
        {
            "entity_name": "MAYHEW ET AL. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "A research group that published a study in 2017, achieving the highest score of 51.32 on the Cygnar Unsequestered Set."
        },
        {
            "entity_name": "MAYHEW ET AL. (2017) (ONLY ENG. DATA)",
            "entity_type": "ORGANIZATION",
            "description": "A subset of the research group Mayhew et al. (2017) that used only English data, achieving a score of 27.20 on the Cygnar Unsequestered Set."
        },
        {
            "entity_name": "BWET",
            "entity_type": "ORGANIZATION",
            "description": "An organization or model that achieved a score of 25.73 ± 0.89 on the Cygnar Unsequestered Set using a 5K dictionary."
        },
        {
            "entity_name": "BWET + SELF-ATT.",
            "entity_type": "ORGANIZATION",
            "description": "An enhanced version of BWET with self-attention mechanisms, achieving a score of 26.38 ± 0.34 on the Cygnar Unsequestered Set using a 5K dictionary."
        },
        {
            "entity_name": "CYGNAR UNSEQUESTERED SET",
            "entity_type": "EVENT",
            "description": "A benchmark dataset used to evaluate the performance of different models and methods."
        },
        {
            "entity_name": "WIKIPEDIA",
            "entity_type": "ORGANIZATION",
            "description": "An online encyclopedia used as an extra resource for some of the models."
        },
        {
            "entity_name": "100K DICT.",
            "entity_type": "OBJECT",
            "description": "A dictionary containing 100,000 entries used as an extra resource for some of the models."
        },
        {
            "entity_name": "5K DICT.",
            "entity_type": "OBJECT",
            "description": "A dictionary containing 5,000 entries used as an extra resource for some of the models."
        }
    ]
}