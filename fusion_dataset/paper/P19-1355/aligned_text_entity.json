{
    "image_1": [
    ],
    "image_2": [
        {
            "entity_name": "NLP PIPELINE (PARSING, SRL)",
            "entity_type": "ORGANIZATION",
            "description": "A computational framework used for natural language processing tasks including parsing and semantic role labeling. It is noted to have a complexity score of 39. This framework is central to the paper's discussion on energy and policy considerations for deep learning in NLP.",
            "source_image_entities": [
                "NLP PIPELINE (PARSING, SRL)"
            ],
            "source_text_entities": [
                "NLP"
            ]
        }
    ],
    "image_3": [
        {
            "entity_name": "CHINA",
            "entity_type": "GEO",
            "description": "China is a country compared in terms of energy sources in the context of cloud computing.",
            "source_image_entities": [
                "CHINA"
            ],
            "source_text_entities": [
                "CHINA"
            ]
        },
        {
            "entity_name": "GERMANY",
            "entity_type": "GEO",
            "description": "Germany is a country compared in terms of energy sources in the context of cloud computing.",
            "source_image_entities": [
                "GERMANY"
            ],
            "source_text_entities": [
                "GERMANY"
            ]
        },
        {
            "entity_name": "UNITED STATES",
            "entity_type": "GEO",
            "description": "The United States is a country compared in terms of energy sources and CO2 emissions in the context of cloud computing.",
            "source_image_entities": [
                "UNITED STATES"
            ],
            "source_text_entities": [
                "UNITED STATES"
            ]
        },
        {
            "entity_name": "AMAZON-AWS",
            "entity_type": "ORGANIZATION",
            "description": "Amazon Web Services is a cloud compute service provider, and its energy breakdown is compared to that of the United States.",
            "source_image_entities": [
                "AMAZON-AWS"
            ],
            "source_text_entities": [
                "AMAZON WEB SERVICES"
            ]
        }
    ],
    "image_4": [
        {
            "merged_entity_name": "GPT-2 MODEL",
            "entity_type": "MODEL",
            "description": "GPT-2 is OpenAIâ€™s latest edition of GPT general-purpose token encoder, trained with a language modeling objective and based on Transformer-style self-attention. It requires 1 week (168 hours) of training on 32 TPUv3 chips and incurs a cloud compute cost ranging from $12,902 to $43,008.",
            "source_image_entities": [
                "GPT-2"
            ],
            "source_text_entities": [
                "GPT-2 MODEL"
            ]
        },
        {
            "merged_entity_name": "BERT BASE MODEL",
            "entity_type": "MODEL",
            "description": "The BERT BASE model provides a Transformer-based architecture for building contextual representations. It uses TPUv2x16 hardware, runs for 96 hours, and incurs a cloud compute cost ranging from $2074 to $6912. Additionally, it uses V100x64 hardware, consumes 12,041.51 watts of power, runs for 79 hours, generates 1507 kWh of energy, emits 1438 kg of CO2, and incurs a cloud compute cost ranging from $3751 to $12,571.",
            "source_image_entities": [
                "BERT_BASE"
            ],
            "source_text_entities": [
                "BERT MODEL"
            ]
        },
        {
            "merged_entity_name": "ELMO MODEL",
            "entity_type": "MODEL",
            "description": "The ELMo model is based on stacked LSTMs and provides word representations in context. It uses P100x3 hardware, consumes 517.66 watts of power, runs for 336 hours, generates 275 kWh of energy, emits 262 kg of CO2, and incurs a cloud compute cost ranging from $433 to $1472.",
            "source_image_entities": [
                "ELMO"
            ],
            "source_text_entities": [
                "ELMO MODEL"
            ]
        },
        {
            "merged_entity_name": "TRANSFORMER (T2T) MODEL",
            "entity_type": "MODEL",
            "description": "The Transformer (T2T) model is an encoder-decoder architecture recognized for machine translation. T2T_BASE uses P100x8 hardware, consumes 1415.78 watts of power, runs for 12 hours, generates 27 kWh of energy, emits 26 kg of CO2, and incurs a cloud compute cost ranging from $41 to $140. T2T_BIG uses P100x8 hardware, consumes 1515.43 watts of power, runs for 84 hours, generates 201 kWh of energy, emits 192 kg of CO2, and incurs a cloud compute cost ranging from $289 to $981.",
            "source_image_entities": [
                "T2T_BASE",
                "T2T_BIG"
            ],
            "source_text_entities": [
                "TRANSFORMER (T2T) MODEL"
            ]
        },
        {
            "merged_entity_name": "NAS MODEL",
            "entity_type": "MODEL",
            "description": "NAS (Neural Architecture Search) achieves a new state-of-the-art BLEU score of 29.7 for English to German machine translation. It uses P100x8 hardware, consumes 1515.43 watts of power, runs for 274,120 hours, generates 656,347 kWh of energy, emits 626,155 kg of CO2, and incurs a cloud compute cost ranging from $942,973 to $3,201,722. Additionally, it uses TPUv2x1 hardware, runs for 32,623 hours, and incurs a cloud compute cost ranging from $44,055 to $146,848.",
            "source_image_entities": [
                "NAS"
            ],
            "source_text_entities": [
                "NAS"
            ]
        }
    ],
    "image_5": [
    ]
}