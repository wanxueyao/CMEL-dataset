{
    "image_1": [
    ],
    "image_2": [
        {
            "merged_entity_name": "SAROYEHUN SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "The saroyehun system participated in the shared task, utilizing LSTM and translation for data augmentation. It also used a combination of RNN and CNN representations along with additional preprocessing like spelling correction, translation of emoji, and computation of sentiment score for the best performance on the Twitter dataset.",
            "source_image_entities": [
                "SAROYEHUN"
            ],
            "source_text_entities": [
                "SAROYEHUN SYSTEM"
            ]
        },
        {
            "merged_entity_name": "EBSI-LIA-UNAM SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "The EBSI-LIA-UNAM system participated in the shared task, using a combination of Passive-Aggressive and SVM classifiers with character-based n-gram (1-5 grams) TF-IDF for feature representation.",
            "source_image_entities": [
                "EBSI-LIA-UNAM"
            ],
            "source_text_entities": [
                "EBSI-LIA-UNAM SYSTEM"
            ]
        },
        {
            "merged_entity_name": "DA-LD-HILDESHEIM SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "DA-LD-Hildesheim participated in the shared task, using LSTM with pretrained Fasttext vector for embeddings for classifying English Facebook texts. For other datasets, CNN performed better.",
            "source_image_entities": [
                "DA-LD-HILDESHEIM"
            ],
            "source_text_entities": [
                "DA-LD-HILDESHEIM"
            ]
        },
        {
            "merged_entity_name": "TAKELAB SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "TakeLab participated in the shared task, using a Bidirectional LSTM on Glove embeddings to achieve the best performance.",
            "source_image_entities": [
                "TAKELAB"
            ],
            "source_text_entities": [
                "TAKELAB"
            ]
        },
        {
            "merged_entity_name": "SREEIN SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "The sreeIN system participated in the shared task, using a voting-based ensemble method with 3 classifiers - CNN with 4 layers, LSTM, and Bidirectional LSTM.",
            "source_image_entities": [
                "SREEIN"
            ],
            "source_text_entities": [
                "SREEIN SYSTEM"
            ]
        },
        {
            "merged_entity_name": "JULIAN TEAM",
            "entity_type": "ORGANIZATION",
            "description": "The Julian team participated in the shared task, using translation for data augmentation and an ensemble of TF-IDF based approaches, using character n-grams (2-6) and word n-grams (1-2) with a bi-directional RNN, using fasttext embeddings, to achieve the best performance in the task.",
            "source_image_entities": [
                "JULIAN"
            ],
            "source_text_entities": [
                "JULIAN TEAM"
            ]
        },
        {
            "merged_entity_name": "TARAKA RAMA SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "Taraka rama participated in the shared task, using different systems for different datasets and various machine learning techniques, including a stacked ensemble classifier for English Facebook dataset and Hindi Twitter dataset, and a plain SVM for Hindi Facebook and English Twitter dataset.",
            "source_image_entities": [
                "TARAKA_RAMA"
            ],
            "source_text_entities": [
                "TARAKA RAMA"
            ]
        },
        {
            "merged_entity_name": "UOTTAWA SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "The uOttawa system participated in the shared task, using a novel deep-learning architecture for text classification based on Multi-task learning (MTL). The approach, MTL, was evaluated using three neural network models, with MultiCNN giving the best performance.",
            "source_image_entities": [
                "UOTTAWA"
            ],
            "source_text_entities": [
                "UOTTAWA SYSTEM"
            ]
        },
        {
            "merged_entity_name": "ISISTANITOS SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "The Isistanitos system participated in the shared task, using a soft voting (average the class probabilities of other models) of two models - a recurrent neural network and an SVM.",
            "source_image_entities": [
                "ISISTANTITOS"
            ],
            "source_text_entities": [
                "ISISTANITOS SYSTEM"
            ]
        }
    ],
    "image_3": [],
    "image_4": [
        {
            "entity_name": "DATAGEEKS SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "DataGeeks system, represented by the fifth bar in the chart for Twitter performance, uses Logistic Regression classifier with preprocessing for text classification.",
            "source_image_entities": [
                "DATAGEEKS"
            ],
            "source_text_entities": [
                "DATAGEEKS SYSTEM"
            ]
        },
        {
            "entity_name": "NA14",
            "entity_type": "ORGANIZATION",
            "description": "NA14, represented by the second bar in the chart for Twitter performance, uses Logistic Regression classifier with preprocessing for text classification.",
            "source_image_entities": [
                "NA14"
            ],
            "source_text_entities": [
                "NA14"
            ]
        },
        {
            "entity_name": "VISTA.UE SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "VISTA.UE system, represented by the third bar in the chart for Twitter performance, is developed using dense neural networks.",
            "source_image_entities": [
                "VISTA.UE"
            ],
            "source_text_entities": [
                "VISTA.UE SYSTEM"
            ]
        },
        {
            "entity_name": "QUINE SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "Quine system, represented by the fourth bar in the chart for Twitter performance, is trained using an LSTM with attention and simple embeddings.",
            "source_image_entities": [
                "QUINE"
            ],
            "source_text_entities": [
                "QUINE SYSTEM"
            ]
        },
        {
            "entity_name": "MANITBHOPALINDIA SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "MANITBHOPALINDIA system, represented by the tenth bar in the chart for Twitter performance, uses SVM for English and deep neural networks for English text classification.",
            "source_image_entities": [
                "MANITBHOPALINDIA"
            ],
            "source_text_entities": [
                "MANITBHOPALINDIA SYSTEM"
            ]
        },
        {
            "entity_name": "RESHAM SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "RESHAM system, represented by the seventh bar in the chart for Twitter performance, for English has been made using an open vocabulary approach and ensemble model.",
            "source_image_entities": [
                "RESHAM"
            ],
            "source_text_entities": [
                "RESHAM SYSTEM"
            ]
        },
        {
            "entity_name": "NESTOR",
            "entity_type": "ORGANIZATION",
            "description": "Nestor, represented by the eleventh bar in the chart for Twitter performance, uses an approach that combines Neural Networks and a new word representation model.",
            "source_image_entities": [
                "NESTOR"
            ],
            "source_text_entities": [
                "NESTOR"
            ]
        },
        {
            "entity_name": "UAEMEX-UAPT1",
            "entity_type": "ORGANIZATION",
            "description": "UAEMex-UAPT1, represented by the twelfth bar in the chart for Twitter performance, uses the same approach as used by the team Nestor.",
            "source_image_entities": [
                "UAEMEX-UAPT1"
            ],
            "source_text_entities": [
                "UAEMEX-UAPT1"
            ]
        },
        {
            "entity_name": "SHUSRUT SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "Shusrut system, represented by the ninth bar in the chart for Twitter performance, uses an ensemble of CNN 2D with MAXPOOL classifier and a SVM classifier.",
            "source_image_entities": [
                "SHUSRUT"
            ],
            "source_text_entities": [
                "SHUSRUT SYSTEM"
            ]
        },
        {
            "entity_name": "PMRS SYSTEM",
            "entity_type": "ORGANIZATION",
            "description": "PMRS system, represented by the fourteenth bar in the chart for Twitter performance, employs a winner-takes-all autoencoder for Twitter sentiment classification.",
            "source_image_entities": [
                "PMRS"
            ],
            "source_text_entities": [
                "PMRS SYSTEM"
            ]
        },
        {
            "entity_name": "UNITO",
            "entity_type": "ORGANIZATION",
            "description": "Unito, represented by the fifteenth bar in the chart for Twitter performance, is the only unsupervised system submitted, based on a multilingual lexicon of aggressive words.",
            "source_image_entities": [
                "UNITO"
            ],
            "source_text_entities": [
                "UNITO"
            ]
        }
    ]
}