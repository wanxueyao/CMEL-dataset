<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_4&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image is a table labeled 'Table 2: Test results as per the GLUE evaluation server.' The table presents the performance of various models on different natural language processing tasks. The columns represent different datasets and metrics, including CoLA (Matthews correlation), SST-2 (Accuracy), MRPC (F1 score), STS-B (Spearman correlation), QQP (F1 score), MNLI-m/mm (Accuracy), QNLI (Accuracy), RTE (Accuracy), and an average score. The rows list different models: OpenAI GPT, CNN Base, CNN Large, BPE Large, GPT on STILTs, BERT_BASE, and BERT_LARGE. Each cell contains a numerical value representing the model's performance on the respective task. For example, the OpenAI GPT scores 45.4 on CoLA, 91.3 on SST-2, 82.3 on MRPC, 80.0 on STS-B, 70.3 on QQP, 82.1/81.4 on MNLI-m/mm, 88.1 on QNLI, and 56.0 on RTE, with an average score of 75.2. The BERT_LARGE model performs the best overall, scoring 60.5 on CoLA, 94.9 on SST-2, 89.3 on MRPC, 86.5 on STS-B, 72.1 on QQP, 86.7/85.9 on MNLI-m/mm, 91.1 on QNLI, and 70.1 on RTE, with an average score of 81.9."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;OPENAI GPT&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A model developed by OpenAI, showcasing performance across various NLP tasks including CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, and RTE."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;CNN BASE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A Convolutional Neural Network model with base configuration, evaluated on multiple NLP benchmarks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;CNN LARGE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A Convolutional Neural Network model with a larger configuration, demonstrating performance on several NLP tasks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;BPE LARGE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A Byte Pair Encoding model with a large configuration, assessed on various NLP datasets."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;GPT ON STILTS&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A variant of the GPT model, tested on different NLP challenges including CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, and RTE."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;BERT_BASE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"The base version of the BERT model, evaluated on multiple NLP benchmarks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<node id="&quot;BERT_LARGE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"The large version of the BERT model, showing performance across various NLP tasks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
</node>
<edge source="&quot;IMAGE_4&quot;" target="&quot;OPENAI GPT&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"OpenAI GPT是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;CNN BASE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CNN Base是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;CNN LARGE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CNN Large是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;BPE LARGE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"BPE Large是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;GPT ON STILTS&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"GPT on STILTs是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;BERT_BASE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"BERT_BASE是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_4&quot;" target="&quot;BERT_LARGE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"BERT_LARGE是从image_4中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;OPENAI GPT&quot;" target="&quot;BERT_LARGE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Both are models used for natural language processing tasks, with BERT_LARGE generally outperforming OpenAI GPT across most tasks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;CNN BASE&quot;" target="&quot;BERT_BASE&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are models used for NLP tasks, with BERT_BASE generally performing better than CNN Base across most tasks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;CNN LARGE&quot;" target="&quot;BERT_LARGE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Both are models used for NLP tasks, with BERT_LARGE generally outperforming CNN Large across most tasks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BPE LARGE&quot;" target="&quot;BERT_LARGE&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are models used for NLP tasks, with BERT_LARGE generally performing better than BPE Large across most tasks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GPT ON STILTS&quot;" target="&quot;BERT_LARGE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Both are models used for NLP tasks, with BERT_LARGE generally outperforming GPT on STILTs across most tasks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D19-1539/images/image_4.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
