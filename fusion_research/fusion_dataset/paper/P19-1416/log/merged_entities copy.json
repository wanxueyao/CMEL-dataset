{
    "chunk-b592d04d5ced8b96eebb6a344d84cdb1": [
        {
            "entity_name": "Bonobo (Pan paniscus, Pygmy Chimpanzee, Dwarf Chimpanzee, Gracile Chimpanzee)",
            "entity_type": "GEO",
            "description": "Bonobo, also known as 'Pan paniscus', is an endangered great ape whose habitat is protected by the Lomako Forest Reserve in the Democratic Republic of the Congo. It is formerly known as Pygmy Chimpanzee, Dwarf Chimpanzee, and Gracile Chimpanzee, and is part of the multi-hop reading comprehension research context.",
            "source_entities": [
                "BONOBO",
                "PAN PANISCUS",
                "PYGMY CHIMPANZEE",
                "DWARF CHIMPANZEE",
                "GRACILE CHIMPANZEE"
            ]
        },
        {
            "entity_name": "Lomako Forest Reserve (R´eserve Naturelle Lomako Yokokala)",
            "entity_type": "GEO",
            "description": "The Lomako Forest Reserve, also known as R´eserve Naturelle Lomako Yokokala, is a geographical location established to protect the habitat of the Bonobo apes in the Democratic Republic of the Congo. It is mentioned in the context of multi-hop reading comprehension research.",
            "source_entities": [
                "LOMAKO FOREST RESERVE",
                "R´ESERVE NATURELLE LOMAKO YOKOKALA"
            ]
        }
    ],
    "chunk-641cd529de353090b26104297132f871": [
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a model used in the single-paragraph BERT approach for answering questions, as referenced in the research by Devlin et al. (2018).",
            "source_entities": [
                "BERT"
            ]
        },
        {
            "entity_name": "HOTPOTQA",
            "entity_type": "ORGANIZATION",
            "description": "HOTPOTQA is a dataset that consists of multi-hop questions requiring reasoning over two paragraphs from Wikipedia, constructed using crowd workers and mentioned in various research works including Yang et al. (2018) and Chen and Durrett (2019).",
            "source_entities": [
                "HOTPOTQA"
            ]
        },
        {
            "entity_name": "WIKIHOP",
            "entity_type": "ORGANIZATION",
            "description": "WIKIHOP is a dataset constructed using knowledge bases, mentioned in the context of multi-hop QA and associated with the research by Welbl et al. (2017).",
            "source_entities": [
                "WIKIHOP"
            ]
        },
        {
            "entity_name": "COMPLEXWEBQUESTIONS",
            "entity_type": "ORGANIZATION",
            "description": "COMPLEXWEBQUESTIONS is a dataset consisting of open-domain compositional questions, constructed from WEBQUESTIONS and mentioned in the context of multi-hop QA.",
            "source_entities": [
                "COMPLEXWEBQUESTIONS"
            ]
        },
        {
            "entity_name": "TF-IDF SIMILARITY",
            "entity_type": "CONCEPT",
            "description": "TF-IDF similarity is a method used to select spurious paragraphs in the Distractor Setting and to retrieve paragraphs in the Open-domain Setting of HOTPOTQA, also referred to as BIGRAM TF-IDF SIMILARITY in the context of paragraph retrieval.",
            "source_entities": [
                "TF-IDF SIMILARITY",
                "BIGRAM TF-IDF SIMILARITY"
            ]
        },
        {
            "entity_name": "SPURIOUS PARAGRAPHS",
            "entity_type": "CONCEPT",
            "description": "Spurious paragraphs are the paragraphs selected using TF-IDF similarity with the question, used in the Distractor Setting of HOTPOTQA, and sometimes referred to as distractors.",
            "source_entities": [
                "SPURIOUS PARAGRAPHS"
            ]
        },
        {
            "entity_name": "GOLD PARAGRAPHS",
            "entity_type": "CONCEPT",
            "description": "Gold paragraphs are the two paragraphs the question was written for, used in the Distractor Setting of HOTPOTQA.",
            "source_entities": [
                "GOLD PARAGRAPHS"
            ]
        },
        {
            "entity_name": "YEMPTY",
            "entity_type": "CONCEPT",
            "description": "yempty is a scalar value used in the single-paragraph BERT model to select the answer from the paragraph with the lowest score, and is part of the output indicating no answer.",
            "source_entities": [
                "YEMPTY"
            ]
        },
        {
            "entity_name": "YSPAN, YYES, YNO",
            "entity_type": "CONCEPT",
            "description": "yspan, yyes, and yno are scalars generated by the classifier in the single-paragraph BERT model, indicating the answer is a span, 'yes', or 'no' respectively.",
            "source_entities": [
                "YSPAN",
                "YYES",
                "YNO"
            ]
        },
        {
            "entity_name": "SPAN",
            "entity_type": "CONCEPT",
            "description": "Span refers to an extractive paragraph span, which is obtained separately in the single-paragraph BERT model.",
            "source_entities": [
                "SPAN"
            ]
        }
    ],
    "chunk-c96e6bb9567410b6eb2a84b3ea94d4cd": [
        {
            "entity_name": "Kaiser Ventures (American Industrialist, Father of Modern American Shipbuilding)",
            "entity_type": "ORGANIZATION",
            "description": "Kaiser Ventures is an organization used as an example to illustrate questions that are compositional but can be solved using only part of the question. It is also associated with the founder who is referred to as 'American Industrialist' and 'Father of Modern American Shipbuilding'.",
            "source_entities": [
                "KAISER VENTURES",
                "AMERICAN INDUSTRIALIST",
                "FATHER OF MODERN AMERICAN SHIPBUILDING"
            ]
        }
    ],
    "chunk-da3785709741127896bd86556478a157": [
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a model used for language understanding tasks, mentioned in the context of its performance on question compositionality and multi-hop reasoning. It is also referenced in the context of its accuracy on new distractors and its performance after re-training.",
            "source_entities": [
                "\"BERT\""
            ]
        },
        {
            "entity_name": "Allen Institute for AI (ALLEN INSTITUTE FOR AI)",
            "entity_type": "ORGANIZATION",
            "description": "Allen Institute for AI is an organization that provided gifts to support the research.",
            "source_entities": [
                "\"ALLEN INSTITUTE FOR AI\"",
                "\"ALLENNLP\""
            ]
        },
        {
            "entity_name": "Amazon (AMAZON)",
            "entity_type": "ORGANIZATION",
            "description": "Amazon is an organization that provided gifts to support the research.",
            "source_entities": [
                "\"AMAZON\""
            ]
        },
        {
            "entity_name": "Google (GOOGLE)",
            "entity_type": "ORGANIZATION",
            "description": "Google is an organization that provided gifts to support the research.",
            "source_entities": [
                "\"GOOGLE\""
            ]
        },
        {
            "entity_name": "UW NLP",
            "entity_type": "ORGANIZATION",
            "description": "UW NLP is an organization whose members are acknowledged for their valuable feedback in the research.",
            "source_entities": [
                "\"UW NLP\""
            ]
        },
        {
            "entity_name": "Table 4",
            "entity_type": "EVENT",
            "description": "Table 4 is referenced as showing the F1 score of single-paragraph BERT on new distractors and the accuracy after re-training.",
            "source_entities": [
                "\"TABLE 4\""
            ]
        },
        {
            "entity_name": "Section 4.1",
            "entity_type": "GEO",
            "description": "Section 4.1 is mentioned as the place where the entity type bias is described.",
            "source_entities": [
                "\"SECTION 4.1\""
            ]
        },
        {
            "entity_name": "Table 5",
            "entity_type": "EVENT",
            "description": "Table 5 is referenced to show the accuracy of single-paragraph BERT in different open-domain retrieval settings.",
            "source_entities": [
                "\"TABLE 5\""
            ]
        },
        {
            "entity_name": "Bonobo apes (BONOBO APES)",
            "entity_type": "GEO",
            "description": "Bonobo apes are mentioned as an example where the model fails to retrieve relevant paragraphs due to lack of specific terms in the question.",
            "source_entities": [
                "\"BONOBO APES\""
            ]
        },
        {
            "entity_name": "Figure 1",
            "entity_type": "GEO",
            "description": "Figure 1 is referenced to illustrate the failure to retrieve a paragraph about 'Bonobo apes'.",
            "source_entities": [
                "\"FIGURE 1\""
            ]
        },
        {
            "entity_name": "Reading Comprehension (RC)",
            "entity_type": "ORGANIZATION",
            "description": "RC likely stands for 'Reading Comprehension' and is used in the context of discussing question types and dataset design.",
            "source_entities": [
                "\"RC\""
            ]
        }
    ],
    "chunk-725d8cfe3eb952e1f9c79442ce7a6c8b": [],
    "chunk-5e7ccf1d72e7b038983b2017f5d8ddb6": [
        {
            "entity_name": "R´eserve Naturelle du Grand Cul-de-Sac Marin (Guadeloupe Archipelago)",
            "entity_type": "ORGANIZATION",
            "description": "A marine protected area adjacent to the park and administered in conjunction with it, part of the Guadeloupe Archipelago biosphere reserve, which comprises protected areas in the Guadeloupe region.",
            "source_entities": [
                "\"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN\"",
                "\"GUADELOUPE ARCHIPELAGO\""
            ]
        },
        {
            "entity_name": "La D´esirade National Nature Reserve (De´sirade Island)",
            "entity_type": "ORGANIZATION",
            "description": "A reserve in De´sirade Island in Guadeloupe, established for its special geological features, representing the geological heritage of the Caribbean tectonic plate, with an area of 62 ha.",
            "source_entities": [
                "\"LA D´ESIRADE NATIONAL NATURE RESERVE\"",
                "\"DE´SIRADE ISLAND\""
            ]
        },
        {
            "entity_name": "R´eserve Naturelle Nationale de Saint-Barth´elemy (La Tortue ou l’Ecalle or Ile Tortue, Ile Fourchue)",
            "entity_type": "ORGANIZATION",
            "description": "A national nature reserve in Saint Barth´elemy that includes La Tortue ou l’Ecalle or Ile Tortue, a small rocky islet off the northeastern coast, and Ile Fourchue, an island between Saint-Barthe´lemy and Saint Martin, both privately owned.",
            "source_entities": [
                "\"LA TORTUE OU L’ECALLE OR ILE TORTUE\"",
                "\"SAINT BARTH´ELEMY\"",
                "\"NATURE RESERVE OF SAINT BARTHOLOMEW\"",
                "\"ILE FOURCHUE\"",
                "\"R´ESERVE NATURELLE NATIONALE DE SAINT-BARTH´ELEMY\"",
                "\"ILE FOURCHE\""
            ]
        }
    ],
    "chunk-76e5e660f564ca4da0077e1cfaaa9966": [
        {
            "entity_name": "Adam",
            "entity_type": "PERSON",
            "description": "Adam is associated with a learning rate in the context of the implementation details, likely referring to a person involved in the development process. Adam is one of the authors of the Adam optimization algorithm, contributing to the field of machine learning.",
            "source_entities": [
                "ADAM",
                "KINGMA",
                "BA"
            ]
        },
        {
            "entity_name": "Hugging Face (HUGGING FACE)",
            "entity_type": "ORGANIZATION",
            "description": "Hugging Face is a company known for its contributions to the field of natural language processing, including the implementation of PyTorch. PyTorch is an open-source machine learning library based on Torch, used for applications such as computer vision and natural language processing.",
            "source_entities": [
                "HUGGING FACE",
                "PYTORCH"
            ]
        }
    ]
}