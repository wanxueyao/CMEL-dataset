{
    "image_1": {
        "image_id": 1,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_1.jpg",
        "caption": [],
        "footnote": [],
        "context": "To investigate BERT’s decision making we looked at data points it finds easy to classify over multiple runs. Habernal et al. (2018b) performed a similar analysis with the SemEval submissions,  Table 1: Baselines and BERT results. Our results come from 20 different random seeds ( $\\pm$ gives the standard deviation). The mean for BERT Large is skewed by the $5/20$ random seeds for which it failed to train, a problem noted by Devlin et al. (2018). We therefore consider the median a better measure of BERT’s average performance. The mean of the non-degenerate runs for BERT (Large) is $0.716\\pm0.04$ . to know how consumer choice and web re-directs relate to the concept of monopoly, and that Google is a search engine. All but one participating system in the shared task could not exceed $60\\%$ accuracy (on binary classification). It is therefore surprising that BERT (Devlin et al., 2018) achieves $77\\%$ test set accuracy with its best run (Table 1), only three points below the average (untrained) human baseline. Without supplying the required world knowledge for this task it does not seem reasonable to expect it to perform so well. This motivates the question: what has BERT learned about argument comprehension? ",
        "chunk_order_index": 0,
        "chunk_id": "chunk-86be7b6fd443f07c3aa235e44b2d0974",
        "description": "The image is a table that presents the performance of various models on a specific task, likely related to argument comprehension or text classification. The table is divided into two main sections: 'Dev' and 'Test'. Under 'Dev', there are columns for 'Mean' and 'Median', while under 'Test', there are columns for 'Mean', 'Median', and 'Max'. The rows represent different models and baselines. The first row shows 'Human (trained)' with a test mean of 0.909 ± 0.11. The second row shows 'Human (untrained)' with a test mean of 0.798 ± 0.16. The subsequent rows list various models: BERT (Large) with a dev mean of 0.701 ± 0.05, a test mean of 0.671 ± 0.09, a test median of 0.712, and a test max of 0.770; GIST (Choi and Lee, 2018) with a dev mean of 0.716 ± 0.01 and a test mean of 0.711 ± 0.01; BERT (Base) with a dev mean of 0.680 ± 0.02, a test mean of 0.623 ± 0.07, a test median of 0.651, and a test max of 0.685; World Knowledge (Botschen et al., 2018) with a dev mean of 0.674 ± 0.01 and a test mean of 0.568 ± 0.03; BoV with a dev mean of 0.639 ± 0.02 and a test mean of 0.564 ± 0.02; and BiLSTM with a dev mean of 0.658 ± 0.01 and a test mean of 0.552 ± 0.02. The table highlights the performance of these models, with BERT (Large) achieving the highest test max value of 0.770.",
        "segmentation": false
    },
    "image_2": {
        "image_id": 2,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_2.jpg",
        "caption": [
            "Figure 2: General architecture of the models in our experiments. Logits are independently calculated for each argument-warrant pair then concatenated and passed through softmax. "
        ],
        "footnote": [],
        "context": "However, we show that the major problem can be eliminated in ARCT. Since $R\\wedge A\\to\\lnot C$ , we can add a To investigate BERT’s decision making we looked at data points it finds easy to classify over multiple runs. Habernal et al. (2018b) performed a similar analysis with the SemEval submissions, and consistent with their results we found that BERT exploits the presence of cue words in the warrant, especially “not.” Through probing experiments designed to isolate such effects, we demonstrate in this work that BERT’s surprising performance can be entirely accounted for in terms of exploiting spurious statistical cues. the required world knowledge for this task it does not seem reasonable to expect it to perform so well. This motivates the question: what has BERT learned about argument comprehension?  Table 1: Baselines and BERT results. Our results come from 20 different random seeds ( $\\pm$ gives the standard deviation). The mean for BERT Large is skewed by the $5/20$ random seeds for which it failed to train, a problem noted by Devlin et al. (2018). We therefore consider the median a better measure of BERT’s average performance. The mean of the non-degenerate runs for BERT (Large) is $0.716\\pm0.04$ . ",
        "chunk_order_index": 0,
        "chunk_id": "chunk-86be7b6fd443f07c3aa235e44b2d0974",
        "description": "The image is a flowchart illustrating the general architecture of models used in experiments. It consists of three main layers: the input layer, the processing layer, and the output layer. The input layer contains two sets of inputs represented by pink rectangles labeled 'c', 'r', and 'w_0' for the first set, and 'c', 'r', and 'w_1' for the second set. These inputs are passed through a blue rectangle labeled 'θ', which represents some form of processing or transformation. From this processing layer, two outputs are generated, represented by orange rectangles labeled 'z_0' and 'z_1'. These outputs are then concatenated and passed through a green rectangle labeled 'Softmax', which likely represents the final classification or probability distribution over classes.",
        "segmentation": false
    },
    "image_3": {
        "image_id": 3,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_3.jpg",
        "caption": [],
        "footnote": [],
        "context": "Our BERT classifier is visualized in Figure 3. The claim and reason are joined to form the first text segment, which is paired with each warrant and independently processed. The final layer CLS vector is passed to a linear layer to obtain the logits zj(i ). 3 BERT Figure 3: Processing an argument-warrant pair with BERT. The reason (with word pieces of length $a$ ) and claim (length b) together form the first utterance, and the warrant (length $c$ ) is the second. The final CLS vector is then passed to a linear layer to calculate the logit $z_{j}^{(i)}$ . (BiLSTM), the SemEval winner GIST (Choi and Lee, 2018), the best model of Botschen et al. (2018), and human performance (Table 1). For all of our experiments we use grid search to select hyperparameters, dropout regularization (Srivastava et al., 2014), and Adam (Kingma and Ba, 2014) for optimization. We anneal the learning rate by $1/10$ when validation accuracy drops. The final parameters come from the epoch with maximum validation accuracy. The BoV and BiLSTM inputs are 300-dimensional GloVe embeddings trained on 640B tokens (Pennington et al., 2014). Code to reproduce all experiments, and detailing all hyperparameters, is provided on GitHub. ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-6d8347f5fe115cac0955dadaeb7b490c",
        "description": "The image is a diagram illustrating the processing of an argument-warrant pair using the BERT (Bidirectional Encoder Representations from Transformers) model. The diagram is divided into three main sections: input tokens, BERT layers, and output embeddings. At the top, there are input tokens represented by green boxes with labels such as 'v_CLS', 'v_1(c)', 'v_a(c)', 'v_1(r)', 'v_b(r)', 'v_SEP', 'v_1(w)', and 'v_c(w)'. These tokens correspond to different parts of the input text, including the claim, reason, and warrant. The tokens are connected to the BERT layers, which are depicted as a series of interconnected circles within a blue rectangle labeled 'BERT'. The BERT layers process the input tokens and produce output embeddings, represented by yellow boxes at the bottom with labels such as 'E_CLS', 'E_1(c)', 'E_a(c)', 'E_1(r)', 'E_b(r)', 'E_SEP', 'E_1(w)', and 'E_c(w)'. These embeddings are then used for further processing. The diagram also includes hexagonal shapes at the bottom representing the original text segments, labeled as 'Claim', 'Reason', and 'Warrant'. The overall structure shows how the BERT model processes the input text and generates embeddings for each segment.",
        "segmentation": false
    },
    "image_4": {
        "image_id": 4,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_4.jpg",
        "caption": [],
        "footnote": [],
        "context": "The productivity and coverage of the strongest unigram cue we found (“not”) is given in Table 2. It provides a particularly strong training signal. While it is less productive in the test set, it is just one among many such cues. We found a range of other unigrams, albeit with less overall productivity, mostly being high frequency words such as “is,” “do,” and strength of the signal it provides. With $m$ labels, if $\\pi_{k}>1/m$ then the presence of a cue is going to be useful for the task and a machine learner would do well to make use of it.  it predicts the correct answer: $$ \\pi_{k}=\\frac{\\sum_{i=1}^{n}\\mathbb{1}\\left[\\exists j,k\\in\\mathbb{T}_{j}^{(i)}\\land k\\not\\in\\mathbb{T}_{\\rightarrow j}^{(i)}\\land y_{i}=j\\right]}{\\alpha_{k}} $$ Finally, we define the coverage $\\xi_{k}$ of a cue as the proportion of applicable cases over the total number of data points: $\\xi_{k}~=~\\alpha_{k}/n$ . In these terms, the productivity of a cue measures the benefit of exploiting it, while coverage measures the Table 2: Productivity and coverage of using the presence of “not” in the warrant to predict the label in ARCT. Across the whole dataset, if you pick the warrant with “not” you will be right $61\\%$ of the time, which covers $64\\%$ of all data points. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-66f0cc171e500d5b800332b1ba6a9b6f",
        "description": "The image is a table labeled 'Table 2: Productivity and coverage of using the presence of “not” in the warrant to predict the label in ARCT.' The table is structured with two main columns: 'Productivity' and 'Coverage'. Each column represents a metric and contains the following rows: 'Train', 'Validation', 'Test', and 'All'. The values for each row are as follows: Train - Productivity: 0.65, Coverage: 0.66; Validation - Productivity: 0.62, Coverage: 0.44; Test - Productivity: 0.52, Coverage: 0.77; All - Productivity: 0.61, Coverage: 0.64. The table highlights the productivity and coverage metrics across different dataset partitions, showing that while the productivity is highest in the training set, the coverage is highest in the test set.",
        "segmentation": false
    },
    "image_5": {
        "image_id": 5,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_5.jpg",
        "caption": [],
        "footnote": [],
        "context": "The major problem of statistical cues over labels in ARCT can be eliminated due the original design of the dataset. Given that $R\\land A\\,\\rightarrow\\,\\neg C$ ,we can produce adversarial examples by negating the claim and inverting the label 6 Adversarial Test Set Table 3: Results of probing experiments with BERT Large, and the BoV and BiLSTM baselines. These results indicate that BERT’s peak $77\\%$ performance can be entirely accounted for by exploiting spurious cues. By just considering warrants (W) we can get to $71\\%$ .Adding cues over reasons (R, W) and claims (C, W) accounts for the remaining six points. these setups breaks the task since we no longer have an argument to match with a warrant. Experimental results are given in Table 3. On warrants alone (W) BERT achieves a maximum $71\\%$ accuracy. That leaves only six percentage points to account for its peak of $77\\%$ . We find a gain of four percentage points for (R, W) over (W), and a gain of two for (C, W), accounting for the missing six points. Based on this evidence our major finding is that the entirety of BERT’s performance can be accounted for in terms of exploiting spurious statistical cues. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-66f0cc171e500d5b800332b1ba6a9b6f",
        "description": "The image is a table that presents the results of probing experiments with BERT Large, and the BoV and BiLSTM baselines. The table is structured with four main columns: Test Mean, Test Median, and Test Max. Each row represents a different model or model configuration. The first row shows the performance of BERT with a mean of 0.671 ± 0.09, a median of 0.712, and a maximum of 0.770. The subsequent rows show the performance of BERT with different configurations: BERT (W) has a mean of 0.656 ± 0.05, a median of 0.675, and a maximum of 0.712; BERT (R, W) has a mean of 0.600 ± 0.10, a median of 0.574, and a maximum of 0.750; BERT (C, W) has a mean of 0.532 ± 0.09, a median of 0.503, and a maximum of 0.732. The table also includes results for BoV and BiLSTM models with similar configurations. For BoV, the mean ranges from 0.545 to 0.567, the median from 0.544 to 0.572, and the maximum from 0.579 to 0.606. For BiLSTM, the mean ranges from 0.547 to 0.552, the median from 0.547 to 0.555, and the maximum from 0.577 to 0.601. The table highlights the performance differences between the models and their configurations, with BERT showing the highest performance overall.",
        "segmentation": false
    },
    "image_6": {
        "image_id": 6,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_6.jpg",
        "caption": [],
        "footnote": [
            "Figure 4: Original and adversarial data points. The claim is negated and the warrants are swapped. The assignment of labels to $W$ and $A$ are kept the same. By including both, the distribution of linguistic artifacts in the warrants are thereby mirrored around the labels, eliminating the major source of spurious statistical cues in ARCT. "
        ],
        "context": "The most successful previous work on ARCT (Choi and Lee, 2018; Zhao et al., 2018; Niven and Kao, 2018) involved transfer learning from Natural Language Inference (NLI) datasets (Bowman et al., 2015; Williams et al., 2017), and utilized effective NLI models such as ESIM (Chen et al., 2016) and InferSent (Conneau et al., 2017). More recently, Botschen et al. (2018) added FrameNet knowledge with modest performance gains. These models should be evaluated on our adversarial dataset. In particular it will be interesting if Botschen et al.’s model stands out due to the inclusion of some of the 7 Related Work the cues in the original training set. In the second, models were trained from scratch on the adversarial training and validation sets, then evaluated on the adversarial test set. Results are given in Table 4. BERT’s peak performance has reduced to $53\\%$ ,with mean and median at $50\\%$ . We conclude from these results that the adversarial dataset has successfully eliminated the cues as expected, providing a more robust evaluation of machine argument comprehension. This result better apts with our intuitions about this task: with little to no understanding about the reality underlying these arguments, good performance shouldn’t be feasible. ",
        "chunk_order_index": 3,
        "chunk_id": "chunk-c65b737226b835d39374cd6d0d2df637",
        "description": "The image is a table labeled 'Figure 4: Original and adversarial data points.' The table is divided into two main columns: 'Original' and 'Adversarial.' Each column contains four rows labeled 'Claim,' 'Reason,' 'Warrant,' and 'Alternative.' In the 'Original' column, the 'Claim' row states 'Google is not a harmful monopoly.' The 'Reason' row states 'People can choose not to use Google.' The 'Warrant' row states 'Other search engines do not redirect to Google.' The 'Alternative' row states 'All other search engines redirect to Google.' In the 'Adversarial' column, the 'Claim' row states 'Google is a harmful monopoly.' The 'Reason' row states 'People can choose not to use Google.' The 'Warrant' row states 'All other search engines redirect to Google.' The 'Alternative' row states 'Other search engines do not redirect to Google.' The table highlights the negation of the claim and the swapping of warrants between the original and adversarial data points. The footnote indicates that the assignment of labels to 'W' and 'A' are kept the same, and by including both, the distribution of linguistic artifacts in the warrants are thereby mirrored around the labels, eliminating the major source of spurious statistical cues in ARCT.",
        "segmentation": false
    },
    "image_7": {
        "image_id": 7,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1459/images/image_7.jpg",
        "caption": [],
        "footnote": [],
        "context": "However, our investigations confirmed that BERT is indeed a very strong learner. Analysis of easy ARCT provides a fortuitous opportunity to see how stark the problem of exploiting spurious statistics can be. Due to our ability to eliminate the major source of these cues, we were able to show that BERT’s maximum performance fell from just three points below the average untrained human baseline to essentially random. To answer our question in the introduction: BERT has learned nothing about argument comprehension. 8 Conclusion Table 4: Results for BERT Large on the adversarial test set with adversarial training and validation sets. since the presence of a cue is enough to increase the logits for either warrant. The original ARCT data comes with a training set created in the same way as our adversarial dataset. Habernal et al. (2018a) reported experiments using this training data that led to random accuracy. They suggested it could be that high similarity between the data points made the problem too difficult for the simple models they implemented. Our work indicates the necessity of applying this transformation to the entire dataset in order to obtain a more robust evaluation by eliminating spurious statistical cues over the labels. ",
        "chunk_order_index": 3,
        "chunk_id": "chunk-c65b737226b835d39374cd6d0d2df637",
        "description": "The image is a table that presents the results for BERT Large on an adversarial test set with adversarial training and validation sets. The table has four rows and four columns. The first column lists different versions of BERT: 'BERT', 'BERT (W)', 'BERT (R, W)', and 'BERT (C, W)'. The subsequent columns are labeled 'Mean', 'Median', and 'Max', representing statistical measures of performance. The values in the 'Mean' column are as follows: BERT has a mean of 0.504 ± 0.01, BERT (W) has 0.501 ± 0.00, BERT (R, W) has 0.500 ± 0.00, and BERT (C, W) has 0.501 ± 0.01. The 'Median' column shows that all versions have a median of 0.500 or 0.501. The 'Max' column indicates the maximum values: BERT has 0.533, BERT (W) has 0.502, BERT (R, W) has 0.502, and BERT (C, W) has 0.518. The table highlights the performance metrics of different BERT configurations on the adversarial dataset.",
        "segmentation": false
    }
}