{
    "image_1": [
    ],
    "image_2": [
        {
            "entity_name": "MOVIE REVIEWS",
            "entity_type": "DATASET",
            "description": "A dataset with 1600 training, 200 development, and 200 test samples. It contains 774 tokens and includes positive/negative sentiment labels on movie reviews.",
            "source_image_entities": [
                "MOVIE REVIEWS"
            ],
            "source_text_entities": [
                "MOVIE REVIEWS"
            ]
        },
        {
            "entity_name": "FEVER",
            "entity_type": "DATASET",
            "description": "A dataset with 97957 training, 6122 development, and 6111 test samples. It contains 327 tokens and is short for Fact Extraction and VERification, used for verifying claims from textual sources.",
            "source_image_entities": [
                "FEVER"
            ],
            "source_text_entities": [
                "FEVER"
            ]
        },
        {
            "entity_name": "MULTIRC",
            "entity_type": "DATASET",
            "description": "A dataset with 24029 training, 3214 development, and 4848 test samples. It contains 303 tokens and is composed of questions with multiple correct answers that depend on information from multiple sentences.",
            "source_image_entities": [
                "MULTIRC"
            ],
            "source_text_entities": [
                "MULTIRC"
            ]
        },
        {
            "entity_name": "COS-E",
            "entity_type": "DATASET",
            "description": "A dataset with 8733 training, 1092 development, and 1092 test samples. It contains 28 tokens and comprises multiple-choice questions and answers with supporting rationales.",
            "source_image_entities": [
                "COS-E"
            ],
            "source_text_entities": [
                "COMMONSENSE EXPLANATIONS (COS-E)"
            ]
        },
        {
            "entity_name": "E-SNLI",
            "entity_type": "DATASET",
            "description": "A dataset with 911938 training, 16449 development, and 16429 test samples. It contains 16 tokens and augments the SNLI corpus with rationales marked in the premise and/or hypothesis.",
            "source_image_entities": [
                "E-SNLI"
            ],
            "source_text_entities": [
                "E-SNLI"
            ]
        }
    ],
    "image_3": [
        {
            "merged_entity_name": "COHEN Κ",
            "entity_type": "EVENT",
            "description": "A statistical measure of inter-annotator agreement, mentioned in the context of human agreement over extracted rationales, with a high Cohen κ indicating substantial or better agreement.",
            "source_image_entities": [
                "COHEN Κ"
            ],
            "source_text_entities": [
                "COHEN $\\KAPPA$"
            ]
        },
        {
            "merged_entity_name": "F1 SCORE",
            "entity_type": "EVENT",
            "description": "A measure of a test's accuracy, considering both the precision and the recall of the test to compute the score, used here to calculate an F1 score based on partial matches for rationale extraction.",
            "source_image_entities": [
                "F1"
            ],
            "source_text_entities": [
                "F1 SCORE"
            ]
        }
    ],
    "image_4": [
    ],
    "image_5": [
        {
            "entity_name": "EVIDENCE INFERENCE",
            "entity_type": "EVENT",
            "description": "EVIDENCE INFERENCE is an event or dataset used for evaluating the performance of models, particularly those that comprise very long inputs exceeding the token limit for BERT models.",
            "source_image_entities": [
                "EVIDENCE INFERENCE"
            ],
            "source_text_entities": [
                "EVIDENCE INFERENCE"
            ]
        },
        {
            "entity_name": "BOOLQ",
            "entity_type": "EVENT",
            "description": "BOOLQ is an event or dataset that comprises very long inputs, exceeding the token limit for BERT models.",
            "source_image_entities": [
                "BOOLQ"
            ],
            "source_text_entities": [
                "BOOLQ"
            ]
        },
        {
            "entity_name": "FEVER",
            "entity_type": "EVENT",
            "description": "FEVER is one of the datasets mentioned where random removal of rationales is particularly damaging to performance, indicating poor absolute ranking.",
            "source_image_entities": [
                "FEVER"
            ],
            "source_text_entities": [
                "FEVER"
            ]
        },
        {
            "entity_name": "COS-E",
            "entity_type": "EVENT",
            "description": "COS-E is a dataset used to illustrate the scoring metrics comprehensiveness and sufficiency, and is also one of the datasets where random removal of rationales is particularly damaging to performance, indicating poor absolute ranking.",
            "source_image_entities": [
                "COS-E"
            ],
            "source_text_entities": [
                "COS-E",
                "COS-E",
                "COS-E"
            ]
        },
        {
            "entity_name": "E-SNLI",
            "entity_type": "EVENT",
            "description": "E-SNLI is an event or dataset used for evaluating the performance of models, particularly BertTo-Bert for CoS-E, and is also one of the datasets where random removal of rationales is particularly damaging to performance, indicating poor absolute ranking.",
            "source_image_entities": [
                "E-SNLI"
            ],
            "source_text_entities": [
                "E-SNLI",
                "ESNLI"
            ]
        }
    ],
    "image_7": [
        {
            "entity_name": "FEVER",
            "entity_type": "DATASET",
            "description": "FEVER is a dataset with 2915 train documents, 570 validation documents, and 614 test documents. The train set has 97957 instances, the validation set has 6122 instances, and the test set has 6111 instances. The rationale percentage is 20.0% for the train set and 21.6% for the validation set. It is also a benchmark event that involves processing and repartitioning of validation sets and dealing with claims and evidence. The dataset is mentioned as an exception for the use of bert-base-uncased as a token embedder.",
            "source_image_entities": [
                "FEVER"
            ],
            "source_text_entities": [
                "FEVER"
            ]
        },
        {
            "entity_name": "BOOLQ",
            "entity_type": "EVENT",
            "description": "BOOLQ is a dataset with 4518 train documents, 1092 validation documents, and 2294 test documents. The train set has 6363 instances, the validation set has 1491 instances, and the test set has 2817 instances. The rationale percentage is 6.64% for the train set and 7.13% for the validation set. It is also an event where a dataset required substantial processing, including identifying source paragraphs and repartitioning for testing. Amazon Mechanical Turk is a platform used to collect reference comprehensive rationales for the BoolQ dataset. The Levenshtein distance ratio is a measure used to determine the similarity between two strings, with a score of at least 90 required for the BoolQ dataset.",
            "source_image_entities": [
                "BOOLQ"
            ],
            "source_text_entities": [
                "BOOLQ"
            ]
        },
        {
            "entity_name": "E-SNLI",
            "entity_type": "EVENT",
            "description": "E-SNLI is a dataset with 911938 train documents, 16328 validation documents, and 16299 test documents. The train set has 549309 instances, the validation set has 9823 instances, and the test set has 9807 instances. The rationale percentage is 27.3% for the train set and 25.6% for the validation set. It is also an event where minimal processing was performed, involving the separation of premise and hypothesis statements.",
            "source_image_entities": [
                "E-SNLI"
            ],
            "source_text_entities": [
                "E-SNLI"
            ]
        },
        {
            "entity_name": "EVIDENCE INFERENCE",
            "entity_type": "EVENT",
            "description": "EVIDENCE INFERENCE is a dataset with 1924 train documents, 247 validation documents, and 240 test documents. The train set has 7958 instances, the validation set has 972 instances, and the test set has 959 instances. The rationale percentage is 1.34% for the train set and 1.38% for the validation set. It is also an event that uses a different embedding method and is mentioned in the context of model training. SciSpacy is a library used for tokenization in Evidence Inference, developed by Neumann et al. in 2019.",
            "source_image_entities": [
                "EVIDENCE INFERENCE"
            ],
            "source_text_entities": [
                "EVIDENCE INFERENCE"
            ]
        }
    ],
    "image_8": [
    ]
}