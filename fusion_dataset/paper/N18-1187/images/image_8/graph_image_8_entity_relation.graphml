<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_8&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image is a line graph titled 'Task Success Rate over Time (smoothed)'. The x-axis represents the number of interactive dialogue learning sessions, ranging from 0 to 10,000. The y-axis represents the task success rate, ranging from 0.3 to 0.7. There are five different lines representing different RL training settings: SL Baseline (dotted cyan line with crosses), SL + policy-only RL (solid red line with pentagons), SL + end-to-end RL (solid blue line with stars), SL + IL 1000 + policy-only RL (dashed blue line with stars), and SL + IL 1000 + end-to-end RL (solid blue line with stars). The SL Baseline starts at around 0.32 and remains relatively flat throughout the sessions. The SL + policy-only RL starts at around 0.35 and shows a gradual increase, reaching around 0.55 by 10,000 sessions. The SL + end-to-end RL starts at around 0.35 and shows a more significant increase, reaching around 0.65 by 10,000 sessions. The SL + IL 1000 + policy-only RL starts at around 0.45 and shows a steady increase, reaching around 0.6 by 10,000 sessions. The SL + IL 1000 + end-to-end RL starts at around 0.45 and shows the highest increase, reaching around 0.68 by 10,000 sessions."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
</node>
<node id="&quot;GRAPH&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"A graph showing the task success rate over time for different learning methods in interactive dialogue learning sessions."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
</node>
<node id="&quot;SL BASELINE&quot;">
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d1">"The SL Baseline is a data point on the graph representing the supervised learning baseline performance."</data>
  <data key="d0">"UNKNOWN"</data>
</node>
<node id="&quot;SL + POLICY-ONLY RL&quot;">
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d1">"The SL + policy-only RL is a data line on the graph representing the performance of combining supervised learning with policy-only reinforcement learning."</data>
  <data key="d0">"UNKNOWN"</data>
</node>
<node id="&quot;SL + END-TO-END RL&quot;">
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d1">"The SL + end-to-end RL is a data line on the graph representing the performance of combining supervised learning with end-to-end reinforcement learning."</data>
  <data key="d0">"UNKNOWN"</data>
</node>
<node id="&quot;SL + IL 1000 + POLICY-ONLY RL&quot;">
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d1">"The SL + IL 1000 + policy-only RL is a data line on the graph representing the performance of combining supervised learning with imitation learning and policy-only reinforcement learning."</data>
  <data key="d0">"UNKNOWN"</data>
</node>
<node id="&quot;SL + IL 1000 + END-TO-END RL&quot;">
  <data key="d2">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d1">"The SL + IL 1000 + end-to-end RL is a data line on the graph representing the performance of combining supervised learning with imitation learning and end-to-end reinforcement learning."</data>
  <data key="d0">"UNKNOWN"</data>
</node>
<edge source="&quot;IMAGE_8&quot;" target="&quot;GRAPH&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Graph是从image_8中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRAPH&quot;" target="&quot;SL BASELINE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The SL Baseline is a data point on the graph representing the supervised learning baseline performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRAPH&quot;" target="&quot;SL + POLICY-ONLY RL&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The SL + policy-only RL is a data line on the graph representing the performance of combining supervised learning with policy-only reinforcement learning."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRAPH&quot;" target="&quot;SL + END-TO-END RL&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The SL + end-to-end RL is a data line on the graph representing the performance of combining supervised learning with end-to-end reinforcement learning."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRAPH&quot;" target="&quot;SL + IL 1000 + POLICY-ONLY RL&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The SL + IL 1000 + policy-only RL is a data line on the graph representing the performance of combining supervised learning with imitation learning and policy-only reinforcement learning."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRAPH&quot;" target="&quot;SL + IL 1000 + END-TO-END RL&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The SL + IL 1000 + end-to-end RL is a data line on the graph representing the performance of combining supervised learning with imitation learning and end-to-end reinforcement learning."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/N18-1187/images/image_8.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
