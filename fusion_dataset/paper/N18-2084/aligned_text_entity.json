{
    "image_1": [
    ],
    "image_2": [
    ],
    "image_3": [
    ],
    "image_4": [
    ],
    "image_5": [
    ],
    "image_6": [
        {
            "entity_name": "GL/PT",
            "entity_type": "GEO",
            "description": "GL/PT represents the language pair of Galician (GL) to Portuguese (PT), noted for their high similarity and used in the study to investigate the effect of linguistic similarity on pre-trained embeddings. The similarity of GL/PT is the highest among the language pairs considered, and they showed the largest gains in BLEU scores when applying pre-trained embeddings.",
            "source_image_entities": [
                "GL + PT"
            ],
            "source_text_entities": [
                "GL/PT"
            ]
        },
        {
            "entity_name": "BE/RU",
            "entity_type": "GEO",
            "description": "BE/RU represents the language pair of Belarusian (BE) to Russian (RU), noted for their low similarity. The gains in BLEU scores when applying pre-trained embeddings are smaller for this language pair compared to others, likely due to the partial mutual intelligibility and rich morphology of Slavic languages.",
            "source_image_entities": [
                "BE + RU"
            ],
            "source_text_entities": [
                "BE/RU"
            ]
        },
        {
            "entity_name": "Smith et al. (2017)",
            "entity_type": "ORGANIZATION",
            "description": "Smith et al. (2017) proposed an approach to learn orthogonal transformations for aligning word embeddings of multiple languages into a single space, which is a method used in the context of pre-training word embeddings. Their approach is mentioned as a way to convert the word embeddings of multiple languages to a single space, used in the study to learn reasonable projection of word embeddings during the normal training process.",
            "source_image_entities": [],
            "source_text_entities": [
                "SMITH ET AL., 2017",
                "SMITH ET AL. (2017)"
            ]
        }
    ],
    "image_7": [
    ],
    "image_8": [
    ],
    "image_9": [
        {
            "entity_name": "F-measure in NMT",
            "entity_type": "CONCEPT",
            "description": "F-measure is a measure of a test's accuracy, specifically in the context of machine learning and information retrieval, used to evaluate the performance of different methods in Neural Machine Translation (NMT) as shown in a bar chart comparing 'std' and 'pre' methods across different frequency ranges in a training corpus.",
            "source_image_entities": [
                "F-MEASURE"
            ],
            "source_text_entities": [
                "F-MEASURE"
            ]
        }
    ]
}