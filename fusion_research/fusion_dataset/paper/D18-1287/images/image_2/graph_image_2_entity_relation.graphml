<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_2&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image is a detailed diagram illustrating the architecture for an instruction-following system, specifically designed to interpret and execute the command 'Turn left and go to the red oil drum.' The diagram is divided into several interconnected components. On the top left, there is a panorama image labeled as ${\\bf I}_{P}$, which represents the initial observation of the environment. This image is processed by a CNN (Convolutional Neural Network) to generate a feature map ${\\bf F}_{0}$. Below this, there are multiple layers of convolutions that further process the feature map, resulting in a sequence of feature maps ${\\bf F}_{1}, {\\bf F}_{2}, {\\bf F}_{3}, {\\bf F}_{4}$. These feature maps are then combined with text kernels ${\\bf K}_{1}, {\\bf K}_{2}, {\\bf K}_{3}, {\\bf K}_{4}$ generated from the instruction representation $\\bar{\\bf x}$, which is derived from the original instruction $\\bar{x}$ using an RNN (Recurrent Neural Network). The text-conditioned feature maps ${\\bf G}_{1}, {\\bf G}_{2}, {\\bf G}_{3}, {\\bf G}_{4}$ are de-convolved to produce ${\\bf H}_{1}, {\\bf H}_{2}, {\\bf H}_{3}, {\\bf H}_{4}$. The goal probability distribution $P_{g}$ is computed from ${\\bf H}_{1}$, and the goal location $l_{g}$ is inferred from the maximum value in $P_{g}$. Given $l_{g}$ and the current pose $p_{t}$ at step $t$, the goal mask ${\\bf M}_{t}$ is computed and passed into an RNN to output the action to execute. The actions shown are 'TURNLEFT', 'TURNLEFT', and 'FORWARD'."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;INSTRUCTION REPRESENTATION X&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"The representation of the instruction 'Turn left and go to the red oil drum' processed by the system."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;PANORAMA IMAGE I_P&quot;">
  <data key="d0">"GEO"</data>
  <data key="d1">"A panoramic image used as input for the system, showing a scene with various objects and landmarks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;TEXT KERNELS&quot;">
  <data key="d0">"OBJECT"</data>
  <data key="d1">"Components of the system that process text information from the instruction."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;SOFTMAX&quot;">
  <data key="d0">"OBJECT"</data>
  <data key="d1">"A function used in the system to convert scores into probabilities."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;GOAL DISTRIBUTION P_G&quot;">
  <data key="d0">"OBJECT"</data>
  <data key="d1">"A distribution representing possible goal locations based on the processed instruction and image."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;GOAL LOCATION L_G&quot;">
  <data key="d0">"GEO"</data>
  <data key="d1">"The specific location within the image identified as the goal based on the instruction."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;POSES P1, P2, P3&quot;">
  <data key="d0">"OBJECT"</data>
  <data key="d1">"Different poses or viewpoints considered by the system to reach the goal."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;GOAL MASKS M1, M2, M3&quot;">
  <data key="d0">"OBJECT"</data>
  <data key="d1">"Masks highlighting areas of the image that are relevant to the goal."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<node id="&quot;ACTIONS TURNLEFT, FORWARD&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Commands generated by the system to navigate towards the goal."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
</node>
<edge source="&quot;IMAGE_2&quot;" target="&quot;INSTRUCTION REPRESENTATION X&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Instruction Representation x是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;PANORAMA IMAGE I_P&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Panorama Image I_p是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;TEXT KERNELS&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Text Kernels是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;SOFTMAX&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Softmax是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;GOAL DISTRIBUTION P_G&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Goal Distribution P_g是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;GOAL LOCATION L_G&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Goal Location l_g是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;POSES P1, P2, P3&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Poses p1, p2, p3是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;GOAL MASKS M1, M2, M3&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Goal Masks M1, M2, M3是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_2&quot;" target="&quot;ACTIONS TURNLEFT, FORWARD&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Actions TURNLEFT, FORWARD是从image_2中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;INSTRUCTION REPRESENTATION X&quot;" target="&quot;PANORAMA IMAGE I_P&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The instruction representation is derived from the panorama image."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;INSTRUCTION REPRESENTATION X&quot;" target="&quot;TEXT KERNELS&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"The text kernels process the instruction representation."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;TEXT KERNELS&quot;" target="&quot;SOFTMAX&quot;">
  <data key="d3">6.0</data>
  <data key="d4">"The softmax function processes the output of the text kernels."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SOFTMAX&quot;" target="&quot;GOAL DISTRIBUTION P_G&quot;">
  <data key="d3">9.0</data>
  <data key="d4">"The softmax output influences the goal distribution."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GOAL DISTRIBUTION P_G&quot;" target="&quot;GOAL LOCATION L_G&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The goal distribution determines the goal location."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GOAL LOCATION L_G&quot;" target="&quot;POSES P1, P2, P3&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"The goal location influences the different poses considered."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;POSES P1, P2, P3&quot;" target="&quot;GOAL MASKS M1, M2, M3&quot;">
  <data key="d3">6.0</data>
  <data key="d4">"The poses influence the goal masks."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GOAL MASKS M1, M2, M3&quot;" target="&quot;ACTIONS TURNLEFT, FORWARD&quot;">
  <data key="d3">9.0</data>
  <data key="d4">"The goal masks determine the actions to be taken."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/D18-1287/images/image_2.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
