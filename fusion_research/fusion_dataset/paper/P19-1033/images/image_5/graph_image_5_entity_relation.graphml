<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_5&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image is a table that compares the performance of various methods for news recommendation using different evaluation metrics. The table has four columns: Methods, AUC, MRR, nDCG@5, and nDCG@10. Each row represents a different method. The methods listed are LibFM, DeepFM, Wide &amp; Deep, DSSM, CNN, DKN, GRU, LSTUR-con, and LSTUR-ini. The values in each column represent the performance metrics with their respective standard deviations. For example, LibFM has an AUC of 56.52 ± 1.31, MRR of 25.53 ± 0.81, nDCG@5 of 26.66 ± 1.04, and nDCG@10 of 34.72 ± 0.95. The highest AUC value is achieved by LSTUR-ini at 63.56 ± 0.42, followed closely by LSTUR-con at 63.47 ± 0.10. Similarly, the highest MRR value is also achieved by LSTUR-ini at 30.98 ± 0.32, and the highest nDCG@5 and nDCG@10 values are both achieved by LSTUR-ini at 33.45 ± 0.39 and 41.37 ± 0.36 respectively. The table highlights the superior performance of the LSTUR methods, especially LSTUR-ini, over other methods in all evaluated metrics."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;LIBFM&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A machine learning algorithm used for recommendation systems, achieving an AUC of 56.52 ± 1.31, MRR of 25.53 ± 0.81, nDCG@5 of 26.66 ± 1.04, and nDCG@10 of 34.72 ± 0.95."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;DEEPFM&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"An algorithm that combines the factorization-machine based recommender system with deep learning, achieving an AUC of 58.13 ± 1.69, MRR of 27.01 ± 0.20, nDCG@5 of 28.37 ± 0.57, and nDCG@10 of 36.78 ± 0.62."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;WIDE &amp; DEEP&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A model that combines wide linear models and deep neural networks, achieving an AUC of 58.07 ± 0.55, MRR of 27.07 ± 0.37, nDCG@5 of 28.51 ± 0.45, and nDCG@10 of 36.93 ± 0.43."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;DSSM&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A deep structured semantic model used for information retrieval, achieving an AUC of 58.43 ± 0.58, MRR of 27.25 ± 0.49, nDCG@5 of 28.31 ± 0.60, and nDCG@10 of 36.91 ± 0.54."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;CNN&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A convolutional neural network model, achieving an AUC of 61.13 ± 0.77, MRR of 29.44 ± 0.73, nDCG@5 of 31.44 ± 0.87, and nDCG@10 of 39.51 ± 0.74."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;DKN&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A dynamic knowledge-aware network model, achieving an AUC of 61.25 ± 0.78, MRR of 29.47 ± 0.64, nDCG@5 of 31.54 ± 0.79, and nDCG@10 of 39.59 ± 0.67."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;GRU&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A gated recurrent unit model, achieving an AUC of 62.69 ± 0.16, MRR of 30.24 ± 0.13, nDCG@5 of 32.56 ± 0.17, and nDCG@10 of 40.55 ± 0.13."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;LSTUR-CON&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A long short-term user representation model with continuous training, achieving an AUC of 63.47 ± 0.10, MRR of 30.94 ± 0.14, nDCG@5 of 33.43 ± 0.13, and nDCG@10 of 41.34 ± 0.13."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<node id="&quot;LSTUR-INI&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A long short-term user representation model with initial training, achieving an AUC of 63.56 ± 0.42, MRR of 30.98 ± 0.32, nDCG@5 of 33.45 ± 0.39, and nDCG@10 of 41.37 ± 0.36."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
</node>
<edge source="&quot;IMAGE_5&quot;" target="&quot;LIBFM&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LibFM是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;DEEPFM&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"DeepFM是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;WIDE &amp; DEEP&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Wide &amp; Deep是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;DSSM&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"DSSM是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;CNN&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CNN是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;DKN&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"DKN是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;GRU&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"GRU是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;LSTUR-CON&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTUR-con是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_5&quot;" target="&quot;LSTUR-INI&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"LSTUR-ini是从image_5中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;LIBFM&quot;" target="&quot;DEEPFM&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are algorithms used in recommendation systems, with DeepFM showing slightly better performance across all metrics."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;DEEPFM&quot;" target="&quot;WIDE &amp; DEEP&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both combine linear models with deep learning, but Wide &amp; Deep shows a slight edge in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;WIDE &amp; DEEP&quot;" target="&quot;DSSM&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are models used for information retrieval, with DSSM showing a slight edge in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;DSSM&quot;" target="&quot;CNN&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are neural network models, with CNN showing a significant improvement in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;CNN&quot;" target="&quot;DKN&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are advanced neural network models, with DKN showing a slight improvement in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;DKN&quot;" target="&quot;GRU&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are recurrent neural network models, with GRU showing a significant improvement in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;GRU&quot;" target="&quot;LSTUR-CON&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are advanced recurrent neural network models, with LSTUR-con showing a significant improvement in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;LSTUR-CON&quot;" target="&quot;LSTUR-INI&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Both are long short-term user representation models, with LSTUR-ini showing a slight improvement in performance."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/P19-1033/images/image_5.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
