{
    "image_1": {
        "image_id": 1,
        "image_path": "./fusion_research/fusion_dataset/paper/W18-4401/images/image_1.jpg",
        "caption": [
            "Table 1: Timeline of the Aggression Identification Shared Task at TRAC - 1. "
        ],
        "footnote": [],
        "context": "While 4.1 Issues with the Dataset The participants of the shared task were provided with a dataset of 12,000 randomly sampled Facebook comments for training and 3,000 comments for development and in English and Hindi each, annotated with 3 levels of aggression - Overtly Aggressive (OAG), Covertly Aggressive (CAG) and NonAggressive (NAG). For test, 916 English comments and 970 Hindi comments were provided. Additionally, 1,257 English tweets and 1,194 Hindi tweets were given as the surprise test set . The dataset released for the task is a subset of a larger dataset discussed in Kumar et al. (2018b). 4 Dataset most of them got less time than this. Initially, the dataset was not released publicly but was emailed only to the registered participants. After the 6 weeks of release of train and dev sets, the test set was released and the participants had 5 days to test and upload their system. The complete timeline of the shared task is given in Table 1. We made use of CodaLab for the evaluation. Each team was allowed to submit up to 3 systems for evaluation. We used the best of the 3 runs for the final ranking and evaluation of the systems. ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-c98797b4d5898b68808aad4eb43794e0",
        "description": "The image is a table labeled 'Table 1: Timeline of the Aggression Identification Shared Task at TRAC - 1'. The table is structured with two main columns: 'Date' and 'Event'. Each row represents a specific date and the corresponding event in the timeline of the shared task. The dates and events are as follows: '1 February, 2018' - 'Shared Task Announcement and Start of Registration', '13 March, 2018' - 'Release of train and dev sets', '25 April, 2018' - 'Release of test set', '30 April, 2018' - 'Deadline for Submission of System', '2 May, 2018' - 'Declaration of Results', and '28 May, 2018' - 'Deadline for Submission of System Description Paper'. The table provides a clear and detailed timeline of the key events in the shared task, from the announcement to the final submission of system description papers.",
        "segmentation": false
    },
    "image_2": {
        "image_id": 2,
        "image_path": "./fusion_research/fusion_dataset/paper/W18-4401/images/image_2.jpg",
        "caption": [],
        "footnote": [],
        "context": "saroyehun system gives the best performance with LSTM and they resorted to translation as data augmentation strategy. With the surprise twitter set, a combination of the representations of the RNN and CNN as features, along with additional preprocessing like spelling correction, translation of emoji, and computation of sentiment score gave the Next we give a short description of the approach taken by each team for building their system. More details about the approaches could be found in the paper submitted by the respective teams. Table 2: The teams that participated in the Aggression Identification Shared Task at TRAC - 1. only in Hindi track and 56 teams registered to participate in both the tracks. Out of these, finally a total of 30 teams submitted their systems - 15 teams for both English and Hindi and 30 teams for only English track. All the systems who submitted their system were invited to submit the system description paper, describing the experiments conducted by them. 18 participants submitted the final description paper which are included in the workshop proceedings - it included papers by majority of the top 10 teams. Table 2, lists the participating teams and the language they took part in. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-545990bda67013ebcc871877a4d5a1b1",
        "description": "The image is a table labeled 'Table 2: The teams that participated in the Aggression Identification Shared Task at TRAC - 1.' It provides information about the participating teams and the languages they took part in. The table has four columns: Team, Hindi, English, and System Description Paper. Each row represents a team and indicates whether they participated in the Hindi track, English track, or both, and if they submitted a system description paper. The rows are as follows:\\n\\n- saroyehun: Participated in English, with a system description paper by Aroyehun and Gelbukh (2018).\\n- EBSI-LIA-UNAM: Participated in English, with a system description paper by Arroyo-Fernández et al. (2018).\\n- DA-LD-Hildesheim: Participated in Hindi and English, with a system description paper by Modha et al. (2018).\\n- TakeLab: Participated in English, with a system description paper by Golem et al. (2018).\\n- sreeIN: Participated in Hindi and English, with a system description paper by Madisetty and Desarkar (2018).\\n- Julian: Participated in Hindi and English, with a system description paper by Risch and Krestel (2018).\\n- taraka_rama: Participated in Hindi.\\n- uOttawa: Participated in English, with a system description paper by Orabi et al. (2018).\\n- Isistantitos: Participated in English, with a system description paper by Tommasel et al. (2018).\\n- hakuchumu: Participated in English.\\n- DataGeeks: Participated in Hindi and English.\\n- na14: Participated in Hindi and English, with a system description paper by Samghabadi et al. (2018).\\n- dinel: Participated in English, with a system description paper by Orasan (2018).\\n- vista.ue: Participated in Hindi and English, with a system description paper by Raiyani et al. (2018).\\n- MANITBHOPALINDIA: Participated in Hindi and English.\\n- IRIT: Participated in English, with a system description paper by Ramiandrisoa and Mothe (2018).\\n- quine: Participated in Hindi and English, with a system description paper by Nikhil et al. (2018).\\n- IIIT-Delhi: Participated in English.\\n- PMRS: Participated in Hindi and English, with a system description paper by Maitra and Sarkhel (2018).\\n- resham: Participated in Hindi.\\n- IreneR: Participated in English.\\n- Nestor: Participated in Hindi and English.\\n- UAEMex-UAPT1: Participated in Hindi and English.\\n- forest_and_trees: Participated in Hindi and English, with a system description paper by Galery et al. (2018).\\n- groutar: Participated in English, with a system description paper by Fortuna et al. (2018).\\n- Shusrut: Participated in Hindi and English, with a system description paper by Roy et al. (2018).\\n- malaypramanick: Participated in English.\\n- UAEMex-UAPT-TAC2: Participated in Hindi and English.\\n- Unito: Participated in Hindi and English.\\n- bhanodaig: Participated in English, with a system description paper by Kumar et al. (2018a).\\n\\nThe table also shows the total number of teams participating in each language track: 15 for Hindi, 30 for English, and 18 who submitted a system description paper.",
        "segmentation": false
    },
    "image_3": {
        "image_id": 3,
        "image_path": "./fusion_research/fusion_dataset/paper/W18-4401/images/image_3.jpg",
        "caption": [
            "Figure 1: Performance of top 15 teams on English Dataset "
        ],
        "footnote": [],
        "context": "In this paper, we have presented the report of the First Shared task on Aggression Identification organized with the TRAC workshop at 7 Conclusion  The participants were allowed to use other datasets, in addition to the one provided by the organizers of the task. However, because of the lack of similar alternative datasets, all the groups, except ’groutar’ and ’saroyehun’ team, used only the dataset provided for the task. As we mentioned earlier, the participants were given two kinds of test sets for the final testing of the system - one from Facebook and a surprise test set from Twitter. and Covertly Aggressive classes respectively. The classification of sentences is straightforward: a sentence that does not contain any word from the lexicon is tagged as NAG, a sentence containing more directly offensive words than potentially offensive words is tagged as OAG, and the other cases are tagged as CAG. bhanodaig system uses a bidirectional LSTM. 6 Results In this section, we present the results of the experiments carried out by different teams during the shared task. The results of the top 15 teams on English dataset is given in Figure 1 and that on Hindi dataset is in Figure 2. ",
        "chunk_order_index": 4,
        "chunk_id": "chunk-d548ab53599fd4d48cda4a33bb77ead9",
        "description": "The image is a bar chart titled 'English Performance' that compares the performance of top 15 teams on two different social media platforms: Twitter and Facebook. The x-axis lists the names of the teams, while the y-axis represents the performance score ranging from 0 to 0.8. Each team has two bars representing their performance on Twitter (black) and Facebook (gray). The teams are listed as follows: vista_ile, Julian, saroyehun, EBSI-LIA-UNAM, uOttawa, na14, taraka_rama, TakeLab, DataGeeks, quine, DA-LD-Hildesheim, Isistanitos, resham, IIIT-Delhi, IRIT, Shusrut, sreeIN, dinel, hakuchumu, MANITBHOPALINDIA. The performance scores vary across teams, with some teams performing better on Twitter and others on Facebook. For example, 'saroyehun' has a higher score on Facebook compared to Twitter, while 'DA-LD-Hildesheim' has a higher score on Twitter compared to Facebook.",
        "segmentation": false
    },
    "image_4": {
        "image_id": 4,
        "image_path": "./fusion_research/fusion_dataset/paper/W18-4401/images/image_4.jpg",
        "caption": [
            "Figure 2: Performance of teams on Hindi Dataset "
        ],
        "footnote": [],
        "context": "The performance of the best systems in the task show that aggression identification is a hard problem to solve. Moreover, the performance of the neural networks-based systems as well as the other approaches do not seem to differ much. If the features In this paper, we have presented the report of the First Shared task on Aggression Identification organized with the TRAC workshop at COLING 2018. The shared task received a very encouraging response from the community which underlines the relevance and need of the task. More than 100 teams registered and 30 teams finally submitted their system. 7 Conclusion The results of the top 15 teams on English dataset is given in Figure 1 and that on Hindi dataset is in Figure 2.  The participants were allowed to use other datasets, in addition to the one provided by the organizers of the task. However, because of the lack of similar alternative datasets, all the groups, except ’groutar’ and ’saroyehun’ team, used only the dataset provided for the task. As we mentioned earlier, the participants were given two kinds of test sets for the final testing of the system - one from Facebook and a surprise test set from Twitter. ",
        "chunk_order_index": 4,
        "chunk_id": "chunk-d548ab53599fd4d48cda4a33bb77ead9",
        "description": "The image is a bar chart titled 'Hindi Performance' that compares the performance of various teams on Hindi datasets from Twitter and Facebook. The x-axis lists the names of the teams, which include DA-LD-Hildesheim, na14, vista_ue, quine, DataGeeks, taraka_rana, resham, Julian, Shusrut, MANITBHOPALINDIA, Nestor, UAEMex-UAPT1, UAEMex-UAPT-TAC2, PMRS, and Unito. The y-axis represents the performance score, ranging from 0 to 0.8. Each team has two bars representing their performance on Twitter (black) and Facebook (gray). The highest performing team on Twitter is DA-LD-Hildesheim with a score of approximately 0.55, while the highest performing team on Facebook is na14 with a score of approximately 0.65. The lowest performing team on both platforms is Unito, with scores around 0.2 for Twitter and 0.25 for Facebook. The chart shows that most teams perform better on Facebook than on Twitter.",
        "segmentation": false
    }
}