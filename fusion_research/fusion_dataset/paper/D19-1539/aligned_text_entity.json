{
    "image_1": [
    ],
    "image_2": [
    ],
    "image_3": [
    ],
    "image_4": [
        {
            "merged_entity_name": "OPENAI GPT",
            "entity_type": "ORGANIZATION",
            "description": "A model developed by OpenAI, showcasing performance across various NLP tasks including CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, and RTE. The unidirectional transformer (OpenAI GPT) is a model that the current models outperform.",
            "source_image_entities": [
                "OPENAI GPT"
            ],
            "source_text_entities": [
                "UNIDIRECTION TRANSFORMER (OPENAI GPT)"
            ]
        },
        {
            "merged_entity_name": "CNN BASE",
            "entity_type": "ORGANIZATION",
            "description": "A Convolutional Neural Network model with base configuration, evaluated on multiple NLP benchmarks. The CNN base model performs as well as STILTs in aggregate, however, on some tasks involving sentence-pairs, STILTs performs much better (MRPC, RTE).",
            "source_image_entities": [
                "CNN BASE"
            ],
            "source_text_entities": [
                "CNN BASE ARCHITECTURE"
            ]
        },
        {
            "merged_entity_name": "GPT ON STILTS",
            "entity_type": "ORGANIZATION",
            "description": "A variant of the GPT model, tested on different NLP challenges including CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, and RTE. STILTs is a model that the CNN base model performs as well as in aggregate, but not as well on some sentence-pair tasks.",
            "source_image_entities": [
                "GPT ON STILTS"
            ],
            "source_text_entities": [
                "STILTS"
            ]
        }
    ],
    "image_5": [
    ],
    "image_6": [
    ],
    "image_7": [],
    "image_8": [
    ],
    "image_9": [
        {
            "entity_name": "QUORA QUESTION PAIRS BENCHMARK (QQP)",
            "entity_type": "EVENT",
            "description": "The QQP is a benchmark used to evaluate the performance of models in terms of F1 score, ranging from 84.9 to 87.2.",
            "source_image_entities": [
                "QQP (F1)"
            ],
            "source_text_entities": [
                "\"QUORA QUESTION PAIRS BENCHMARK (QQP)\""
            ]
        }
    ]
}