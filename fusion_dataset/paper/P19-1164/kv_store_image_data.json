{
    "image_1": {
        "image_id": 1,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_1.jpg",
        "caption": [],
        "footnote": [],
        "context": "As shown in Figure 1, we use data introduced by two recent coreference gender-bias studies: the Winogender (Rudinger et al., 2018), and the WinoBias (Zhao et al., 2018) datasets. Following the Winograd schema (Levesque, 2011), each instance in these datasets is an English sentence which describes a scenario with human entities, who are identified by their role (e.g., “the doctor” and “the nurse” in Figure 1), and a pronoun (“her” in the example), which needs to 2017; Font and Costa-Jussa\\`, 2019). Google Translate recently tried to mitigate these biases by allowing users to sometimes choose between gendered translations (Kuczmarski, 2018).  biases, e.g., translating nurses as females and programmers as males, regardless of context (Alvarez-Melis and Jaakkola, Figure 1: An example of gender bias in machine translation from English (top) to Spanish (bottom). In the English source sentence, the nurse’s gender is unknown, while the coreference link with “her” identifies the “doctor” as a female. On the other hand, the Spanish target sentence uses morphological features for gender: “el doctor” (male), versus “la enfermera” (female). Aligning between source and target sentences reveals that a stereotypical assignment of gender roles changed the meaning of the translated sentence by changing the doctor’s gender. ",
        "chunk_order_index": 0,
        "chunk_id": "chunk-61a07b2c6cd3a5fe05ae01915da5cbe9",
        "description": "The image is a diagram illustrating an example of gender bias in machine translation from English to Spanish. The top part of the image contains an English sentence: 'The doctor asked the nurse to help her in the procedure.' The bottom part of the image shows the Spanish translation: 'El doctor le pidió a la enfermera que le ayudara con el procedimiento.' The diagram includes arrows pointing from specific words in the English sentence to their corresponding translations in Spanish. The arrow from 'The doctor' points to 'El doctor,' and the arrow from 'the nurse' points to 'la enfermera.' The diagram highlights how the gender of the doctor is specified as male in Spanish ('el doctor') while the gender of the nurse is specified as female ('la enfermera'), even though the original English sentence does not specify the gender of either role.",
        "segmentation": false
    },
    "image_2": {
        "image_id": 2,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_2.jpg",
        "caption": [],
        "footnote": [
            "Table 1: The coreference test sets and resulting WinoMT corpus statistics (in number of instances). "
        ],
        "context": "This process can introduce noise into our evaluation in steps (2) and This process extracts the translated genders, according to $M$ , for all of the entities in WinoMT, which we can then evaluate against the gold annotations provided by the original English dataset. We then map the English entity annotated in the coreference datasets to its translation (e.g., align between “the doctor” and “el doctor” in Figure 1). (3) Finally, we extract the target-side entity’s gender using simple heuristics over languagespecific morphological analysis, which we perform using off-the-shelf tools for each target language, as discussed in the following section. genders, as well as between stereotypical and nonstereotypical gender-role assignments (e.g., a female doctor versus a female nurse). Additional dataset statistics are presented in Table 1. We use WinoMT to estimate the gender-bias of an MT model, $M$ , in target-language $L$ by performing following steps (exemplified in Figure 1): (1) Translate all of the sentences in WinoMT into $L$ using $M$ , thus forming a bilingual corpus of English and the target language $L$ . (2) Align between the source and target translations, using fast align (Dyer et al., 2013), trained on the automatic translations from from step (1). ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-de280a19f9b0d2d6cec43fde95b790d2",
        "description": "The image is a table labeled 'Table 1: The coreference test sets and resulting WinoMT corpus statistics (in number of instances)'. The table is structured with four main columns: Winogender, WinoBias, and WinoMT. Each column represents different datasets and contains the following rows: 'Male', 'Female', and 'Neutral'. The values in the table are as follows: For Winogender, 'Male' has 240 instances, 'Female' has 240 instances, and 'Neutral' has 240 instances, totaling 720 instances. For WinoBias, 'Male' has 1582 instances, 'Female' has 1586 instances, and 'Neutral' has 0 instances, totaling 3168 instances. For WinoMT, 'Male' has 1826 instances, 'Female' has 1822 instances, and 'Neutral' has 240 instances, totaling 3888 instances. The table highlights the distribution of gender instances across different datasets, showing significant numbers for both male and female instances in WinoBias and WinoMT, while maintaining equal distribution in Winogender.",
        "segmentation": false
    },
    "image_3": {
        "image_id": 3,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_3.jpg",
        "caption": [],
        "footnote": [],
        "context": "Table 2: Performance of commercial MT systems on the WinoMT corpus on all tested languages, categorized by their family: Spanish, French, Italian, Russian, Ukrainian, Hebrew, Arabic, and German. $A c c$ indicates overall gender accuracy ( $\\%$ of instances the translation had the correct gender), $\\Delta_{G}$ denotes the difference in performance $\\boldsymbol{F}_{1}$ score) between masculine and feminine scores, and $\\Delta_{S}$ is the difference in performance ( $F_{1}$ score) between pro-stereotypical and anti-stereotypical gender role assignments (higher numbers in the two latter metrics indicate stronger biases). Numbers in bold indicate best accuracy for the language across MT systems (row), and underlined Experimental Setup MT systems We test six widely used MT models, representing the state of the art in both commercial and academic research: (1) Google Translate,1 (2) Microsoft Translator,2 (3) Amazon Translate, (4) SYSTRAN, (5) the model of Ott et al. (2018), which recently achieved the best performance on English-to-French translation on the WMT’14 test set, and (6) the model of Edunov et al. (2018), the WMT’18 winner on English-toGerman translation. We query the online API for the first four commercial MT systems, while for the latter two academic models we use the pretrained models provided by the Fairseq toolkit.5 ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-de280a19f9b0d2d6cec43fde95b790d2",
        "description": "The image is a table comparing the performance of four commercial machine translation (MT) systems on the WinoMT corpus across eight languages: Spanish (ES), French (FR), Italian (IT), Russian (RU), Ukrainian (UK), Hebrew (HE), Arabic (AR), and German (DE). The table is structured with columns for each MT system (Google Translate, Microsoft Translator, Amazon Translate*, SYSTRAN) and rows for each language. Each cell contains three values: Acc (overall gender accuracy in percentage), Δ_G (difference in performance F1 score between masculine and feminine scores), and Δ_S (difference in performance F1 score between pro-stereotypical and anti-stereotypical gender role assignments). For example, for Spanish (ES), Google Translate has an Acc of 53.1%, Δ_G of 23.4, and Δ_S of 21.3. The highest Acc for each language is highlighted in bold, and the lowest Δ_G and Δ_S are underlined. Notable data points include Amazon Translate* achieving the highest Acc for ES, FR, IT, RU, HE, AR, and DE, while Microsoft Translator has the highest Acc for UK. Significant biases are indicated by higher Δ_G and Δ_S values, such as Google Translate's Δ_G of 43.6 for UK.",
        "segmentation": false
    },
    "image_4": {
        "image_id": 4,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_4.jpg",
        "caption": [],
        "footnote": [
            "Table 3: Performance of recent state-of-the-art academic translation models from English to French and German. Metrics are the same as those in Table 2. "
        ],
        "context": "Target languages and morphological analysis We selected a set of eight languages with grammatical gender which exhibit a wide range of other linguistic properties (e.g., in terms of alphabet, word order, or grammar), while still allowing for highly accurate automatic morphological analysis. These languages belong to four different families: (1) Romance languages: Spanish, French, and Italian, all of which have gendered noun-determiner agreement and spaCy morphological analysis support (Honnibal and Montani, 2017). (2) Slavic languages (Cyrillic alphabet): Russian and Ukrainian, for which we use the morphological analyzer developed by Korobov (2015). (3) Semitic languages: Hebrew and Arabic, each with a Ukrainian, Hebrew, Arabic, and German. $A c c$ indicates overall gender accuracy ( $\\%$ of instances the translation had the correct gender), $\\Delta_{G}$ denotes the difference in performance $\\boldsymbol{F}_{1}$ score) between masculine and feminine scores, and $\\Delta_{S}$ is the difference in performance ( $F_{1}$ score) between pro-stereotypical and anti-stereotypical gender role assignments (higher numbers in the two latter metrics indicate stronger biases). Numbers in bold indicate best accuracy for the language across MT systems (row), and underlined numbers indicate best accuracy for the MT system across languages (column). ∗Amazon Translate does not have a trained model for English to Ukrainian. ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-de280a19f9b0d2d6cec43fde95b790d2",
        "description": "The image is a table labeled 'Table 3: Performance of recent state-of-the-art academic translation models from English to French and German.' The table contains three columns: Acc (accuracy), Δ_G, and Δ_S. Each row represents a different language pair. The first row is for FR (French) using the model from Ott et al., 2018, with values 49.4 for Acc, 2.6 for Δ_G, and 16.1 for Δ_S. The second row is for DE (German) using the model from Edunov et al., 2018, with values 52.5 for Acc, 7.3 for Δ_G, and 8.4 for Δ_S. The table provides metrics related to gender accuracy in translations, with Acc indicating overall gender accuracy (% of instances the translation had the correct gender), Δ_G denoting the difference in performance F1 score between masculine and feminine scores, and Δ_S representing the difference in performance F1 score between pro-stereotypical and anti-stereotypical gender role assignments. Higher numbers in Δ_G and Δ_S indicate stronger biases.",
        "segmentation": false
    },
    "image_5": {
        "image_id": 5,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_5.jpg",
        "caption": [
            "Figure 2: Google Translate’s performance on gender translation on our tested languages. The performance on the stereotypical portion of WinoMT is consistently better than that on the non-stereotypical portion. The other MT systems we tested display similar trends. "
        ],
        "footnote": [],
        "context": "Finally, we tested whether we 3.3 Fighting Bias with Bias ence in performance ( $\\boldsymbol{F}_{1}$ score) between stereotypical and non-stereotypical gender role assignments, as defined by Zhao et al. (2018) who use statistics provided by the US Department of Labor. This metric shows that all tested systems have a significant and consistently better performance when presented with pro-stereotypical assignments (e.g., a female nurse), while their performance deteriorates when translating antistereotypical roles (e.g., a male receptionist). For instance, Figure 2 depicts Google Translate absolute accuracies on stereotypical and nonstereotypical gender roles across all tested languages. Other tested systems show similar trends.   may be explained by German’s similarity to the English source language (Hawkins, 2015). In Table 2, $\\Delta_{G}$ denotes the difference in performance ( $\\mathrm{\\nabla}F_{1}$ score) between male and female translations. Interestingly, all systems, except Microsoft Translator on German, perform signifi- cantly better on male roles, which may stem from these being more frequent in the training set. Perhaps most tellingly, $\\Delta_{S}$ measures the differTable 4: Performance of Google Translate on Spanish, Russian, and Ukranian gender prediction accuracy $\\%$ correct) on the original WinoMT corpus, versus a modified version of the dataset where we add sterotypical gender adjectives (see Section 3.3). ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-739dc030a3e9d6d53de1fc7b0f734b7a",
        "description": "The image is a bar chart titled 'Google Translate’s performance on gender translation on our tested languages.' The chart compares the accuracy (%) of Google Translate in translating stereotypical and non-stereotypical gender roles across eight different languages. The x-axis represents the languages: ES (Spanish), FR (French), IT (Italian), RU (Russian), UK (Ukrainian), HE (Hebrew), AR (Arabic), and DE (German). The y-axis represents the accuracy in percentage, ranging from 0 to 100. Each language has two bars: one blue for stereotypical translations and one red for non-stereotypical translations. The exact values are as follows: ES - Stereotypical 67%, Non-Stereotypical 46%; FR - Stereotypical 80%, Non-Stereotypical 54%; IT - Stereotypical 52%, Non-Stereotypical 30%; RU - Stereotypical 44%, Non-Stereotypical 33%; UK - Stereotypical 46%, Non-Stereotypical 35%; HE - Stereotypical 76%, Non-Stereotypical 38%; AR - Stereotypical 60%, Non-Stereotypical 44%; DE - Stereotypical 69%, Non-Stereotypical 57%. The chart shows that the performance on stereotypical translations is consistently better than that on non-stereotypical translations across all languages.",
        "segmentation": false
    },
    "image_6": {
        "image_id": 6,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_6.jpg",
        "caption": [],
        "footnote": [],
        "context": "Finally, we tested whether we 3.3 Fighting Bias with Bias ence in performance ( $\\boldsymbol{F}_{1}$ score) between stereotypical and non-stereotypical gender role assignments, as defined by Zhao et al. (2018) who use statistics provided by the US Department of Labor. This metric shows that all tested systems have a significant and consistently better performance when presented with pro-stereotypical assignments (e.g., a female nurse), while their performance deteriorates when translating antistereotypical roles (e.g., a male receptionist). For instance, Figure 2 depicts Google Translate absolute accuracies on stereotypical and nonstereotypical gender roles across all tested languages. Other tested systems show similar trends.  may be explained by German’s similarity to the English source language (Hawkins, 2015). In Table 2, $\\Delta_{G}$ denotes the difference in performance ( $\\mathrm{\\nabla}F_{1}$ score) between male and female translations. Interestingly, all systems, except Microsoft Translator on German, perform signifi- cantly better on male roles, which may stem from these being more frequent in the training set. Perhaps most tellingly, $\\Delta_{S}$ measures the differTable 4: Performance of Google Translate on Spanish, Russian, and Ukranian gender prediction accuracy $\\%$ correct) on the original WinoMT corpus, versus a modified version of the dataset where we add sterotypical gender adjectives (see Section 3.3).  ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-739dc030a3e9d6d53de1fc7b0f734b7a",
        "description": "The image is a table labeled 'Table 4: Performance of Google Translate on Spanish, Russian, and Ukranian gender prediction accuracy (%) correct) on the original WinoMT corpus, versus a modified version of the dataset where we add stereotypical gender adjectives (see Section 3.3).'. The table is structured with four main columns: Original, +Adj, and Δ. Each row represents a different language and contains the following values: ES (Spanish) has an Original value of 53.1%, +Adj value of 63.5%, and Δ value of +10.4%. RU (Russian) has an Original value of 37.7%, +Adj value of 48.9%, and Δ value of +11.2%. UK (Ukrainian) has an Original value of 38.4%, +Adj value of 42.9%, and Δ value of +4.5%. The table highlights the performance improvement when stereotypical gender adjectives are added to the dataset.",
        "segmentation": false
    },
    "image_7": {
        "image_id": 7,
        "image_path": "./fusion_research/fusion_dataset/paper/P19-1164/images/image_7.jpg",
        "caption": [],
        "footnote": [
            "Table 5: Examples of Google Translate’s output for different sentences in the WinoMT corpus. Words in blue, red, and orange indicate male, female and neutral entities, respectively. "
        ],
        "context": "Limitations and future work While Related work This work is most related to several recent efforts which evaluate MT through the use of challenge sets. Similarly to our use WinoMT, these works evaluate MT systems (either manually or automatically) on test sets which are specially created to exhibit certain linguistic phenomena, thus going beyond the traditional BLEU metric (Papineni et al., 2002). These include challenge sets for language-specific idiosyncrasies (Isabelle et al., 2017), discourse phenomena (Bawden et al., 2018), pronoun translation (Mu¨ller et al., 2018; Webster et al., 2018), or coreference and multiword expressions (Burchardt et al., 2017). 4 Discussion  translations. Our errors occur when language-specific idiosyncrasies introduce ambiguity to the morphological analysis. For example, gender for certain words in Hebrew cannot be distinguished without diacritics (e.g., the male and female versions of the word “baker” are spelled identically), and the contracted determiner in French and Italian $(l^{\\prime})$ is used for both masculine and feminine nouns. In addition, some languages have only male or female inflections for professions which were stereotypically associated with one of the genders, for example “sastre” (tailor) in Spanish or “soldat” (soldier) in French, which do not have female inflections. See Table 5 for detailed examples. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-739dc030a3e9d6d53de1fc7b0f734b7a",
        "description": "The image is a table labeled 'Table 5: Examples of Google Translate’s output for different sentences in the WinoMT corpus.' The table is divided into three columns: 'Source,' '[Target lang.] Predicted translation,' and 'Phenomenon.' Each row represents a sentence translated from English to Spanish or French, with specific words highlighted in blue, red, and orange to indicate male, female, and neutral entities, respectively. The first row shows an English sentence about a janitor not liking a baker because she always messes up the kitchen. The predicted Spanish translation incorrectly assigns a male inflection to 'baker' ('el panadero') despite the pronoun 'she.' The phenomenon noted is biased translation due to gender mismatch. The second row modifies the original sentence by adding 'pretty' before 'baker.' The predicted Spanish translation now correctly uses 'la panadera bonita,' indicating that adding a stereotypically female adjective fixes the translation issue. The third row presents an English sentence about a counselor asking a guard questions and praising her for good work. The predicted French translation uses 'la garde' and 'l’a louée,' which are gender-neutral terms in French, allowing for a more direct translation without gender ambiguity.",
        "segmentation": false
    }
}