{
    "image_1": [
        {
            "merged_entity_name": "BIDIRECTIONAL LSTM",
            "entity_type": "ORGANIZATION",
            "description": "A neural network layer that processes sequences in both forward and backward directions, utilized in the credibility assessment model to capture long and short range dependencies in text.",
            "source_image_entities": [
                "BIDIRECTIONAL LSTM"
            ],
            "source_text_entities": [
                "BIDIRECTIONAL LONG SHORT-TERM MEMORY (LSTM) NETWORK"
            ]
        },
        {
            "merged_entity_name": "ATTENTION MECHANISM",
            "entity_type": "ORGANIZATION",
            "description": "An attention mechanism that helps the model focus on salient words in the article with respect to the claim, contributing to the interpretability and transparency of the credibility assessment model.",
            "source_image_entities": [
                "ATTENTION WEIGHTS"
            ],
            "source_text_entities": [
                "ATTENTION MECHANISM"
            ]
        },
        {
            "merged_entity_name": "CLAIM SOURCE EMBEDDING",
            "entity_type": "OBJECT",
            "description": "A vector representation of the source of the claim, used in the credibility assessment model to capture the trustworthiness of the claim's origin.",
            "source_image_entities": [
                "CLAIM SOURCE EMBEDDING"
            ],
            "source_text_entities": [
                "C S_{N}"
            ]
        },
        {
            "merged_entity_name": "ARTICLE SOURCE EMBEDDING",
            "entity_type": "OBJECT",
            "description": "A vector representation of the source of the article, used in the credibility assessment model to influence the credibility score based on the article's origin.",
            "source_image_entities": [
                "ARTICLE SOURCE EMBEDDING"
            ],
            "source_text_entities": [
                "A S_{M,N}"
            ]
        },
        {
            "merged_entity_name": "CREDIBILITY SCORE",
            "entity_type": "OBJECT",
            "description": "The output score indicating the credibility of the claim, generated by the end-to-end neural network model after processing claim and article embeddings, attention weights, and source information.",
            "source_image_entities": [
                "CREDIBILITY SCORE"
            ],
            "source_text_entities": [
                "CREDIBILITY SCORE"
            ]
        },
        {
            "merged_entity_name": "CONCATENATE FEATURES",
            "entity_type": "ORGANIZATION",
            "description": "An operation that combines multiple feature vectors into a single vector, used in the credibility assessment model to integrate various informative features for interpretability.",
            "source_image_entities": [
                "CONCATENATE FEATURES"
            ],
            "source_text_entities": [
                "CONCATENATE"
            ]
        }
    ],
    "image_2": [
        {
            "merged_entity_name": "DATASET",
            "entity_type": "ORGANIZATION",
            "description": "A collection of data organized into different categories such as SN, PF, NT, and SE, which include various fact-checking and credibility assessment datasets like Snopes, PolitiFact, NewsTrust, and SemEval.",
            "source_image_entities": [
                "DATASET"
            ],
            "source_text_entities": [
                "TABLE 1",
                "SEMEVAL TWITTER RUMOUR DATASET",
                "SEMEVAL"
            ]
        },
        {
            "merged_entity_name": "SN",
            "entity_type": "EVENT",
            "description": "Snopes category in the dataset with 4341 total claims, 1164 true claims, 3177 false claims, and 29242 articles from 336 sources, known for investigating rumors and providing credibility labels.",
            "source_image_entities": [
                "SN"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "merged_entity_name": "PF",
            "entity_type": "EVENT",
            "description": "PolitiFact category in the dataset with 3568 total claims, 1867 true claims, 1701 false claims, and 29556 articles from 336 sources, which rates the credibility of claims made by political figures.",
            "source_image_entities": [
                "PF"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        },
        {
            "merged_entity_name": "NT",
            "entity_type": "EVENT",
            "description": "NewsTrust category in the dataset with 5344 total claims and 25128 articles from 251 sources, which is a news review community that assigns credibility scores to news articles based on community reviews.",
            "source_image_entities": [
                "NT"
            ],
            "source_text_entities": [
                "NEWSTRUST"
            ]
        },
        {
            "merged_entity_name": "SE",
            "entity_type": "EVENT",
            "description": "SemEval category in the dataset with 272 total claims, 127 true claims, 50 false claims, and 95 unverified claims, and 3717 articles from 89 sources, which is used for determining credibility and stance of social media content, particularly Twitter.",
            "source_image_entities": [
                "SE"
            ],
            "source_text_entities": [
                "SEMEVAL-2017 TASK 8",
                "SEMEVAL"
            ]
        }
    ],
    "image_3": [
        {
            "merged_entity_name": "TABLE 1",
            "entity_type": "EVENT",
            "description": "Table 1 is an event in the text where data statistics for various datasets, including SN (Snopes), PF (PolitiFact), NT (NewsTrust), and SE (SemEval), are presented.",
            "source_image_entities": [
                "TABLE"
            ],
            "source_text_entities": [
                "TABLE 1"
            ]
        },
        {
            "merged_entity_name": "TABLE 2",
            "entity_type": "EVENT",
            "description": "Table 2 is an event in the text where model parameters used for each dataset, including SN (Snopes), PF (PolitiFact), NT (NewsTrust), and SE (SemEval), are presented.",
            "source_image_entities": [
                "TABLE"
            ],
            "source_text_entities": [
                "TABLE 2"
            ]
        },
        {
            "merged_entity_name": "SEMEVAL",
            "entity_type": "ORGANIZATION",
            "description": "SemEval is the organization that provides datasets and data splits for the task of determining credibility and stance of social media content, particularly Twitter, and is also involved in the benchmark dataset released for SemEval-2017 Task 8.",
            "source_image_entities": [
                "SE"
            ],
            "source_text_entities": [
                "SEMEVAL",
                "SEMEVAL-2017 TASK 8"
            ]
        },
        {
            "merged_entity_name": "SNOPES",
            "entity_type": "ORGANIZATION",
            "description": "Snopes is a general fact-checking website that investigates rumors and provides credibility labels, and is also involved in the extraction of relevant snippets from reporting articles and is used as a dataset for credibility classification.",
            "source_image_entities": [
                "SN"
            ],
            "source_text_entities": [
                "SNOPES",
                "SNOPES (2017)"
            ]
        },
        {
            "merged_entity_name": "POLITIFACT",
            "entity_type": "ORGANIZATION",
            "description": "PolitiFact is a political fact-checking website that rates the credibility of claims made by political figures, assigns credibility ratings to claims, and is used as a dataset for credibility classification.",
            "source_image_entities": [
                "PF"
            ],
            "source_text_entities": [
                "POLITIFACT",
                "POLITIFACT (2017)"
            ]
        },
        {
            "merged_entity_name": "NEWSTRUST",
            "entity_type": "ORGANIZATION",
            "description": "NewsTrust is a news review community that assigns credibility scores to news articles based on community reviews and is used as a dataset for credibility regression.",
            "source_image_entities": [
                "NT"
            ],
            "source_text_entities": [
                "NEWSTRUST"
            ]
        }
    ],
    "image_4": "[\n    {\n        \"entity_name\": \"DECLARE\",\n        \"entity_type\": \"ORGANIZATION\",\n        \"description\": \"DeClarE is an organization that has developed a system for credibility classification and regression tasks, with different configurations like (PLAIN), (PLAIN+ATTN), (PLAIN+SREMB), and (FULL) showing varying levels of performance in the Snopes dataset.\",\n        \"source_image_entities\": [\n            \"DECLARE (PLAIN)\",\n            \"DECLARE (PLAIN+ATTN)\",\n            \"DECLARE (PLAIN+SREMB)\",\n            \"DECLARE (FULL)\"\n        ],\n        \"source_text_entities\": [\n            \"DECLARE\"\n        ]\n    },\n    {\n        \"entity_name\": \"LSTM-TEXT\",\n        \"entity_type\": \"CONCEPT\",\n        \"description\": \"LSTM-text is a recent approach for credibility assessment proposed by Rashkin et al. in 2017, achieving 64.65% accuracy on true claims and 64.21% on false claims in the Snopes dataset, with a Macro F1-Score of 0.66 and AUC of 0.70.\",\n        \"source_image_entities\": [\n            \"LSTM-TEXT\"\n        ],\n        \"source_text_entities\": [\n            \"LSTM-TEXT\"\n        ]\n    },\n    {\n        \"entity_name\": \"CNN-TEXT\",\n        \"entity_type\": \"CONCEPT\",\n        \"description\": \"CNN-text is a CNN-based approach for credibility assessment proposed by Wang in 2017, achieving 67.15% accuracy on true claims and 63.14% on false claims in the Snopes dataset, with a Macro F1-Score of 0.66 and AUC of 0.72.\",\n        \"source_image_entities\": [\n            \"CNN-TEXT\"\n        ],\n        \"source_text_entities\": [\n            \"CNN-TEXT\"\n        ]\n    },\n    {\n        \"entity_name\": \"DISTANT SUPERVISION\",\n        \"entity_type\": \"CONCEPT\",\n        \"description\": \"Distant Supervision is a state-of-the-art distant supervision based approach proposed by Popat et al. in 2017, achieving the highest accuracy among the listed configurations for the Snopes dataset, with 83.21% on true claims and 80.78% on false claims, a Macro F1-Score of 0.82, and an AUC of 0.88.\",\n        \"source_image_entities\": [\n            \"DISTANT SUPERVISION\"\n        ],\n        \"source_text_entities\": [\n            \"DISTANT SUPERVISION\"\n        ]\n    },\n    {\n        \"entity_name\": \"SNOPES\",\n        \"entity_type\": \"ORGANIZATION\",\n        \"description\": \"Snopes is an organization involved in the extraction of relevant snippets from reporting articles and is also a dataset used for credibility classification, comparing the performance of various models, including DeClarE, which shows clear separability between credible and non-credible articles.\",\n        \"source_image_entities\": [\n            \"SNOPES\"\n        ],\n        \"source_text_entities\": [\n            \"SNOPES\"\n        ]\n    },\n    {\n        \"entity_name\": \"POLITIFACT\",\n        \"entity_type\": \"ORGANIZATION\",\n        \"description\": \"PolitiFact is an organization that assigns credibility ratings to claims made by political figures and is also a dataset used for credibility classification, comparing the performance of various models, with claim sources analyzed by DeClarE.\",\n        \"source_image_entities\": [\n            \"POLITIFACT\"\n        ],\n        \"source_text_entities\": [\n            \"POLITIFACT\"\n        ]\n    }\n]",
    "image_5": [
        {
            "entity_name": "DeClarE",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE is an organization that has developed a system for credibility classification and regression tasks, including an end-to-end system with biLSTM, attention, and source embeddings, outperforming other approaches in credibility classification.",
            "source_image_entities": [
                "CONFIGURATION"
            ],
            "source_text_entities": [
                "DECLARE",
                "DECLARE (FULL)"
            ]
        },
        {
            "entity_name": "MSE",
            "entity_type": "CONCEPT",
            "description": "Mean Squared Error (MSE) is a metric used to evaluate the performance of the different configurations in credibility regression tasks, with a lower value indicating better performance.",
            "source_image_entities": [
                "MSE"
            ],
            "source_text_entities": [
                "MEAN SQUARE ERROR (MSE)"
            ]
        },
        {
            "entity_name": "Credibility Classification",
            "entity_type": "EVENT",
            "description": "Credibility Classification is the task for which various approaches, including DeClarE, are evaluated on the SemEval dataset, focusing on classifying true and false claims, with measures such as accuracy, macro F1-score, and AUC for the ROC curve.",
            "source_image_entities": [
                "CONFIGURATION"
            ],
            "source_text_entities": [
                "CREDIBILITY CLASSIFICATION",
                "SEMEVAL"
            ]
        },
        {
            "entity_name": "Snopes",
            "entity_type": "ORGANIZATION",
            "description": "Snopes is an organization involved in the extraction of relevant snippets from reporting articles and is used as a dataset for credibility classification, comparing the performance of various models, including DeClarE.",
            "source_image_entities": [
                "CONFIGURATION"
            ],
            "source_text_entities": [
                "SNOPES",
                "SNOPES"
            ]
        },
        {
            "entity_name": "PolitiFact",
            "entity_type": "ORGANIZATION",
            "description": "PolitiFact is an organization that assigns credibility ratings to claims made by political figures and is used as a dataset for credibility classification, comparing the performance of various models, including DeClarE.",
            "source_image_entities": [
                "CONFIGURATION"
            ],
            "source_text_entities": [
                "POLITIFACT",
                "POLITIFACT"
            ]
        }
    ],
    "image_6": [
        {
            "entity_name": "IITP",
            "entity_type": "ORGANIZATION",
            "description": "IITP, proposed by Singh et al. in 2017, is the best performing approach for the open variant of the SemEval task, with a macro accuracy of 0.39 and an RMSE of 0.746.",
            "source_image_entities": [
                "IITP (OPEN)"
            ],
            "source_text_entities": [
                "IITP"
            ]
        },
        {
            "entity_name": "NILETMRG",
            "entity_type": "ORGANIZATION",
            "description": "NILETMRG, proposed by Enayet and El-Beltagy in 2017, is the best performing approach for the close variant of the SemEval task, with a macro accuracy of 0.54 and an RMSE of 0.673.",
            "source_image_entities": [
                "NILETMRG (CLOSE)"
            ],
            "source_text_entities": [
                "NILETMRG"
            ]
        },
        {
            "entity_name": "DECLARE (PLAIN)",
            "entity_type": "ORGANIZATION",
            "description": "DeClare (Plain) is an approach that uses only biLSTM, without attention and source embeddings, and has a macro accuracy of 0.46 and an RMSE of 0.687.",
            "source_image_entities": [
                "DECLARE (PLAIN)"
            ],
            "source_text_entities": [
                "DECLARE (PLAIN)"
            ]
        },
        {
            "entity_name": "DECLARE (FULL)",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE (Full) is an end-to-end system that uses biLSTM, attention, and source embeddings, outperforming other approaches in credibility classification, with a macro accuracy of 0.57 and an RMSE of 0.604.",
            "source_image_entities": [
                "DECLARE (FULL)"
            ],
            "source_text_entities": [
                "DECLARE (FULL)"
            ]
        }
    ],
    "image_7": [
        {
            "entity_name": "DeClarE",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE is an automated end-to-end neural network model for evidence-aware credibility assessment of natural language claims, using PCA to project article representations and distinguish between credible and non-credible sources. It is developed by an organization that has also created a system for credibility classification and regression tasks.",
            "source_image_entities": [
                "DECLARE"
            ],
            "source_text_entities": [
                "DECLARE"
            ]
        },
        {
            "entity_name": "PCA",
            "entity_type": "EVENT",
            "description": "Principal Component Analysis, a statistical procedure used by DeClarE to reduce the dimensionality of data while retaining trends and patterns, projecting article representations from a high-dimensional space to a 2D plane for analysis.",
            "source_image_entities": [
                "PCA"
            ],
            "source_text_entities": [
                "PCA"
            ]
        },
        {
            "entity_name": "NON-CREDIBLE ARTICLES",
            "entity_type": "OBJECT",
            "description": "Articles identified as fake or unreliable by DeClarE, represented in red in the projections, and used in the dataset for credibility classification where DeClarE shows clear separability between credible and non-credible articles.",
            "source_image_entities": [
                "NON-CREDIBLE ARTICLES"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "entity_name": "CREDIBLE ARTICLES",
            "entity_type": "OBJECT",
            "description": "Articles identified as true or reliable by DeClarE, represented in green in the projections, and used in the dataset for credibility classification where DeClarE shows clear separability between credible and non-credible articles.",
            "source_image_entities": [
                "CREDIBLE ARTICLES"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "entity_name": "FAKE NEWS SOURCES",
            "entity_type": "ORGANIZATION",
            "description": "Sources of information that spread false or misleading content, clustered separately from authentic sources in the projections, and clearly separated by DeClarE from mainstream news sources.",
            "source_image_entities": [
                "FAKE NEWS SOURCES"
            ],
            "source_text_entities": [
                "SNOPES"
            ]
        },
        {
            "entity_name": "AUTHENTIC NEWS SOURCES",
            "entity_type": "ORGANIZATION",
            "description": "Sources of information that provide accurate and reliable content, clustered separately from fake news sources in the projections, and clearly separated by DeClarE from fake news sources.",
            "source_image_entities": [
                "AUTHENTIC NEWS SOURCES"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        },
        {
            "entity_name": "POLITICIANS",
            "entity_type": "PERSON",
            "description": "Individuals holding political offices, such as Bernie Sanders, Barack Obama, Hillary Clinton, etc., clustered based on their ideological similarities in the projections, and located close to each other in the embedding space by DeClarE.",
            "source_image_entities": [
                "POLITICIANS"
            ],
            "source_text_entities": [
                "POLITIFACT"
            ]
        }
    ],
    "image_8": [
        {
            "entity_name": "DeClarE",
            "entity_type": "ORGANIZATION",
            "description": "DeClarE is an end-to-end system developed by an organization for credibility classification and regression tasks, utilizing biLSTM, attention mechanisms, and source embeddings, and has been shown to outperform other approaches in credibility classification.",
            "source_image_entities": [
                "\"DECLARE\""
            ],
            "source_text_entities": [
                "\"DECLARE (FULL)\"",
                "\"DECLARE\""
            ]
        },
        {
            "entity_name": "Snopes",
            "entity_type": "ORGANIZATION",
            "description": "Snopes is a dataset used for credibility classification, where DeClarE shows clear separability between credible and non-credible articles, and is also used to sample popular news sources for analysis in the context of claim and article source embeddings.",
            "source_image_entities": [
                "\"SOCIAL SECURITY\"",
                "\"MEDICARE\""
            ],
            "source_text_entities": [
                "\"SNOPES\"",
                "\"SNOPES\""
            ]
        },
        {
            "entity_name": "PolitiFact",
            "entity_type": "ORGANIZATION",
            "description": "PolitiFact is a dataset used for credibility classification, comparing the performance of various models, and is also used to sample claim sources from PolitiFact for analysis in the context of claim and article source embeddings.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"POLITIFACT\"",
                "\"POLITIFACT\""
            ]
        },
        {
            "entity_name": "PCA",
            "entity_type": "EVENT",
            "description": "PCA is the dimensionality reduction technique used to project article representations from a high-dimensional space to a 2D plane for analysis, employed to assess how the DeClarE model separates articles reporting false claims from those reporting true ones.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"PCA\""
            ]
        },
        {
            "entity_name": "Credibility Classification",
            "entity_type": "EVENT",
            "description": "Credibility Classification is the task for which various approaches, including DeClarE, are evaluated on the SemEval dataset, using measures such as macro F1-score and Root-Mean-Square Error (RMSE) over confidence scores.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"CREDIBILITY CLASSIFICATION\""
            ]
        },
        {
            "entity_name": "Table 5",
            "entity_type": "EVENT",
            "description": "Table 5 is the source of comparison data for various approaches for credibility classification on the SemEval dataset, showing that DeClarE outperforms other approaches.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"TABLE 5\""
            ]
        },
        {
            "entity_name": "Figure 2a",
            "entity_type": "EVENT",
            "description": "Figure 2a is where the projections of article representations using PCA are shown, illustrating DeClarE's clear separability between credible and non-credible articles.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"FIGURE 2A\""
            ]
        },
        {
            "entity_name": "Figure 2b",
            "entity_type": "EVENT",
            "description": "Figure 2b is where the projections of claim and article source embeddings are shown, with DeClarE separating fake news sources from mainstream ones.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"FIGURE 2B\""
            ]
        },
        {
            "entity_name": "Figure 2c",
            "entity_type": "EVENT",
            "description": "Figure 2c is where the projections of claim sources from PolitiFact are shown, with DeClarE locating politicians with similar ideologies close to each other in the embedding space.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"FIGURE 2C\""
            ]
        },
        {
            "entity_name": "Table 6",
            "entity_type": "EVENT",
            "description": "Table 6 illustrates claims and salient words that DeClarE focused on during learning, with darker shades indicating higher weights, helping understand what DeClarE focuses on and how it affects its decisions.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"TABLE 6\""
            ]
        }
    ]
}