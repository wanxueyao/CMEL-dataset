{
    "image_1": [
        {
            "merged_entity_name": "PROCEDURE",
            "entity_type": "EVENT",
            "description": "A medical task or operation that requires the collaboration of multiple healthcare professionals, as described in the example sentence 'The doctor asked the nurse to help her in the operation', which is used to evaluate gender bias in machine translation.",
            "source_image_entities": [
                "PROCEDURE"
            ],
            "source_text_entities": [
                "WINOMT"
            ]
        }
    ],
    "image_2": [
        {
            "merged_entity_name": "WINOMT",
            "entity_type": "EVENT",
            "description": "WinoMT is the challenge set created by concatenating Winogender and WinoBias datasets for evaluating gender bias in machine translation, containing 3,888 instances and is equally balanced between male and female genders, as well as between stereotypical and nonstereotypical gender-role assignments.",
            "source_image_entities": [
                "WINOMT"
            ],
            "source_text_entities": [
                "WINOMT"
            ]
        },
        {
            "merged_entity_name": "WINOGENDER",
            "entity_type": "EVENT",
            "description": "Winogender is a dataset used in the study for evaluating gender bias in machine translation, containing 720 examples, equally divided among male, female, and neutral genders.",
            "source_image_entities": [
                "WINOGENDER"
            ],
            "source_text_entities": [
                "WINOGENDER"
            ]
        },
        {
            "merged_entity_name": "WINOBIAS",
            "entity_type": "EVENT",
            "description": "WinoBias is a dataset used in the study for evaluating gender bias in machine translation, containing 3168 examples, with a focus on bias analysis, including 1582 male and 1586 female examples.",
            "source_image_entities": [
                "WINOBIAS"
            ],
            "source_text_entities": [
                "WINOBIAS"
            ]
        }
    ],
    "image_3": null,
    "image_4": [
        {
            "merged_entity_name": "FR (OTT ET AL., 2018)",
            "entity_type": "EVENT",
            "description": "A research event documented by Ott et al. in 2018, focusing on French language data with accuracy of 49.4%, a gain of 2.6 in \\(\\Delta_G\\), and a score change of 16.1 in \\(\\Delta_S\\). Ott et al. (2018) refers to the creators of a machine translation model that achieved the best performance on English-to-French translation on the WMT’14 test set.",
            "source_image_entities": [
                "FR (OTT ET AL., 2018)"
            ],
            "source_text_entities": [
                "OTT ET AL. (2018)"
            ]
        },
        {
            "merged_entity_name": "DE (EDUNOV ET AL., 2018)",
            "entity_type": "EVENT",
            "description": "A research event documented by Edunov et al. in 2018, focusing on German language data with accuracy of 52.5%, a gain of 7.3 in \\(\\Delta_G\\), and a score change of 8.4 in \\(\\Delta_S\\). Edunov et al. (2018) refers to the creators of a machine translation model that won the WMT’18 on English-to-German translation.",
            "source_image_entities": [
                "DE (EDUNOV ET AL., 2018)"
            ],
            "source_text_entities": [
                "EDUNOV ET AL. (2018)"
            ]
        }
    ],
    "image_5": [
        {
            "merged_entity_name": "Spanish",
            "entity_type": "GEO",
            "description": "Spanish is a Romance language tested in the WinoMT challenge set for gender bias in machine translation, with 67% accuracy for stereotypical and 46% for non-stereotypical.",
            "source_image_entities": [
                "ES"
            ],
            "source_text_entities": [
                "SPANISH"
            ]
        },
        {
            "merged_entity_name": "French",
            "entity_type": "GEO",
            "description": "French is a Romance language tested in the WinoMT challenge set for gender bias in machine translation, with 80% accuracy for stereotypical and 54% for non-stereotypical. French has a contracted determiner used for both masculine and feminine nouns, contributing to ambiguity in gender identification.",
            "source_image_entities": [
                "FR"
            ],
            "source_text_entities": [
                "FRENCH"
            ]
        },
        {
            "merged_entity_name": "Italian",
            "entity_type": "GEO",
            "description": "Italian is a Romance language tested in the WinoMT challenge set for gender bias in machine translation, with 52% accuracy for stereotypical and 30% for non-stereotypical. Italian has a contracted determiner used for both masculine and feminine nouns, contributing to ambiguity in gender identification.",
            "source_image_entities": [
                "IT"
            ],
            "source_text_entities": [
                "ITALIAN"
            ]
        },
        {
            "merged_entity_name": "Russian",
            "entity_type": "GEO",
            "description": "Russian is a Slavic language tested in the WinoMT challenge set for gender bias in machine translation, with 44% accuracy for stereotypical and 33% for non-stereotypical.",
            "source_image_entities": [
                "RU"
            ],
            "source_text_entities": [
                "RUSSIAN"
            ]
        },
        {
            "merged_entity_name": "United Kingdom",
            "entity_type": "GEO",
            "description": "United Kingdom is a country whose abbreviation is UK, tested in the WinoMT challenge set for gender bias in machine translation, with 46% accuracy for stereotypical and 35% for non-stereotypical.",
            "source_image_entities": [
                "UK"
            ],
            "source_text_entities": [
                "UK"
            ]
        },
        {
            "merged_entity_name": "Hebrew-speaking region",
            "entity_type": "GEO",
            "description": "Hebrew is a Semitic language tested in the WinoMT challenge set for gender bias in machine translation, with 76% accuracy for stereotypical and 38% for non-stereotypical. Gender for certain words in Hebrew cannot be distinguished without diacritics, leading to ambiguity in morphological analysis.",
            "source_image_entities": [
                "HE"
            ],
            "source_text_entities": [
                "HEBREW"
            ]
        },
        {
            "merged_entity_name": "Argentina",
            "entity_type": "GEO",
            "description": "Argentina is a country whose abbreviation is AR, tested in the WinoMT challenge set for gender bias in machine translation, with 60% accuracy for stereotypical and 44% for non-stereotypical.",
            "source_image_entities": [
                "AR"
            ],
            "source_text_entities": [
                "AR"
            ]
        },
        {
            "merged_entity_name": "Germany",
            "entity_type": "GEO",
            "description": "German is a Germanic language tested in the WinoMT challenge set for gender bias in machine translation, with 69% accuracy for stereotypical and 57% for non-stereotypical. German's similarity to the English source language may explain the better performance of translation systems in German.",
            "source_image_entities": [
                "DE"
            ],
            "source_text_entities": [
                "GERMAN"
            ]
        }
    ],
    "image_6": [
        {
            "entity_name": "Russian",
            "entity_type": "GEO",
            "description": "Russian is a Slavic language tested in the WinoMT challenge set for gender bias in machine translation. The country represented in the table has an original score of 37.7 and an adjusted score of 48.9, showing an increase of +11.2.",
            "source_image_entities": [
                "RU"
            ],
            "source_text_entities": [
                "RUSSIAN"
            ]
        },
        {
            "entity_name": "Ukrainian",
            "entity_type": "GEO",
            "description": "Ukrainian is a Slavic language tested in the WinoMT challenge set for gender bias in machine translation. The country represented in the table has an original score of 38.4 and an adjusted score of 42.9, showing an increase of +4.5.",
            "source_image_entities": [
                "UK"
            ],
            "source_text_entities": [
                "UKRAINIAN"
            ]
        }
    ],
    "image_7": [
        {
            "merged_entity_name": "WinoMT",
            "entity_type": "EVENT",
            "description": "WinoMT is a challenge set for gender bias in machine translation, created by combining the Winogender and WinoBias coreference test sets, used to evaluate machine translation systems, especially in the context of gender bias.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"WINOMT\""
            ]
        },
        {
            "merged_entity_name": "Google Translate",
            "entity_type": "ORGANIZATION",
            "description": "Google Translate is a widely used machine translation model, representing the state of the art in commercial research, showing better performance on pro-stereotypical assignments and deteriorates with antistereotypical roles.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"GOOGLE TRANSLATE\"",
                "\"GOOGLE TRANSLATE\""
            ]
        },
        {
            "merged_entity_name": "Microsoft Translator",
            "entity_type": "ORGANIZATION",
            "description": "Microsoft Translator is a widely used machine translation model, representing the state of the art in commercial research, that performs significantly better on male roles in translation tasks.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"MICROSOFT TRANSLATOR\"",
                "\"MICROSOFT TRANSLATOR\""
            ]
        },
        {
            "merged_entity_name": "German",
            "entity_type": "GEO",
            "description": "German is a Germanic language tested in the WinoMT challenge set for gender bias in machine translation, where translation systems often achieve their best performance, possibly due to its similarity to English.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"GERMAN\"",
                "\"GERMAN\""
            ]
        },
        {
            "merged_entity_name": "Zhao et al.",
            "entity_type": "PERSON",
            "description": "Zhao et al. are referenced for defining stereotypical and non-stereotypical gender role assignments and their impact on translation system performance, providing statistics used by the US Department of Labor to define stereotypical gender roles.",
            "source_image_entities": [],
            "source_text_entities": [
                "\"ZHAO ET AL.\"",
                "\"US DEPARTMENT OF LABOR\""
            ]
        }
    ]
}