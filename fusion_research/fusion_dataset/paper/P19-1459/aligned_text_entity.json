{
    "image_1": [
        {
            "merged_entity_name": "GIST (CHOI AND LEE, 2018)",
            "entity_type": "ORGANIZATION",
            "description": "The GIST model proposed by Choi and Lee in 2018, achieving a mean test score of 0.711 ± 0.01, which is the SemEval winning model, used as a baseline in the experiments for argument comprehension tasks.",
            "source_image_entities": [
                "GIST (CHOI AND LEE, 2018)"
            ],
            "source_text_entities": [
                "GIST"
            ]
        },
        {
            "merged_entity_name": "BILSTM",
            "entity_type": "ORGANIZATION",
            "description": "The Bi-directional Long Short-Term Memory model, achieving a mean test score of 0.552 ± 0.02 and a maximum score of 0.592, which is a baseline model used in the experiments for argument comprehension tasks and introduced by Hochreiter and Schmidhuber.",
            "source_image_entities": [
                "BILSTM"
            ],
            "source_text_entities": [
                "BILSTM"
            ]
        },
        {
            "merged_entity_name": "BOV",
            "entity_type": "ORGANIZATION",
            "description": "The Bag of Visual Words model, achieving a mean test score of 0.564 ± 0.02 and a maximum score of 0.595, which is a baseline model used in the experiments for argument comprehension tasks and utilizes GloVe embeddings provided by Pennington et al.",
            "source_image_entities": [
                "BOV"
            ],
            "source_text_entities": [
                "BOV"
            ]
        }
    ],
    "image_2": [
        {
            "merged_entity_name": "SOFTMAX",
            "entity_type": "TECHNOLOGY",
            "description": "Softmax is a mathematical function used in machine learning, including in the model described in the paper, to turn a vector of real numbers into a probability distribution. It is often used as the activation function for the output layer in neural networks, especially in classification tasks, to determine a probability distribution over the two warrants based on the logits.",
            "source_image_entities": [
                "SOFTMAX"
            ],
            "source_text_entities": [
                "SOFTMAX"
            ]
        }
    ],
    "image_3": [
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a deep learning model used for natural language processing tasks, including the Argument Reasoning Comprehension Task (ARCT). It is a transformer-based model that uses bidirectional training to understand the context of words in a sentence and has shown surprising performance in argument comprehension tasks, but this effectiveness can be attributed to exploiting spurious statistical cues.",
            "source_image_entities": [
                "BERT"
            ],
            "source_text_entities": [
                "BERT"
            ]
        },
        {
            "entity_name": "CLAIM",
            "entity_type": "CONCEPT",
            "description": "Claim refers to a statement in an argument that is supported or attacked by reasons. It is an essential component of the argument structure and is used in the Argument Reasoning Comprehension Task (ARCT) to evaluate model performance on understanding arguments.",
            "source_image_entities": [
                "CLAIM"
            ],
            "source_text_entities": [
                "CLAIM"
            ]
        },
        {
            "entity_name": "REASON",
            "entity_type": "CONCEPT",
            "description": "Reason refers to a statement in an argument that supports or attacks a claim. It provides the explanation or justification for the claim and is a key element in the Argument Reasoning Comprehension Task (ARCT) used to assess model capabilities in argument comprehension.",
            "source_image_entities": [
                "REASON"
            ],
            "source_text_entities": [
                "REASON"
            ]
        },
        {
            "entity_name": "WARRANT",
            "entity_type": "CONCEPT",
            "description": "Warrants are a form of world knowledge that permit inferences and are central to the argumentation mining task discussed in the paper. They serve as the underlying assumption or principle that connects the reason to the claim, and their role is crucial in the Argument Reasoning Comprehension Task (ARCT) for evaluating models' ability to understand argument structures.",
            "source_image_entities": [
                "WARRANT"
            ],
            "source_text_entities": [
                "WARRANTS"
            ]
        }
    ],
    "image_4": [
    ],
    "image_5": [
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a deep learning model used for natural language processing tasks, including argument comprehension, showing surprising performance but attributed to exploiting spurious statistical cues. It has the highest mean test score of 0.671 in certain tasks.",
            "source_image_entities": [
                "BERT"
            ],
            "source_text_entities": [
                "\"BERT\""
            ]
        },
        {
            "entity_name": "BOV",
            "entity_type": "ORGANIZATION",
            "description": "BoV, or Bag of Vectors, is a baseline model used in the experiments for argument comprehension tasks, achieving a mean test score of 0.564 with additional variants showing different performance scores.",
            "source_image_entities": [
                "BOV"
            ],
            "source_text_entities": [
                "\"BOV\""
            ]
        },
        {
            "entity_name": "BILSTM",
            "entity_type": "ORGANIZATION",
            "description": "BiLSTM, or Bidirectional LSTM, is a baseline model used in the experiments for argument comprehension tasks, achieving a mean test score of 0.552 with various weight and regularization adjustments.",
            "source_image_entities": [
                "BILSTM"
            ],
            "source_text_entities": [
                "\"BILSTM\""
            ]
        }
    ],
    "image_6": [
    ],
    "image_7": [
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "The base BERT model with a mean test score of 0.504, a median of 0.505, and a maximum of 0.533, used in experiments to evaluate the exploitation of spurious statistical cues in the ARCT dataset.",
            "source_image_entities": [
                "BERT"
            ],
            "source_text_entities": [
                "BERT"
            ]
        },
        {
            "entity_name": "BERT (W)",
            "entity_type": "ORGANIZATION",
            "description": "The BERT model with weight adjustment, having a mean test score of 0.501, a median of 0.501, and a maximum of 0.502, used in the setup where models are trained only on the warrants to evaluate the exploitation of distributional cues over the labels.",
            "source_image_entities": [
                "BERT (W)"
            ],
            "source_text_entities": [
                "W"
            ]
        },
        {
            "entity_name": "BERT (R, W)",
            "entity_type": "ORGANIZATION",
            "description": "The BERT model with both regularization and weight adjustment, showing a mean test score of 0.500, a median of 0.500, and a maximum of 0.502, used in the setup where models consider cues in the reasons and warrants to evaluate model performance.",
            "source_image_entities": [
                "BERT (R, W)"
            ],
            "source_text_entities": [
                "R, W"
            ]
        },
        {
            "entity_name": "BERT (C, W)",
            "entity_type": "ORGANIZATION",
            "description": "The BERT model with both class weighting and weight adjustment, featuring a mean test score of 0.501, a median of 0.500, and a maximum of 0.518, used in the setup where models consider cues in the claims and warrants to evaluate model performance.",
            "source_image_entities": [
                "BERT (C, W)"
            ],
            "source_text_entities": [
                "C, W"
            ]
        },
        {
            "entity_name": "ARCT",
            "entity_type": "EVENT",
            "description": "ARCT is the event or dataset used for training and testing models, particularly focusing on the presence of statistical cues over labels, and is focused on machine argument comprehension, with the aim of evaluating machine learning models' performance.",
            "source_image_entities": [],
            "source_text_entities": [
                "ARCT",
                "ARCT"
            ]
        }
    ]
}