{
    "image_1": [
        {
            "merged_entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "A deep learning model used for natural language processing tasks, including reading comprehension and as the basis for a single-hop QA model in the research on multi-hop reading comprehension.",
            "source_image_entities": [
                "BERT"
            ],
            "source_text_entities": [
                "BERT"
            ]
        },
        {
            "merged_entity_name": "HOTPOTQA",
            "entity_type": "EVENT",
            "description": "HOTPOTQA is a dataset of mostly compositional questions used in the analysis of multi-hop reading comprehension, consisting of multi-hop questions requiring reasoning over two paragraphs from Wikipedia.",
            "source_image_entities": [
                "QUESTION"
            ],
            "source_text_entities": [
                "HOTPOTQA"
            ]
        },
        {
            "merged_entity_name": "Y_EMPTY",
            "entity_type": "CONCEPT",
            "description": "An output indicating whether the answer is empty or not, used in the single-paragraph BERT model to select the answer from the paragraph with the lowest score.",
            "source_image_entities": [
                "Y_EMPTY"
            ],
            "source_text_entities": [
                "YEMPTY"
            ]
        },
        {
            "merged_entity_name": "SPAN/YES/NO",
            "entity_type": "PERSON",
            "description": "An output indicating the type of answer: a span of text, yes, or no, where yspan, yyes, and yno are scalars generated by the classifier in the single-paragraph BERT model.",
            "source_image_entities": [
                "SPAN/YES/NO"
            ],
            "source_text_entities": [
                "YSPAN",
                "YYES",
                "YNO"
            ]
        },
        {
            "merged_entity_name": "WIKIHOP",
            "entity_type": "EVENT",
            "description": "WIKIHOP is a dataset used in the construction of multi-hop QA datasets, mentioned in the context of multi-hop reading comprehension research, and constructed using knowledge bases.",
            "source_image_entities": [],
            "source_text_entities": [
                "WIKIHOP",
                "WIKIHOP"
            ]
        },
        {
            "merged_entity_name": "COMPLEXWEBQUESTIONS",
            "entity_type": "EVENT",
            "description": "ComplexWebQuestions is an open-domain dataset that uses large distractor sets, mentioned in the multi-hop reading comprehension research, and consists of open-domain compositional questions constructed from WEBQUESTIONS.",
            "source_image_entities": [],
            "source_text_entities": [
                "COMPLEXWEBQUESTIONS",
                "COMPLEXWEBQUESTIONS"
            ]
        }
    ],
    "image_2": [
        {
            "merged_entity_name": "single-paragraph BERT",
            "entity_type": "MODEL",
            "description": "single-paragraph BERT is a model that reads and scores each paragraph independently, achieving a Distractor F1 score of 67.08 and an Open F1 score of 38.40. It selects the answer from the paragraph with the lowest y_empty score, similar to Clark and Gardner (2018).",
            "source_image_entities": [
                "SINGLE-PARAGRAPH BERT*"
            ],
            "source_text_entities": [
                "BERT"
            ]
        },
        {
            "merged_entity_name": "HOTPOTQA",
            "entity_type": "EVENT",
            "description": "HOTPOTQA is a dataset of multi-hop questions requiring reasoning over two paragraphs from Wikipedia, used for evaluating question answering systems with a focus on single-hop and multi-hop reasoning. It consists of two settings: a distractor setting and an open-domain setting. The dataset is used to measure the performance of models like single-paragraph BERT, with F1 scores indicating the model's accuracy.",
            "source_image_entities": [],
            "source_text_entities": [
                "HOTPOTQA",
                "HOTPOTQA",
                "HOTPOTQA",
                "F1 SCORES",
                "DISTRACTOR SETTING",
                "OPEN-DOMAIN SETTING"
            ]
        },
        {
            "merged_entity_name": "BERT",
            "entity_type": "MODEL",
            "description": "BERT is a model used as the basis for a single-hop QA model in the research on multi-hop reading comprehension. It is also used in the single-paragraph BERT approach for answering questions, where it receives a question and a single paragraph as input, and outputs a scalar value y_empty and a text of either span, 'yes', or 'no', based on which of y_span, y_yes, y_no has the largest value.",
            "source_image_entities": [
                "BERT PLUS"
            ],
            "source_text_entities": [
                "BERT",
                "BERT"
            ]
        },
        {
            "merged_entity_name": "WIKIHOP",
            "entity_type": "EVENT",
            "description": "WIKIHOP is a dataset used in the construction of multi-hop QA datasets, mentioned in the context of multi-hop reading comprehension research. It is constructed using knowledge bases and poses questions as triples of a relation and a head entity, with the task being to determine the tail entity of the relationship.",
            "source_image_entities": [],
            "source_text_entities": [
                "WIKIHOP",
                "WIKIHOP"
            ]
        },
        {
            "merged_entity_name": "COMPLEXWEBQUESTIONS",
            "entity_type": "EVENT",
            "description": "COMPLEXWEBQUESTIONS is an open-domain dataset that uses large distractor sets, as mentioned in the multi-hop reading comprehension research. It consists of open-domain compositional questions, constructed by increasing the complexity of SPARQL queries from WEBQUESTIONS.",
            "source_image_entities": [],
            "source_text_entities": [
                "COMPLEXWEBQUESTIONS",
                "COMPLEXWEBQUESTIONS"
            ]
        }
    ],
    "image_3": [
        {
            "entity_name": "RALPH HEFFERLINE",
            "entity_type": "PERSON",
            "description": "Ralph Hefferline is an example of a person used in a multi-hop question where the location of his position as a psychology professor is sought. He was a psychology professor at a university.",
            "source_image_entities": [
                "RALPH HEFFERLINE",
                "UNIVERSITY"
            ],
            "source_text_entities": [
                "RALPH HEFFERLINE"
            ]
        },
        {
            "entity_name": "FILM KISS AND TELL",
            "entity_type": "EVENT",
            "description": "A movie featuring the character Corliss Archer, portrayed by a woman who held a government position.",
            "source_image_entities": [
                "FILM KISS AND TELL",
                "CORLISS ARCHER",
                "GOVERNMENT POSITION"
            ],
            "source_text_entities": [
                "FILM KISS AND TELL"
            ]
        },
        {
            "entity_name": "KAISER VENTURES CORPORATION",
            "entity_type": "ORGANIZATION",
            "description": "An American company founded by an industrialist known as the father of modern American shipbuilding, referred to in the context of questions solvable using only part of the question.",
            "source_image_entities": [
                "KAISER VENTURES CORPORATION",
                "AMERICAN INDUSTRIALIST",
                "FATHER OF MODERN AMERICAN SHIPBUILDING"
            ],
            "source_text_entities": [
                "KAISER VENTURES"
            ]
        },
        {
            "entity_name": "POISON",
            "entity_type": "ORGANIZATION",
            "description": "A band that released an album titled 'Shut Up, Make Love'.",
            "source_image_entities": [
                "POISON",
                "ALBUM 'SHUT UP, MAKE LOVE'"
            ],
            "source_text_entities": []
        }
    ],
    "image_4": [
        {
            "entity_name": "HOTPOTQA",
            "entity_type": "ORGANIZATION",
            "description": "HOTPOTQA is a dataset that consists of multi-hop questions requiring reasoning over two paragraphs from Wikipedia, used for evaluating question answering systems, particularly focusing on single-hop and multi-hop reasoning.",
            "source_image_entities": [
                "HOT ROD"
            ],
            "source_text_entities": [
                "HOTPOTQA",
                "HOTPOTQA",
                "HOTPOTQA"
            ]
        },
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a model used in the single-paragraph BERT approach for answering questions, mentioned in the context of its performance on question compositionality and multi-hop reasoning.",
            "source_image_entities": [
                "HOT ROD"
            ],
            "source_text_entities": [
                "BERT",
                "BERT"
            ]
        },
        {
            "entity_name": "Wikipedia",
            "entity_type": "ORGANIZATION",
            "description": "Wikipedia is the source of all paragraphs considered in the Open-domain Setting of HOTPOTQA and is used as a source for selecting distractor paragraphs based on TF-IDF similarity with the question in the adversarial distractor selection process.",
            "source_image_entities": [],
            "source_text_entities": [
                "WIKIPEDIA",
                "WIKIPEDIA"
            ]
        }
    ],
    "image_5": [
        {
            "entity_name": "TABLE 1",
            "entity_type": "EVENT",
            "description": "Table 1 is referenced to show the F1 scores of single-paragraph BERT in the open-domain setting, indicating the challenge for the single-hop model. It displays the performance of a model on original and adversarial data for both training and evaluation.",
            "source_image_entities": [
                "TABLE"
            ],
            "source_text_entities": [
                "TABLE 1"
            ]
        },
        {
            "entity_name": "TABLE 2",
            "entity_type": "EVENT",
            "description": "Table 2 categorizes bridge questions, showing the distribution of question types in HOTPOTQA and their solvability. It includes information on the performance of the model when trained on original data and when trained on adversarial data, as well as when evaluated on original data and when evaluated on adversarial data.",
            "source_image_entities": [
                "ORIGINAL TRAINING DATA",
                "ADVERSARIAL TRAINING DATA",
                "ORIGINAL EVALUATION DATA",
                "ADVERSARIAL EVALUATION DATA"
            ],
            "source_text_entities": [
                "TABLE 2"
            ]
        },
        {
            "entity_name": "HOTPOTQA",
            "entity_type": "ORGANIZATION",
            "description": "HOTPOTQA is a dataset that consists of multi-hop questions requiring reasoning over two paragraphs from Wikipedia. It is used for evaluating question answering systems, particularly focusing on single-hop and multi-hop reasoning.",
            "source_image_entities": [],
            "source_text_entities": [
                "HOTPOTQA",
                "HOTPOTQA"
            ]
        },
        {
            "entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "BERT is a model used in the single-paragraph BERT approach for answering questions. It is used for language understanding tasks and is mentioned in the context of its performance on question compositionality and multi-hop reasoning.",
            "source_image_entities": [],
            "source_text_entities": [
                "BERT",
                "BERT"
            ]
        },
        {
            "entity_name": "+ TYPE",
            "entity_type": "CONCEPT",
            "description": "The table includes an additional row labeled '+ Type' which may indicate a different type of data or processing. It is used in the context of filtering distractors in the adversarial selection process, aiming to improve the difficulty of the questions.",
            "source_image_entities": [
                "+ TYPE"
            ],
            "source_text_entities": [
                "ENTITY TYPE"
            ]
        }
    ],
    "image_6": [
        {
            "entity_name": "DISTRACTOR",
            "entity_type": "EVENT",
            "description": "A setting where the F1 score is 67.08, involving the accuracy decline from 67.08 F1 to 46.84 F1 when using single-paragraph BERT on new distractors, and increasing to 60.10 F1 after re-training.",
            "source_image_entities": [
                "DISTRACTOR"
            ],
            "source_text_entities": [
                "TABLE 4"
            ]
        },
        {
            "entity_name": "OPEN-DOMAIN 500 PARAGRAPHS",
            "entity_type": "EVENT",
            "description": "A setting where the F1 score is 39.12, indicating the model's performance with 500 retrieved paragraphs, and 53.12 F1 when additional two gold paragraphs are given.",
            "source_image_entities": [
                "OPEN-DOMAIN 500 PARAGRAPHS"
            ],
            "source_text_entities": [
                "TABLE 5"
            ]
        },
        {
            "entity_name": "GOLD PARAGRAPH",
            "entity_type": "EVENT",
            "description": "An additional setting that, when combined with Open-domain 500 Paragraphs, results in an F1 score of 53.12, demonstrating the significant effect of failure to retrieve gold paragraphs.",
            "source_image_entities": [
                "GOLD PARAGRAPH"
            ],
            "source_text_entities": [
                "TABLE 5"
            ]
        }
    ],
    "image_7": [
        {
            "merged_entity_name": "BERT",
            "entity_type": "ORGANIZATION",
            "description": "A deep learning model used for natural language processing tasks, shown in the diagram as a central component that processes input data and generates outputs. It is also mentioned in the text as a model that receives a question and a single paragraph as input, merging them into a single sequence to be processed.",
            "source_image_entities": [
                "BERT"
            ],
            "source_text_entities": [
                "BERT"
            ]
        },
        {
            "merged_entity_name": "QUESTION",
            "entity_type": "EVENT",
            "description": "The input to the BERT model, represented as a sequence of tokens in the diagram, and also mentioned in the text as part of the input to the BERT model, which is a question merged with a paragraph into a single sequence.",
            "source_image_entities": [
                "QUESTION"
            ],
            "source_text_entities": [
                "QUESTION"
            ]
        },
        {
            "merged_entity_name": "PARAGRAPH",
            "entity_type": "EVENT",
            "description": "Another input to the BERT model, also represented as a sequence of tokens in the diagram, and mentioned in the text as a single paragraph that is merged with a question into a single sequence to be processed by BERT.",
            "source_image_entities": [
                "PARAGRAPH"
            ],
            "source_text_entities": [
                "PARAGRAPH"
            ]
        },
        {
            "merged_entity_name": "OUTPUT 1",
            "entity_type": "EVENT",
            "description": "One of the possible outputs from the BERT model, indicating whether the span is empty or contains a yes/no answer, as described in the diagram. It corresponds to the text's description of the BERT model's output, which includes a score indicating the answer is either a span, yes, no, or no answer.",
            "source_image_entities": [
                "OUTPUT 1"
            ],
            "source_text_entities": [
                "OUTPUT 1"
            ]
        },
        {
            "merged_entity_name": "OUTPUT 2",
            "entity_type": "EVENT",
            "description": "Another possible output from the BERT model, similar to Output 1 but with a different index, indicating whether the span is empty or contains a yes/no answer. This corresponds to the text's description of the BERT model's output, which includes a score for different possible answers.",
            "source_image_entities": [
                "OUTPUT 2"
            ],
            "source_text_entities": [
                "OUTPUT 2"
            ]
        },
        {
            "merged_entity_name": "OUTPUT N",
            "entity_type": "EVENT",
            "description": "The final possible output from the BERT model, again indicating whether the span is empty or contains a yes/no answer, as described in the diagram. It corresponds to the text's description of the BERT model's output for HOTPOTQA, where the final answer is selected from multiple possible outputs.",
            "source_image_entities": [
                "OUTPUT N"
            ],
            "source_text_entities": [
                "OUTPUT N"
            ]
        },
        {
            "merged_entity_name": "HOTPOTQA",
            "entity_type": "EVENT",
            "description": "HOTPOTQA is an event or task that involves answering questions based on multiple supporting facts, indicating a complex question-answering challenge, as mentioned in the text. It is also represented in the diagram as a process where the BERT model handles multiple context paragraphs.",
            "source_image_entities": [
                "HOTPOTQA"
            ],
            "source_text_entities": [
                "HOTPOTQA"
            ]
        }
    ],
    "image_8": "[\n    {\n        \"merged_entity_name\": \"NUMERICAL QUESTIONS\",\n        \"entity_type\": \"EVENT\",\n        \"description\": \"NUMERICAL QUESTIONS is a category of questions that involve comparisons using operations such as 'is greater,' 'is smaller,' 'which is greater,' and 'which is smaller.' Examples include determining who was born first between Arthur Conan Doyle and Penelope Lively, and is related to the concept of Comparison Questions mentioned in the text.\",\n        \"source_image_entities\": [\"NUMERICAL QUESTIONS\"],\n        \"source_text_entities\": [\"COMPARISON QUESTIONS\"]\n    },\n    {\n        \"merged_entity_name\": \"LOGICAL QUESTIONS\",\n        \"entity_type\": \"EVENT\",\n        \"description\": \"LOGICAL QUESTIONS is a category of questions that involve logical operations such as 'and,' 'or,' and 'which is true.' An example would be checking if both Hot Rod and the Memory of Our People are magazines, and is related to the concept of Question Operations mentioned in the text.\",\n        \"source_image_entities\": [\"LOGICAL QUESTIONS\"],\n        \"source_text_entities\": [\"QUESTION OPERATIONS\"]\n    },\n    {\n        \"merged_entity_name\": \"STRING QUESTIONS\",\n        \"entity_type\": \"EVENT\",\n        \"description\": \"STRING QUESTIONS is a category of questions that involve string comparisons using operations like 'is equal,' 'not equal,' and 'intersection.' An example is verifying if Cardinal Health and Kansas City Southern are located in the same state, and is related to the concept of Question Operations mentioned in the text.\",\n        \"source_image_entities\": [\"STRING QUESTIONS\"],\n        \"source_text_entities\": [\"QUESTION OPERATIONS\"]\n    },\n    {\n        \"merged_entity_name\": \"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN\",\n        \"entity_type\": \"ORGANIZATION\",\n        \"description\": \"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN is a marine protected area adjacent to the park and administered in conjunction with it, part of the Guadeloupe Archipelago biosphere reserve, and is also known as R´eserve Naturelle Nationale de Saint-Barth´elemy.\",\n        \"source_image_entities\": [\"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN\"],\n        \"source_text_entities\": [\"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN\", \"R´ESERVE NATURELLE NATIONALE DE SAINT-BARTH´ELEMY\"]\n    },\n    {\n        \"merged_entity_name\": \"GUADELOUPE ARCHIPELAGO\",\n        \"entity_type\": \"GEO\",\n        \"description\": \"GUADELOUPE ARCHIPELAGO is a biosphere reserve comprising protected areas including the R´eserve Naturelle du Grand Cul-de-Sac Marin, and is also known as R´eserve Naturelle Nationale de Saint-Barth´elemy.\",\n        \"source_image_entities\": [\"GUADELOUPE ARCHIPELAGO\"],\n        \"source_text_entities\": [\"R´ESERVE NATURELLE DU GRAND CUL-DE-SAC MARIN\", \"R´ESERVE NATURELLE NATIONALE DE SAINT-BARTH´ELEMY\"]\n    },\n    {\n        \"merged_entity_name\": \"LA D´ESIRADE NATIONAL NATURE RESERVE\",\n        \"entity_type\": \"ORGANIZATION\",\n        \"description\": \"LA D´ESIRADE NATIONAL NATURE RESERVE is a reserve in De´sirade Island in Guadeloupe, established for its special geological features, representing the geological heritage of the Caribbean tectonic plate, and was established by Ministerial Decree No. 2011-853 on 19 July 2011.\",\n        \"source_image_entities\": [\"LA D´ESIRADE NATIONAL NATURE RESERVE\"],\n        \"source_text_entities\": [\"DE´SIRADE ISLAND\", \"MINISTERIAL DECREE NO. 2011-853\"]\n    },\n    {\n        \"merged_entity_name\": \"LA TORTUE OU L’ECALLE OR ILE TORTUE\",\n        \"entity_type\": \"GEO\",\n        \"description\": \"LA TORTUE OU L’ECALLE OR ILE TORTUE is a small rocky islet off the northeastern coast of Saint Barth´elemy, part of the R´eserve naturelle nationale de Saint-Barth´elemy.\",\n        \"source_image_entities\": [\"LA TORTUE OU L’ECALLE OR ILE TORTUE\"],\n",
    "image_9": [
        {
            "entity_name": "CATEGORIZE FUNCTION",
            "entity_type": "ORGANIZATION",
            "description": "A function named CATEGORIZE that processes questions to determine the type of operation needed based on keywords and the relationship between the entities, as described in the context of comparison questions and question operations.",
            "source_image_entities": [
                "CATEGORIZE FUNCTION"
            ],
            "source_text_entities": [
                "QUESTION OPERATIONS"
            ]
        },
        {
            "entity_name": "QUESTION",
            "entity_type": "OBJECT",
            "description": "The first parameter of the CATEGORIZE function, representing the question to be analyzed, which is a key component in the process of identifying question operations and classifying comparison questions.",
            "source_image_entities": [
                "QUESTION"
            ],
            "source_text_entities": [
                "COMPARISON QUESTIONS"
            ]
        },
        {
            "entity_name": "ENTITY1 and ENTITY2",
            "entity_type": "OBJECT",
            "description": "Parameters of the CATEGORIZE function, representing the two entities under comparison in a question, which are extracted using the Spacy NER tagger and HOTPOTQA supporting facts to identify suitable question operations.",
            "source_image_entities": [
                "ENTITY1",
                "ENTITY2"
            ],
            "source_text_entities": [
                "COMPARISON QUESTIONS"
            ]
        },
        {
            "entity_name": "SPACY NER TAGGER",
            "entity_type": "TECHNOLOGY",
            "description": "A named entity recognition tool used for extracting entities from text, which is utilized in the process of identifying the two entities under comparison in a question for the CATEGORIZE function.",
            "source_image_entities": [
                "ENTITY1",
                "ENTITY2"
            ],
            "source_text_entities": [
                "SPACY NER TAGGER"
            ]
        },
        {
            "entity_name": "HOTPOTQA",
            "entity_type": "EVENT",
            "description": "An event or task that involves answering questions based on multiple supporting facts, indicating a complex question-answering challenge, which is related to the process of extracting entities and identifying question operations for the CATEGORIZE function.",
            "source_image_entities": [
                "ENTITY1",
                "ENTITY2"
            ],
            "source_text_entities": [
                "HOTPOTQA"
            ]
        }
    ]
}