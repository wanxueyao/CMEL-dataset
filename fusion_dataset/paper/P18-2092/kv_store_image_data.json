{
    "image_1": {
        "image_id": 1,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-2092/images/image_1.jpg",
        "caption": [
            "Table 1: Dataset description. "
        ],
        "footnote": [],
        "context": "Combined (PRET $^{\\ast}$ MULT): In this setting, we first perform PRET on document-level examples. We use the where $U$ is the loss function of document-level classification. $\\lambda\\in(0,1)$ is a hyperparameter that controls the weight of $U$ . $$ L=J+\\lambda U $$ Multi-task Learning (MULT): This approach simultaneously trains two tasks – document-level and aspect-level classification. In this setting, the embedding layer $(\\mathbf{E})$ and the LSTM layer $(\\theta_{l s t m})$ are shared by both tasks, and a document is represented as the mean vector over LSTM outputs. The other parameters are task-specific. The overall loss function is then given by:  This network is the same as the $\\scriptstyle\\mathrm{LSTM+ATT}$ apart from the lack of the attention layer. The training objective is also cross entropy minimization as shown in equation (7) and the parameter set is $\\theta_{d o c}=\\left\\{\\mathbf{E}^{\\prime},\\theta_{l s t m}^{\\prime},\\mathbf{W}_{o}^{\\prime},\\mathbf{b}_{o}^{\\prime}\\right\\}$ . Pretraining (PRET): In this setting, we first train on document-level examples. The last hidden vector from the LSTM outputs is used as the document representation. We initialize the relevant parameters $\\mathbf{E},\\theta_{l s t m},\\mathbf{W}_{o},\\mathbf{b}_{o}$ of $\\scriptstyle\\mathrm{LSTM+ATT}$ with the pretrained weights, and train it on aspect-level examples to fine tune those weights and learn ${\\mathbf W}_{a}$ which is randomly initialized. ",
        "chunk_order_index": 1,
        "chunk_id": "chunk-a9d85e81b9f0513a01a9c45e5f5ca334",
        "description": "The image is a table labeled 'Table 1: Dataset description' that provides detailed statistics for four different datasets, each related to restaurant and laptop reviews. The table is structured with the following columns: Dataset, Pos (Positive), Neg (Negative), and Neu (Neutral). Each row represents a specific dataset split into train and test sets. The datasets are as follows: D1 includes Restaurant14-Train with 2164 positive, 807 negative, and 637 neutral reviews; Restaurant14-Test with 728 positive, 196 negative, and 196 neutral reviews. D2 includes Laptop14-Train with 994 positive, 870 negative, and 464 neutral reviews; Laptop14-Test with 341 positive, 128 negative, and 169 neutral reviews. D3 includes Restaurant15-Train with 1178 positive, 382 negative, and 50 neutral reviews; Restaurant15-Test with 439 positive, 328 negative, and 35 neutral reviews. D4 includes Restaurant16-Train with 1620 positive, 709 negative, and 88 neutral reviews; Restaurant16-Test with 597 positive, 190 negative, and 38 neutral reviews. The table highlights the distribution of sentiment in each dataset, showing a significant number of positive reviews across all datasets.",
        "segmentation": false
    },
    "image_2": {
        "image_id": 2,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-2092/images/image_2.jpg",
        "caption": [],
        "footnote": [],
        "context": "Table 2 indicates that a large percentage of the performance gain comes from PRET. To better understand the transfer effects of different layers – embedding layer $(\\mathbf{E})$ , LSTM layer $(\\theta_{l s t m})$ , and output layer $(\\mathbf{W}_{o},\\mathbf{b}_{o})-\\mathbf{W}\\mathbf{e}$ conduct ablation tests on PRET with different layers transfered from the document-level model to the aspect-level model. Results are presented in Table 3. “LSTM only” denotes the setting where only the LSTM layer is transferred, and “Without LSTM” denotes the setting where only the embedding and output layers are transferred (excluding the LSTM layer). The key observations are: 4.3 Ablation Tests   neutral examples in the training set. A classifier without any external knowledge might still be able to learn some neutral-related features on D1 but it is very hard to learn from D3 and D4. (2) The numbers of neutral examples in the test sets of D3 and D4 are very small. Thus, the precision and recall on neutral class will be largely affected by even a small prediction difference (e.g., with 5 more neutral examples correctly identified, recall is increased by more than $10\\%$ on both datasets). As a result, the macro-F1 scores on D3 and D4 are affected more. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-6d8118bdf1f553a8ea6f4ffad4e15eaf",
        "description": "The image is a table that presents the performance of different methods on four datasets (D1, D2, D3, and D4) in terms of accuracy (Acc.) and Macro-F1 scores. The table includes the following rows: 'Tang et al. (2016a)', 'Wang et al. (2016)', 'Tang et al. (2016b)', 'Chen et al. (2017)', 'LSTM', 'LSTM+ATT', 'Ours: PRET', 'Ours: MULT', and 'Ours: PRET+MULT'. Each row contains the Acc. and Macro-F1 values for each dataset. For example, 'Tang et al. (2016a)' has an Acc. of 75.37 and a Macro-F1 of 64.51 for D1, an Acc. of 68.25 and a Macro-F1 of 65.96 for D2, an Acc. of 76.39 and a Macro-F1 of 58.70 for D3, and an Acc. of 82.16 and a Macro-F1 of 54.21 for D4. The highest values are highlighted in bold, such as 'Ours: PRET+MULT' with an Acc. of 79.11 and a Macro-F1 of 69.73 for D1, an Acc. of 71.15 and a Macro-F1 of 67.46 for D2, an Acc. of 81.30 and a Macro-F1 of 68.74 for D3, and an Acc. of 85.58 and a Macro-F1 of 69.76 for D4.",
        "segmentation": false
    },
    "image_3": {
        "image_id": 3,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-2092/images/image_3.jpg",
        "caption": [
            "Table 2: Average accuracies and Macro-F1 scores over 5 runs with random initialization. The best results are in bold. ∗indicates that PRET $^+$ MULT is significantly better than Tang et al. (2016a), Wang et al. (2016), Tang et al. (2016b), Chen et al. (2017), LSTM, and LSTM+ATT with $p<0.05$ according to one-tailed unpaired t-test. ",
            "Table 3: PRET with different transferred layers. Averaged results over 5 runs are reported. "
        ],
        "footnote": [],
        "context": "Table 2 indicates that a large percentage of the performance gain comes from PRET. To better understand the transfer effects of different layers – embedding layer $(\\mathbf{E})$ , LSTM layer $(\\theta_{l s t m})$ , and output layer $(\\mathbf{W}_{o},\\mathbf{b}_{o})-\\mathbf{W}\\mathbf{e}$ conduct ablation tests on PRET with different layers transfered from the document-level model to the aspect-level model. Results are presented in Table 3. “LSTM only” denotes the setting where only the LSTM layer is transferred, and “Without LSTM” denotes the setting where only the embedding and output layers are transferred (excluding the LSTM layer). The key observations are: 4.3 Ablation Tests  neutral examples in the training set. A classifier without any external knowledge might still be able to learn some neutral-related features on D1 but it is very hard to learn from D3 and D4. (2) The numbers of neutral examples in the test sets of D3 and D4 are very small. Thus, the precision and recall on neutral class will be largely affected by even a small prediction difference (e.g., with 5 more neutral examples correctly identified, recall is increased by more than $10\\%$ on both datasets). As a result, the macro-F1 scores on D3 and D4 are affected more.  ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-6d8118bdf1f553a8ea6f4ffad4e15eaf",
        "description": "The image is a table labeled 'Table 3: PRET with different transferred layers.' It presents the average accuracies and Macro-F1 scores over 5 runs with random initialization for different settings. The table has six rows and five columns. The first column lists the settings: LSTM only, Embeddings only, Output layer only, Without LSTM, Without embeddings, and Without output layer. The subsequent four columns are labeled D1, D2, D3, and D4, each containing two sub-columns for Acc. (Accuracy) and Macro-F1. The values are as follows: For LSTM only, Acc. and Macro-F1 are 78.09 and 67.85 for D1, 71.04 and 66.80 for D2, 78.95 and 65.30 for D3, and 83.85 and 67.11 for D4. For Embeddings only, the values are 77.12 and 67.19 for D1, 69.12 and 65.06 for D2, 80.13 and 67.04 for D3, and 84.12 and 70.11 for D4. For Output layer only, the values are 76.88 and 66.81 for D1, 69.63 and 66.07 for D2, 78.30 and 64.49 for D3, and 82.55 and 62.83 for D4. For Without LSTM, the values are 77.45 and 67.25 for D1, 69.82 and 66.63 for D2, 80.27 and 68.02 for D3, and 84.80 and 70.27 for D4. For Without embeddings, the values are 77.97 and 67.96 for D1, 70.59 and 67.16 for D2, 79.08 and 65.56 for D3, and 83.94 and 68.79 for D4. For Without output layer, the values are 78.36 and 68.06 for D1, 71.10 and 67.87 for D2, 80.82 and 67.68 for D3, and 84.71 and 70.48 for D4.",
        "segmentation": false
    },
    "image_4": {
        "image_id": 4,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-2092/images/image_4.jpg",
        "caption": [
            "Figure 1: Results of PRET $^{\\ast}$ MULT vs. percentage of document-level training data. "
        ],
        "footnote": [],
        "context": "1. “I was highly disappointed in the [food]neg.” 2. “This particular location certainly uses substandard [meats]neg.”， First of all, to our surprise, LSTM+ATT made obvious mistakes on some instances with common opinion words. Below are two examples where the target is enclosed in [] with its true sentiment indicated in the subscript: To better understand in which conditions the proposed method is helpful, we analyze a subset of test examples that are correctly classified by PRET $^{\\dagger}+$ MULT but are misclassified by LSTM $\\pm$ ATT. We find that the benefits brought by document-level knowledge are typically shown in four ways.  for PRET $+.$ MULT. The changes of accuracies and macro-F1 scores on the four datasets are shown in Figure 1. The improvements on accuracies with increasing number of document examples are stable across all datasets. For macro-F1 scores, the improvements on D1 and D2 are stable. We observe sharp increases in the macro-F1 scores of D3 and D4 when changing the percentage from 0 to 0.4. This may be related to their extremely unbalanced label distribution. In such cases, with the knowledge gained from a small number of balanced document-level examples, aspect-level predictions on neutral examples can be significantly improved. ",
        "chunk_order_index": 3,
        "chunk_id": "chunk-ddd8e630fafbfecd379fe586dd58009d",
        "description": "The image consists of two line graphs, each depicting the performance metrics of different datasets as a function of the percentage of document-level training examples. The top graph shows the accuracy (%) for four datasets labeled D1, D2, D3, and D4. The x-axis represents the percentage of document-level training examples, ranging from 0 to 1, while the y-axis represents the accuracy in percentage, ranging from 65% to 85%. The lines for D1 (blue squares), D2 (orange circles), D3 (gray diamonds), and D4 (red crosses) show an increasing trend with the increase in the percentage of document-level training examples. The bottom graph shows the macro-F1 scores (%) for the same datasets. The x-axis is the same as the top graph, while the y-axis ranges from 60% to 70%. The lines for D1 (blue squares), D2 (orange circles), D3 (gray diamonds), and D4 (red crosses) also show an increasing trend, with some fluctuations. Notably, D3 and D4 exhibit sharp increases in macro-F1 scores when the percentage of document-level training examples changes from 0 to 0.4.",
        "segmentation": false
    }
}