{
    "image_1": {
        "entity_name": "Figure 1",
        "entity_type": "EVENT",
        "description": "Wikipedia talk page discussions is the event where the dataset is compiled, consisting of conversations that begin civilly and either remain healthy or derail into personal attacks.",
        "reason": "The image depicts a screenshot of a conversation thread from a Wikipedia talk page discussing the reliability of sources for an article about the Dyatlov Pass Incident. This aligns with the concept of 'Wikipedia talk page discussions' as described in the text information.",
        "matched_chunk_entity_name": "no match"
    },
    "image_2": {
        "entity_name": "Table 1: Descriptions of crowdsourcing jobs, with relevant statistics.",
        "entity_type": "CONCEPT",
        "description": "The table provides a summary of two crowdsourcing jobs aimed at identifying personal attacks and toxic comments in conversations. Job 1 involves determining if the last comment in a conversation is a personal attack, while Job 2 assesses whether any comment in a snippet of three consecutive comments is toxic. The table includes statistics on the number of annotators, conversations, snippets, and agreement rates for each job.",
        "reason": "The image clearly shows a table labeled 'Table 1: Descriptions of crowdsourcing jobs, with relevant statistics.' which aligns with the description provided in the text. The content of the table matches the details given in the text about the two jobs and their respective statistics.",
        "matched_chunk_entity_name": "no match"
    },
    "image_3": {
        "entity_name": "Table 2: Prompt types automatically extracted from talk page conversations, with interpretations and examples from the data.",
        "entity_type": "CONCEPT",
        "description": "The table is structured with three main columns: Prompt Type, Description, and Examples. Each row represents a different prompt type and contains the following information:\n\n1. **Factual check**: Statements about article content, pertaining to or contending issues like factual accuracy. Examples include 'The terms are used interchangeably in the US.' and 'The census is not talking about families here.'\n\n2. **Moderation**: Rebukes or disputes concerning moderation decisions such as blocks and reversions. Examples include 'If you continue, you may be blocked from editing.' and 'He’s accused me of being a troll.'\n\n3. **Coordination**: Requests, questions, and statements of intent pertaining to collaboratively editing an article. Examples include 'It’s a long list so I could do with your help.' and 'Let me know if you agree with this and I’ll go ahead [...]' \n\n4. **Casual remark**: Casual, highly conversational aside-remarks. Examples include 'What’s with this flag image?' and 'I’m surprised there wasn’t an article before.'\n\n5. **Action statement**: Requests, statements, and explanations about various editing actions. Examples include 'Please consider improving the article to address the issues [...]' and 'The page was deleted as self-promotion.'\n\n6. **Opinion**: Statements seeking or expressing opinions about editing challenges and decisions. Examples include 'I think that it should be the other way around.' and 'This article seems to have a lot of bias.'\n\nThe table highlights the variety of prompt types found in Wikipedia talk page conversations, ranging from factual checks and moderation disputes to coordination requests and casual remarks.",
        "reason": "The image clearly shows a table labeled 'Table 2' which matches the description provided in the text. The table is structured with three main columns: Prompt Type, Description, and Examples, and each row represents a different prompt type.",
        "matched_chunk_entity_name": "no match"
    },
    "image_4": {
        "entity_name": "Figure 2: Log-odds ratios of politeness strategies and prompt types",
        "entity_type": "CONCEPT",
        "description": "The image depicts log-odds ratios of politeness strategies and prompt types in the first and second comments of conversations that turn awry versus those that stay on-track. The scatter plots show various linguistic features such as 'Direct question', '2nd person start', 'Prompt: Factual check', etc., with their corresponding log-odds ratios.",
        "reason": "The image clearly shows three scatter plots labeled A, B, and C, which display log-odds ratios of politeness strategies and prompt types in the context of conversation trajectories. This matches the description provided in the text, indicating the focus on linguistic markers and their association with conversation outcomes.",
        "matched_chunk_entity_name": "no match"
    },
    "image_5": {
        "entity_name": "Table 3",
        "entity_type": "GEO",
        "description": "Table 3 is a reference to the summary of prediction accuracies for the balanced future prediction task.",
        "reason": "The image clearly shows Table 3, which summarizes the accuracies for different feature sets in predicting future attacks in conversations. The table matches the description provided in the text and contains the same information about various features and their corresponding accuracies.",
        "matched_chunk_entity_name": "TABLE 3"
    }
}