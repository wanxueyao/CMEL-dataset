<?xml version='1.0' encoding='UTF-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="order" attr.type="long"/>
<key id="d5" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;IMAGE_9&quot;">
  <data key="d0">"ORI_IMG"</data>
  <data key="d1">"The image is a table labeled 'Table 4: Results on the GLUE benchmark test set.' The table compares the performance of two models, BERTBASE (OURS) and SenseBERTBASE, across various NLP tasks. The columns represent different tasks in the GLUE benchmark: Score, CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, and RTE. Each row corresponds to a model. For BERTBASE (OURS), the scores are as follows: Score = 77.5, CoLA = 50.1, SST-2 = 92.6, MRPC = 88.7/84.3, STS-B = 85.7/84.6, QQP = 71.0/88.9, MNLI = 83.6, QNLI = 89.4, and RTE = 67.9. For SenseBERTBASE, the scores are: Score = 77.9, CoLA = 54.6, SST-2 = 92.2, MRPC = 89.2/85.2, STS-B = 83.5/82.3, QQP = 70.3/88.8, MNLI = 83.6, QNLI = 90.6, and RTE = 67.5. The table highlights the performance metrics for each task, with some tasks having two values separated by a slash, indicating possibly different evaluation metrics or subsets."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;BERT_BASE (OURS)&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"A model configuration of BERT used for various natural language processing tasks, achieving specific scores across different benchmarks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;SENSEBERT_BASE&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"Another model configuration of BERT designed for semantic understanding, with its own set of performance metrics across multiple benchmarks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;SCORE&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"The overall performance metric summarizing the effectiveness of the models across all tasks."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;COLA&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"The Corpus of Linguistic Acceptability, a task assessing the grammatical correctness of English sentences."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;SST-2&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"The Stanford Sentiment Treebank, a dataset used for sentiment analysis on movie reviews."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;MRPC&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Microsoft Research Paraphrase Corpus, a dataset for identifying paraphrases among pairs of sentences."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;STS-B&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Semantic Textual Similarity Benchmark, a task measuring the degree of similarity between sentence pairs."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;QQP&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Quora Question Pairs, a dataset for detecting duplicate questions."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;MNLI&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Multi-Genre Natural Language Inference, a task involving textual entailment across diverse genres."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;QNLI&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Question Natural Language Inference, a version of the SQuAD dataset adapted for natural language inference."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<node id="&quot;RTE&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Recognizing Textual Entailment, a task to determine if one text can be inferred from another."</data>
  <data key="d2">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
</node>
<edge source="&quot;IMAGE_9&quot;" target="&quot;BERT_BASE (OURS)&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"BERT_BASE (OURS)是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;SENSEBERT_BASE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"SenseBERT_BASE是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;SCORE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"Score是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;COLA&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"CoLA是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;SST-2&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"SST-2是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;MRPC&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"MRPC是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;STS-B&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"STS-B是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;QQP&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"QQP是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;MNLI&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"MNLI是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;QNLI&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"QNLI是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;IMAGE_9&quot;" target="&quot;RTE&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"RTE是从image_9中提取的实体。"</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;SCORE&quot;">
  <data key="d3">9.0</data>
  <data key="d4">"The model's overall performance is quantified by this score."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;COLA&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in assessing grammatical correctness of sentences."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;SST-2&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in sentiment analysis on movie reviews."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;MRPC&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in identifying paraphrases among sentence pairs."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;STS-B&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in measuring semantic similarity between sentences."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;QQP&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in detecting duplicate questions."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;MNLI&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in textual entailment across diverse genres."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;QNLI&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in question-based natural language inference."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;BERT_BASE (OURS)&quot;" target="&quot;RTE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in recognizing textual entailment."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;SCORE&quot;">
  <data key="d3">9.0</data>
  <data key="d4">"The model's overall performance is quantified by this score."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;COLA&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in assessing grammatical correctness of sentences."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;SST-2&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in sentiment analysis on movie reviews."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;MRPC&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in identifying paraphrases among sentence pairs."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;STS-B&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in measuring semantic similarity between sentences."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;QQP&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in detecting duplicate questions."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;MNLI&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in textual entailment across diverse genres."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;QNLI&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in question-based natural language inference."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
<edge source="&quot;SENSEBERT_BASE&quot;" target="&quot;RTE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"Performance in recognizing textual entailment."</data>
  <data key="d5">./fusion_research/fusion_dataset/paper/2020.acl-main.423/images/image_9.jpg</data>
  <data key="d6">1</data>
</edge>
</graph></graphml>
