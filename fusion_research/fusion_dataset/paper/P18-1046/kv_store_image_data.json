{
    "image_1": {
        "image_id": 1,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_1.jpg",
        "caption": [],
        "footnote": [],
        "context": "With the infinite amount of facts in real world, it is extremely expensive, and almost impossible for human annotators to annotate training dataset to meet the needs of all walks of life. This problem has received increasingly attention. Fewshot learning and Zero-shot Learning (Xian et al., 2017) try to predict the unseen classes with few labeled data or even without labeled data. Differently, distant supervision (Mintz et al., ple, given a sentence “The $[o w l]_{e1}$ held the mouse in its $[c l a w]_{e2}.^{\\circ}$ , a relation classifier should figure out the relation Component-Whole between entity owl and claw.  dataset for relation classification. The experimental results show that the proposed strategy significantly improves the performance of distant supervision relation extraction comparing to state-of-the-art systems. 1 Introduction Relation extraction is a crucial task in the field of natural language processing (NLP). It has a wide range of applications including information retrieval, question answering, and knowledge base completion. The goal of relation extraction system is to predict relation between entity pair in a sentence (Zelenko et al., 2003; Bunescu and Mooney, 2005; GuoDong et al., 2005). For examFigure 1: Illustration of the distant supervision training data distribution for one relation type. ",
        "chunk_order_index": 0,
        "chunk_id": "chunk-cbe821d1d4bb89d10c3be428e8b0b4ee",
        "description": "The image is a diagram illustrating the distribution of distant supervision (DS) training data for one relation type. The main elements include various symbols representing different types of data points: blue circles represent DS true positive data, yellow triangles represent DS false positive data, and red crosses represent DS negative data. There are two decision boundaries depicted: a dashed line represents the desired decision boundary, while a solid line with dashes represents the actual decision boundary of DS data. The background is a simple white space with a rounded rectangle framing the data points. The legend on the left side of the image explains the meaning of each symbol and line.",
        "segmentation": false
    },
    "image_2": {
        "image_id": 2,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_2.jpg",
        "caption": [],
        "footnote": [],
        "context": "This generated dataset $T$ consists of the highconfidence sentences, and Figure 2: An overview of the DSGAN training pipeline. The generator (denoted by G) calculates the probability distribution over a bag of DS positive samples, and then samples according to this probability distribution. The high-confidence samples generated by G are regarded as true positive samples. The discriminator (denoted by $\\mathbf{D}$ ) receives these high-confidence samples but regards them as negative samples; conversely, the low-confidence samples are still treated as positive samples. For the generated samples, G maximizes the probability of being true positive; on the contrary, D minimizes this probability. network parameters $\\theta_{G},\\theta_{D}$ are updated when finishing processing one bag $B_{i}^{\\,1}$ . Based on the notion of adversarial learning, we define the objectives of the generator and the discriminator as follow, and they are alternatively trained towards their respective objectives. Generator Suppose that the generator produces a set of probability distribution $\\{p_{G}(s_{j})\\}_{j=1\\ldots|B_{i}|}$ for a sentence bag $B_{i}$ . Based on these probabilities, a set of sentence are sampled and we denote this set as $T$ . $$ T=\\{s_{j}\\},s_{j}\\sim p_{G}(s_{j}),j=1,2,...,|B_{i}| $$ 1The bag here has the different definition from the sentence bag of an entity pair mentioned in the Section 1. ",
        "chunk_order_index": 2,
        "chunk_id": "chunk-8f28924f070a33438cba8f13b0ebb0d4",
        "description": "The image is a flowchart illustrating the training pipeline of a Deep Supervised Generative Adversarial Network (DSGAN). The process is divided into four main stages: DS Positive Dataset, Generator, Sampling, and Discriminator. In the DS Positive Dataset stage, multiple bags of positive samples are shown, labeled as Bag_{k-1}, Bag_k, and Bag_{k+1}. Each bag contains sentences denoted as s_1, s_2, ..., s_n. The Generator (G) takes these sentences as input and outputs probabilities p_1, p_2, ..., p_n for each sentence. These probabilities range from 0.02 to 0.90. The Sampling stage then divides the generated samples into two categories: low-confidence samples with label = 1 and high-confidence samples with label = 0. The low-confidence samples are fed into the Discriminator (D), which treats them as negative samples, while the high-confidence samples are treated as positive samples. The Discriminator's goal is to minimize the probability of the high-confidence samples being true positives. The network parameters \\\\theta_G and \\\\theta_D are updated after processing one bag B_i. Pre-training is also indicated on the right side of the flowchart, where the Discriminator is pre-trained on both DS positive and negative datasets.",
        "segmentation": false
    },
    "image_3": {
        "image_id": 3,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_3.jpg",
        "caption": [],
        "footnote": [
            "Table 1: Hyperparameter settings of the generator and the discriminator. "
        ],
        "context": "Due to the absence of the corresponding labeled dataset, there is not a ground-truth test dataset to evaluate the performance of distant supervision relation extraction system. Under this circumstance, the previous work adopt the held-out evaluation to evaluate their systems, which can provide an approximate measure of precision without requiring costly human evaluation. It builds a test set where entity pairs are also extracted from Freebase. Similarly, relation facts that discovered from test articles are automatically compared with those in Freebase. CNN is widely used in relation classification (Santos et al., 2015; Qin et al., 2017), thus the generator and  dataset. Freebase is a huge knowledge base including billions of triples: the entity pair and the specific relationship between them. Given these triples, the sentences of each entity pair are selected from the New York Times corpus(NYT). Entity mentions of NYT corpus are recognized by the Stanford named entity recognizer (Finkel et al., 2005). There are 52 actual relationships and a special relation $N A$ which indicates there is no relation between head and tail entities. Entity pairs of $N A$ are defined as the entity pairs that appear in the same sentence but are not related according to Freebase. ",
        "chunk_order_index": 4,
        "chunk_id": "chunk-af18035bfe085a9422d8b192bf90d8e4",
        "description": "The image is a table labeled 'Hyperparameter settings of the generator and the discriminator.' The table contains four rows and two columns. The first column lists the hyperparameters, and the second column provides their respective values. The hyperparameters and their values are as follows: CNN Window \\( c_w \\), kernel size \\( c_k \\) with values 3 and 100; Word embedding \\( d_e \\), vocabulary size \\( |V| \\) with values 50 and 114042; Position embedding \\( d_p \\) with a value of 5; Learning rate of G (generator) and D (discriminator) with values 1e-5 and 1e-4 respectively. The table provides specific settings for the neural network architecture used in the relation extraction system.",
        "segmentation": false
    },
    "image_4": {
        "image_id": 4,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_4.jpg",
        "caption": [],
        "footnote": [],
        "context": "Figure 3: The convergence of the DSGAN training process for 3 relation types and the performance of their corresponding generators. The figures in the first row present the performance change on $N^{D}$ in some specific epochs during processing the $B\\,=\\,\\{B^{1},B^{2},{\\bar{.}}...B^{N}\\}$ . Each curve stands for one epoch; The color of curves become darker as long as the epoch goes on. Because the discriminator reloads the pre-trained parameters at the beginning of each epoch, all curves start from the same point for each relation type; Along with the adversarial training, the generator gradually collapses the discriminator. The figures in the second adversarial learning is widely regarded as an effective but unstable technique, here we illustrate some property changes during the training process, in which way to indicate the learning trend of our proposed approach. We use 3 relation types as the examples: /business/person/company, /people/person/place lived and /location/neighborhood/neighborhood of. Because they are from three major classes (bussiness, people, location) of Reidel dataset and they all have enough distant-supervised instances. The first row in Figure 3 shows the classification ability change of the discriminator during training. The accuracy is calculated from the negative set $N^{D}$ . At the beginning of adversarial learning, the ",
        "chunk_order_index": 4,
        "chunk_id": "chunk-af18035bfe085a9422d8b192bf90d8e4",
        "description": "The image consists of six graphs, arranged in two rows and three columns. Each graph represents the performance change during the training process for different relation types using DSGAN. The first row shows the accuracy of the discriminator over epochs for three relation types: /business/person/company, /people/person/place_lived, and /location/neighborhood/neighborhood_of. The x-axis represents the bag sequence, ranging from 1 to 17, while the y-axis represents the accuracy, ranging from approximately 0.8 to 1.0. Each curve corresponds to a specific epoch, with darker colors indicating later epochs. The curves start from the same point at the beginning of each epoch due to the discriminator reloading pre-trained parameters. As the epochs progress, the accuracy generally decreases, indicating that the generator is gradually collapsing the discriminator. The second row shows the F1 score over epochs for the same three relation types. The x-axis represents the epoch number, ranging from 6 to 28, while the y-axis represents the F1 score, ranging from approximately 0.7 to 1.0. Three lines are plotted for each graph: Random (black triangles), Pre-training (blue circles), and DSGAN (red squares). The F1 score generally increases as the epochs progress, with DSGAN consistently outperforming the other methods.",
        "segmentation": false
    },
    "image_5": {
        "image_id": 5,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_5.jpg",
        "caption": [
            "Figure 4: The performance change of the discriminator on $N^{D}$ during the training process. Each point in the curves records the prediction accuracy on $N^{D}$ when finishing each epoch. We stop the training process when this accuracy no longer decreases. "
        ],
        "footnote": [],
        "context": "Based on the proposed adversarial learning process, we obtain a generator that can recognize the true positive samples from the noisy distant supervision dataset. Naturally, the improvement of distant supervision relation extraction can provide a intuitive evaluation of our generator. We adopt the strategy mentioned in Section 3.3 to relocate the dataset. After obtaining this redistributed dataset, we apply it to train the recent state-of-the-art models and observe whether it brings further improvement for these systems. Zeng et al. (2015) and Lin et al. (2016) are both the robust models to solve wrong 4.4 Performance on Distant Supervision Relation Extraction  and the positive set base on the DSGAN generator. For the pre-trained generator, the positive set is selected according to the probability of being positive from high to low. These three sets have the same size and are accompanied by the same negative set. Obviously, the positive set from the DSGAN generator yields the best performance, which indicates that our adversarial learning process is able to produce a robust true-positive generator. In addition, the pre-trained generator also has a good performance; however, compared with the DSGAN generator, it cannot provide the boundary between the false positives and the true positives. ",
        "chunk_order_index": 5,
        "chunk_id": "chunk-4e236190c748f858736f0dbadbca362d",
        "description": "The image is a line graph depicting the performance change of the discriminator on $N^{D}$ during the training process. The x-axis represents the epoch number, ranging from 5 to 85, while the y-axis shows the accuracy, ranging from 0.5 to 1.05. There are three distinct lines representing different categories: '/business/person/company' (blue triangles), '/people/person/place_lived' (red squares), and '/location/neighborhood/neighborhood_of' (black circles). The blue triangles start at an accuracy of approximately 0.95 and show a slight downward trend, ending around 0.85. The red squares start at an accuracy of approximately 0.75 and also show a slight downward trend, ending around 0.7. The black circles start at an accuracy of approximately 1.0 and show a more stable trend, ending around 0.95. The graph indicates that the accuracy of the discriminator decreases over epochs for all categories, with '/location/neighborhood/neighborhood_of' maintaining the highest accuracy throughout.",
        "segmentation": false
    },
    "image_6": {
        "image_id": 6,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_6.jpg",
        "caption": [
            "Figure 5: Aggregate PR curves of CNN˙based model. "
        ],
        "footnote": [],
        "context": "Even though Zeng et al. (2015) and Lin et al. (2016) are designed to alleviate the influence of false positive samples, both of them merely focus on the noise filtering in the sentence bag of entity pairs. Zeng et al. (2015) combine at-least-one multi-instance learning with deep neural network to extract only one active sentence to represent the target entity pair; Lin et al. (2016) assign soft attention weights to the representations of all sentences of one entity pair, then employ the weighted sum of these representations to predict the relation between the target entity pair. However, from our manual   We adopt the strategy mentioned in Section 3.3 to relocate the dataset. After obtaining this redistributed dataset, we apply it to train the recent state-of-the-art models and observe whether it brings further improvement for these systems. Zeng et al. (2015) and Lin et al. (2016) are both the robust models to solve wrong labeling problem of distant supervision relation extraction. According to the comparison displayed in Figure 5 and Figure 6, all four models $(C N N+O N E$ ,$C N N{+}A T T$ ,$P C N N{+}O N E$ and $P C N N{+}A T T)$ achieve further improvement. ",
        "chunk_order_index": 5,
        "chunk_id": "chunk-4e236190c748f858736f0dbadbca362d",
        "description": "The image is a precision-recall (PR) curve graph comparing four different CNN-based models. The x-axis represents Recall, ranging from 0 to 0.4, and the y-axis represents Precision, ranging from 0.3 to 1.0. Four curves are plotted on the graph, each representing a different model configuration: CNN+ONE (blue triangles), CNN+ONE+DSGAN (red circles), CNN+ATT (black squares), and CNN+ATT+DSGAN (magenta stars). The curves show the trade-off between precision and recall for each model. The CNN+ONE+DSGAN model starts with the highest precision but drops rapidly as recall increases. The CNN+ATT+DSGAN model maintains a relatively high precision across a wider range of recall values compared to the other models. The CNN+ONE and CNN+ATT models have similar trends, with the CNN+ATT model generally having slightly higher precision at lower recall values.",
        "segmentation": false
    },
    "image_7": {
        "image_id": 7,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_7.jpg",
        "caption": [
            "Figure 6: Aggregate PR curves of PCNN˙based model. "
        ],
        "footnote": [],
        "context": "Even though Zeng et al. (2015) and Lin et al. (2016) are designed to alleviate the influence of false positive samples, both of them merely focus on the noise filtering in the sentence bag of entity pairs. Zeng et al. (2015) combine at-least-one multi-instance learning with deep neural network to extract only one active sentence to represent the target entity pair; Lin et al. (2016) assign soft attention weights to the representations of all sentences of one entity pair, then employ the weighted sum of these representations to predict the relation between the target entity pair. However, from our manual  We adopt the strategy mentioned in Section 3.3 to relocate the dataset. After obtaining this redistributed dataset, we apply it to train the recent state-of-the-art models and observe whether it brings further improvement for these systems. Zeng et al. (2015) and Lin et al. (2016) are both the robust models to solve wrong labeling problem of distant supervision relation extraction. According to the comparison displayed in Figure 5 and Figure 6, all four models $(C N N+O N E$ ,$C N N{+}A T T$ ,$P C N N{+}O N E$ and $P C N N{+}A T T)$ achieve further improvement.  ",
        "chunk_order_index": 5,
        "chunk_id": "chunk-4e236190c748f858736f0dbadbca362d",
        "description": "The image is a graph depicting the Precision-Recall (PR) curves of four different PCNN-based models. The x-axis represents Recall, ranging from 0 to 0.4, while the y-axis represents Precision, ranging from 0.4 to 1.0. Four distinct curves are plotted: PCNN+ONE (blue triangles), PCNN+ONE+DSGAN (red circles), PCNN+ATT (black squares), and PCNN+ATT+DSGAN (magenta diamonds). Each curve shows the trade-off between precision and recall for the respective model. The PCNN+ATT+DSGAN model consistently achieves the highest precision across all recall values, followed by PCNN+ATT, PCNN+ONE+DSGAN, and PCNN+ONE. The curves exhibit a general downward trend as recall increases, indicating that higher recall is associated with lower precision.",
        "segmentation": false
    },
    "image_8": {
        "image_id": 8,
        "image_path": "./fusion_research/fusion_dataset/paper/P18-1046/images/image_8.jpg",
        "caption": [],
        "footnote": [
            "Table 2: Comparison of AUC values between previous studies and our DSGAN method. The $p$ -value stands for the result of t-test evaluation. "
        ],
        "context": "Distant supervision has become a standard method in relation extraction. However, while it brings the convenience, it also introduces noise in distantly labeled sentences. In this work, we propose the first generative adversarial training method for robust distant supervision relation extraction. More specifically, our framework has two components: a generator that generates true positives, and a discriminator that tries to classify positive and negative data samples. With adversarial training, our goal is to gradually decrease the performance of the discriminator, while the generator improves the performance for predicting true positives when reaching equilibrium. Our approach is model-agnostic, and 5 Conclusion  of the relation prediction of entity pairs, so we can adopt our generator as the true-positive indicator to filter the noisy distant supervision dataset before relation extraction, which explains the origin of these further improvements in Figure 5 and Figure 6. In order to give more intuitive comparison, in Table 2, we present the AUC value of each PR curve, which reflects the area size under these curves. The larger value of AUC reflects the better performance. Also, as can be seen from the result of t-test evaluation, all the p-values are less than 5e-02, so the improvements are obvious. ",
        "chunk_order_index": 5,
        "chunk_id": "chunk-4e236190c748f858736f0dbadbca362d",
        "description": "The image is a table labeled 'Table 2: Comparison of AUC values between previous studies and our DSGAN method.' The table is structured with four main columns: Model, -, +DSGAN, and p-value. Each row represents a different model configuration and its corresponding AUC values with and without the DSGAN method. The rows are as follows: CNN+ONE (0.177, 0.189, 4.37e-04), CNN+ATT (0.219, 0.226, 8.36e-03), PCNN+ONE (0.206, 0.221, 2.89e-06), and PCNN+ATT (0.253, 0.264, 2.34e-03). The table highlights the improvements in AUC values when using the DSGAN method compared to the baseline models. The p-values indicate the statistical significance of these improvements, all being less than 5e-02.",
        "segmentation": false
    }
}